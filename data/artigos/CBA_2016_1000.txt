XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

DESENVOLVIMENTO DE AMBIENTE VIRTUAL PARA TREINAMENTO DE INTERFACE
CONTROLADA POR RASTREAMENTO DO OLHAR
ALEXANDRE L. C. BISSOLI, MARIANA M. SIME, BERTHIL B. LONGO, TEODIANO F. BASTOS-FILHO
Laboratório de Automação Inteligente, Programa de Pós-Graduação em Engenharia Elétrica
Universidade Federal do Espírito Santo
Av. Fernando Ferrari, 514, Goiabeiras, Vitória-ES
E-mails alexandre-bissoli@hotmail.com, mariana.midori@gmail.com, berthilbl@gmail.com,
teodiano.bastos@ufes.br
Abstract Intelligent environments can be of great help for people with severe motor disabilities, allowing them to control the
lighting and electronic equipment through a Human Computer Interface (HCI) controlled by Videooculography (VOG). In order
to train the HCI for users, a Virtual Environment (VE) that simulates a house with the equipment to be driven was developed at
UFES. The aim of this study is to present the VE here developed, the HCI based on eye tracking and evaluating its usability and
performance during training. Volunteers, including two with disabilities, used and evaluated the system using the System Usability Scale (SUS). The SUS overall average was 92.5 points, which is considered an excellent device according to SUS classification. The performance was evaluated through a modified version of Goal Attainment Scale (GAS), and 14 out of the 16 participants had performance above expectations by researchers.
Keywords Intelligent environment, Virtual reality, Eye tracking, Usability Scale.
Resumo Ambientes inteligentes podem ser de grande auxílio para pessoas com deficiência motora severa, permitindo-lhes
controlar a iluminação e equipamentos eletrônicos de um ambiente através de uma Interface Humano-Computador (IHC), acionada por Videooculografia (VOG). Visando o treinamento para uso da IHC, foi desenvolvido na UFES um Ambiente Virtual
(AV) que simula uma casa com os equipamentos a serem acionados. O objetivo deste trabalho foi apresentar o AV desenvolvido,
a IHC por rastreamento_do_olhar, bem como avaliar a sua usabilidade e desempenho durante o treino. Ao todo, dezesseis pessoas,
sendo duas com deficiência, utilizaram e avaliaram o sistema através do instrumento System Usability Scale (SUS). A média geral do SUS foi 92,5 pontos, sendo considerado um excelente dispositivo, de acordo com a classificação do instrumento. O desempenho foi avaliado através de uma versão modificada da Goal Attainment Scale (GAS), sendo que 14 dos 16 participantes tiveram desempenho acima do esperado pelos pesquisadores.
Palavras-chave .

1

Introdução

Comprometimentos sensitivos, motores, de
linguagem e comportamentais, em diversos níveis,
são comuns em pessoas com deficiências motoras,
acarretando em déficits não só para a realização de
atividades do cotidiano, mas também na interação
com pessoas e objetos (Pedretti e Early, 2004).
Frequentemente, essas pessoas se tornam bastante
dependentes de familiares eou cuidadores. Nesse
sentido, o uso de dispositivos de tecnologia_assistiva
(TA) tem se apresentado como de relevante
importância nos tratamentos de reabilitação, visto
que tais equipamentos ampliam formas de
comunicação, de mobilidade, de controle do
ambiente, de integração com as redes sociais e de
habilidades de aprendizado. O objetivo com uso da
TA é melhorar a funcionalidade e a participação
social dessas pessoas com deficiência (Luzo, Mello e
Capanema, 2004).
Em se tratando de pessoas com deficiência
motora severa, um ambiente_inteligente pode ser uma
indicação, pois nele a iluminação e os equipamentos
eletrônicos (TV, aparelho de som, ventilador) podem
ser controlados mesmo com pouca mobilidade
(pessoas com tetraplegia ou com doenças
neuromusculares, por exemplo). Este controle pode
ser realizado por meio de uma Interface Homem-

ISSN 2525-8311

Computador (IHC) (Rampinelli et al, 2012),
configurada para ser acionada por Videooculografia
(VOG). Eye tracking por VOG, ou rastreamento dos
olhos é uma tecnologia que consiste em determinar o
ponto de olhar da pessoa em uma tela.
Nos chamados eye trackers, dispositivos
equipados com eye tracking, os usuários podem
utilizar o movimento dos olhos como uma
modalidade de interface homem-computador, a qual
pode ser combinada com outros dispositivos de
entrada, tais como mouse, teclado, toque e gestos,
possibilitando diversas aplicações jogos, navegação
web, e-livros, estudos de mercado e testes de
usabilidade (Halton, 2008).
Os eye trackers são utilizados para calcular o
ponto onde o usuário está olhando, por meio de
informações extraídas do seu rosto e olhos. As
coordenadas do ponto são calculadas em relação a
uma tela do monitor que o usuário está olhando, e
são representadas por um par de coordenadas (x, y)
indicado no sistema de coordenadas da tela (Figura
1).
A fim de acompanhar o movimento dos olhos do
usuário e calcular as coordenadas do ponto do olhar,
o eye tracker deve ser colocado abaixo da tela do
computador e apontado para o usuário, conforme
indicado na Figura 1.
Quando o sistema é calibrado, o software do eye
tracker calcula o ponto do olhar do usuário com uma
3476

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

precisão angular média de 0,5 a 1. Assumindo que o
usuário se senta cerca de 60 cm de distância do eye
tracker, esta precisão corresponde a um erro médio
na tela de 0,5 a 1 cm. A calibração é um
procedimento simples que consiste em seguir com o
olhar uma bolinha apresentada na tela, e a duração
total é de cerca de um minuto.

respectivos cômodos. A opção Comunicação será
abordada em outro trabalho, visto seu semelhante
nível de complexidade e de detalhamento. A opção
Navegação corresponde ao controle de locomoção
da cadeira_de_rodas no ambiente_virtual, e a opção
Fechar é para encerrar o uso da interface.

Figura 1. Ponto da tela que o usuário está olhando. Fonte website
da empresa The Eye Tribe (httpdev.theeyetribe.comgeneral)

Por outro lado, uma IHC pode ser beneficiada
com o uso de Ambiente Virtual (AV) (Halton, 2008).
Essa tecnologia tem um amplo campo de utilização,
por exemplo, em salas de aula virtuais ou
simuladores de voo e direção, e vem sendo utilizada
desde a década de 1970 (Kilner e Tori, 2004). Em
AVs, é comum o uso de avatares para representarem
os usuários. Os avatares são modelos que podem ser
usados como substitutos de pessoas reais para
diversas funções (Badler, 1997), podendo ter forma
humana, animal, realista ou caricaturada (Kurlander,
Skelly e Salesin, 1996). Eles ainda podem ser
representados por formas tridimensionais, como visto
normalmente em jogos e simuladores, ou forma
bidimensionais, comumente usadas em ícones de
fóruns de internet ou comunicação on-line (Fink,
1999).
Assim, visando o treinamento de usuários para o
uso da IHC, foi desenvolvida na Universidade
Federal do Espírito Santo  UFES, um AV que
simula uma casa com três cômodos. O usuário é
representado por um avatar com deficiência motora,
(usuário de cadeira_de_rodas), que pode se locomover
pela casa utilizando a IHC, onde equipamentos
eletrônicos podem ser ligados e desligados pelo
usuário.
Nesse sentido, o objetivo deste trabalho foi
apresentar a IHC controlada por rastreamento dos
olhos e avaliar tanto sua usabilidade quanto o
desempenho do usuário ao utilizar o sistema.

Figura 2. Estrutura da Interface de Controle.

Os comandos da IHC são dados através do
movimento dos olhos do usuário, utilizando o eye
tracker, da empresa The Eye Tribe. Através do
recurso de controlar o cursor do mouse com o
movimento dos olhos, o usuário pode posicionar o
cursor em qualquer ponto da interface. Para que a
IHC reconheça um comando, basta que o usuário
olhe durante 1 s para dentro de um dos quadrados.

2 Interface Humano-Computador (IHC)
O sistema desenvolvido será apresentado em duas
partes que se complementam IHC e AV. A Figura 2
apresenta um diagrama_de_blocos com todas as
opções disponíveis na interface de controle.
O menu principal da interface desenvolvida no
Matlab possui cinco ícones (quadrados), onde cada
quadrado corresponde a um comando (Figura 3). As
opções Quarto e Sala correspondem ao conjunto
de equipamentos disponíveis para o usuário nesses
ISSN 2525-8311

Figura 3. Menu principal da Interface Homem-Computador.

Ao selecionar a opção Quarto, será apresentado
ao usuário quatro opções de equipamentos para
ligardesligar, além de opção de fechar essa interface
e retornar  interface principal. O ventilador do
quarto e o ventilador da sala, por exemplo, são
equipamentos diferentes um do outro e possuem

3477

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

interfaces correspondentes, apesar de terem a mesma
aparência.
Quando um equipamento é ligado, o fundo dele
na interface fica em amarelo, como é o caso do
Ventilador e do Rádio apresentados na Figura 4.
Já a Televisão e a Lâmpada estão desligadas, e
por isso o fundo da imagem é branco. Este é o estado
atual dos equipamentos do Quarto, pois os
equipamentos da Sala possuem outro estado
independente.

por exemplo, então ele deverá dar o comando
Frente quatro vezes. O comando Trás é o
contrário do comando Frente e desloca a cadeira 1
metro para trás. Os comandos Direita e Esquerda
giram a cadeira 30 para o respectivo lado.
3 Ambiente Virtual (AV)
A Figura 6 mostra o usuário dando o comando
Frente na sub-interface Navegação para locomover a cadeira 1 metro para frente no Ambiente Virtual.

Figura 4. Sub-menu mostrando os equipamentos disponíveis no
Quarto.

A Figura 4 mostra a sub-interface que aparece
caso o usuário olhe para o quadrado Quarto ou
Sala na interface principal.
Após ligar ou desligar os equipamentos
desejados, o usuário pode dar o comando Fechar e
retornar  interface principal. Ao selecionar a opção
Navegação na interface principal, é apresentada ao
usuário a interface com quatro comandos
relacionados  locomoção da cadeira_de_rodas, além
do comando de fechar a interface e retornar 
interface principal (Figura 5).

Figura 6. Usuário olhando para o comando Frente no monitor, e
ao fundo a projeção do AV, o qual recebe esses comandos.

Para a realização dos testes, a IHC foi colocada
no monitor para o usuário, e o AV foi projetado na
parede atrás do monitor, como pode ser visto na
Figura 6. Por estarem no mesmo computador, a
comunicação entre a IHC e o AV foi feita através do
Protocolo UDP.
A estrutura do AV foi construída no software
Blender 3D versão 2.75, o qual consiste em uma casa
com uma sala, um quarto, uma cozinha e um quintal
com uma passarela que circunda toda a casa (Figura
7). O usuário pode navegar por todos esses espaços
utilizando a interface, e os equipamentos eletrônicos
foram distribuídos na sala e no quarto. A
funcionalidade do AV foi feita utilizando o software
Unity 5, um dos programas mais adequados para essa
finalidade (Silva e Silva, 2011).

Figura 5. Sub-menu Navegação

Se o usuário olhar durante 1 s para dentro de um
dos quadrados disponíveis nessa interface, o
comando correspondente será identificado. A Figura
5 mostra um usuário olhando para o comando
Frente. Neste caso, depois de reconhecido o
comando, o fundo do quadrado correspondente será
alterado para amarelo durante 1 s e depois voltará a
ser branco. Ao dar esse comando, a IHC enviará o
comando para o AV que irá mover a cadeira_de_rodas
para frente por uma distância equivalente a 1 metro.
Se o usuário quiser deslocar-se 4 metros para frente,

ISSN 2525-8311

Figura 7. Vista aérea do Ambiente Virtual desenvolvido.

3478

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

4 Testes com usuários
Para avaliar a usabilidade e o desempenho com o
uso do sistema, foram convidadas a participar
pessoas sem e com deficiência motora, de ambos os
sexos. As pessoas sem deficiência (grupo controle)
correspondem a alunos de graduação e pósgraduação da UFES, e as pessoas com deficiência
foram selecionadas a partir de um projeto de
extensão do curso de Terapia Ocupacional da UFES,
denominado Intervenção da Terapia Ocupacional
com pacientes com sequelas neurológicas, que visa
a reabilitação de pessoas com sequelas advindas de
lesões ou doenças neurológicas.
Seguindo a Resolução n 46612 do Conselho
Nacional de Saúde, a pesquisa foi aprovada pelo
Comitê de Ética em Pesquisas em Seres Humanos da
Universidade Federal do Espírito Santo  CEPUFES
através do parecer n. 976.828.
Foi realizado convite aos participantes e
agendado um dia para a realização do teste no
Laboratório de Automação Inteligente  LAIUFES.
No laboratório, a pesquisa foi explicada
detalhadamente e, após assinar o Termo de
Consentimento Livre e Esclarecido (TCLE), o sujeito
foi posicionado sentado diante do eye tracker e do
monitor de computador no qual a IHC poderia ser
visualizada e acionada. Mais  frente dessa estrutura
foi disposta a tela, na qual foi projetado o AV.
O sistema foi apresentado, ressaltando a planta da
casa, os cômodos, a posição dos equipamentos, a
forma de controle do cursor para acioná-los e
orientações a respeito da navegação com a cadeira de
rodas. Após, foi realizada a etapa de calibração do
eye tracker, seguindo as orientações do fabricante.
O teste consistiu em realizar 18 tarefas ditadas
sequencialmente, as quais estavam divididas em 3
blocos com diferentes quantidades de comandos e
detalhamentos, sendo bloco 1  tarefas detalhadas
compostas por comandos somente da cadeira de
rodas ou somente de controle dos equipamentos
bloco 2  tarefas detalhadas que mesclavam
comandos da cadeira_de_rodas e de controle dos
equipamentos bloco 3  tarefas com menos
detalhamentos dos passos. A Figura 8 apresenta as 18
tarefas realizadas por cada um dos participantes. Os
números seguidos de letras, que constam nas
descrições das tarefas, correspondem  quantidade de
vezes e a direção em que o participante deveria dar o
comando. Todas as tarefas foram ditadas por um dos
pesquisadores.
Ressalta-se que o teste de cada participante foi
filmado para posterior análise.
Cada participante, após realizar todas as tarefas
na sequência, sem pausa, respondeu o instrumento
System Usability Scale (SUS). Este instrumento é
auto-aplicável e visa a avaliação rápida e simples da
usabilidade de produtos ou serviços. O SUS se
caracteriza por 10 itens pontuados por uma escala de
Likert de 5 pontos, variando de 1  discordo
totalmente a 5  concordo totalmente. As
afirmações apresentadas no instrumento abrangem

ISSN 2525-8311

uma variedade de aspectos da usabilidade do sistema,
tais como necessidade de apoio, treino e
complexidade e, portanto, têm um nível elevado de
validade aparente para a medição de um sistema de
usabilidade (Brooke, 1996).
Bloco

Tarefa

Descrição da tarefa
Abrir interface, navegação, 4F, fechar,
1
fechar interface.
Abrir interface, sala, ligar lâmpada, ligar
2
TV, fechar, fechar interface.
Abrir interface, navegação, 1F, 3E,
3
fechar, fechar interface.
Abrir interface, sala, desligar TV, ligar
4
1
rádio, fechar, fechar interface.
Abrir interface, sala, desligar lâmpada,
5
ligar ventilador, fechar, fechar interface.
Abrir interface, sala, desligar rádio,
6
desligar ventilador, fechar, fechar interface.
Abrir interface, navegação, 4F, fechar,
7
fechar interface.
Abrir interface, navegação, 3E, 1F, 3D,
8
2F, fechar, quarto, ligar ventilador,
fechar, fechar interface.
Abrir interface, navegação, 3D, fechar,
9
quarto, ligar lâmpada, ligar rádio, fechar,
fechar interface.
Abrir interface, navegação, 3D, 2F, 3E,
10
2F, 1E, 1F, 2E, 1F, fechar, fechar interface.
Abrir interface, quarto, desligar rádio,
2
11
fechar, navegação, 6D, fechar, quarto,
ligar TV, fechar, fechar interface.
Abrir interface, quarto, desligar TV,
12
desligar lâmpada, fechar, navegação, 1F,
3D, fechar, fechar interface.
Abrir interface, quarto, desligar ventila13
dor, fechar, navegação, 2F, 3E, 4F, 2D,
fechar, fechar interface.
Abrir interface, navegação, 1F, 1D, 2F,
14
3E, fechar, fechar interface.
Abrir interface, navegação, dar a volta na
15
casa para chegar  cozinha, fechar interface.
Abrir interface, navegação, ir até o quarto
16
e acender a luz, fechar interface.
3
Abrir interface, navegação, ir até a sala,
17
ligar ventilador e lâmpada e ir para a
cozinha, fechar interface.
Abrir interface, navegação, sair da cozi18
nha pela esquerda, dar a volta na casa,
parar na porta da sala, fechar interface.
Figura 8. Quadro de tarefas. Sendo F  ir para frente E  ir para
esquerda D  ir para direita.

A avaliação_do_desempenho do usuário com o uso
do sistema foi realizada através de uma versão
modificada do Goal Attainment Scaling (GAS). O
GAS se propõe a avaliar a eficácia de um tratamento
ou intervenção a partir de metas estabelecidas entre o
próprio sujeito e seu terapeuta (Krasny-Pacini et al,
2013), sendo cada meta classificada numa escala de 5
pontos, pontuado de -2 (resultado muito pior do que
o esperadobaseline) a +2 (melhor resultado possível)
e o nível 0 representando o resultado esperado após o
tratamentointervenção.
Para este estudo, buscou-se verificar se o
desempenho do usuário, após utilização do sistema,
sem qualquer treino, se aproximava do desempenho
ideal esperado pela equipe. Assim, foi realizada
3479

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

5 Resultados
A comunicação entre a IHC e o AV utilizando o
Protocolo UDP foi excelente e permitiu que os dois
programas trabalhassem em conjunto.
Foi observado que o tempo de reconhecimento de
comandos, especificados em 1 s, foi adequado,
evitando que comandos indesejados fossem dados
pelo usuário e deixando o sistema bastante rápido.
No total, participaram do estudo dezesseis
pessoas, sendo duas com deficiência motora (os
participantes 3 e 14). Desses, doze eram do sexo
masculino (75) e quatro do sexo feminino (25).
As idades variaram de 20 a 38 anos.
O tempo aproximado de realização de cada teste,
desde o momento da apresentação do sistema até a
finalização das tarefas, foi de 20 minutos.
Todos os participantes finalizaram as tarefas e
responderam ao instrumento SUS. A pontuação de
cada participante encontra-se na Figura 9.
A pontuação média geral foi 92,50, com desvio
padrão de 8,70, e a média somente do grupo das
pessoas com deficiência foi 82,50, com desvio
padrão de 15,00.

Pontuação

100
80

1000
500

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

0
Participantes
Figura 10. Resultados do tempo total (por participante).
3
2
1
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Na equação (1), T é o resultado do GAS. O
parâmetro C varia com o número de objetivos (neste
estudo C6,2) e o valor de Xi é o conceito de cada
objetivo do GAS do participante (-2, -1, 0, 1 ou 2).

1500

Tempo (s)

  50 +   

(1)

número de comandos dados. O tempo mínimo foi de
812 s (13 minutos e 32 segundos) e o tempo máximo
foi de 1309 s (21 minutos e 49 segundos). A média
de todos os participantes foi de 1018 s (16 minutos e
58 segundos) e o desvio padrão de 131 s (2 minutos e
11 segundos). O erro máximo foi de 2 do total de
comandos.

Erro ()

somente uma intervenção pontual utilizando o
sistema, sendo que as tarefas e parâmetros foram
estabelecidos pelo grupo de pesquisadores
previamente ao contato com os participantes.
A estrutura de pontuação do GAS foi mantida
(escala variando de -2 a +2). Foram determinados
valores esperados com relação ao tempo e ao
percentual de erros tolerados para a realização de
todo o teste. O vídeo de cada participante foi
analisado e a pontuação foi realizada.
A seguinte equação (1) foi utilizada para o
cálculo do GAS

Participantes
Figura 11. Resultados do erro (por participante).

As Tabelas 1 e 2 apresentam os parâmetros
estabelecidos para o GAS com relação ao tempo total
e o erro percentual, respectivamente, e a classificação
de cada participante. Os intervalos foram definidos
com base em resultados preliminares de quatro
estudantes envolvidos nessa pesquisa. Na coluna
Frequência é apresentada a quantidade de
participantes classificados em cada intervalo do
GAS.
Tabela 1. Parâmetros do GAS de tempo total.
Intervalo

1
2
3
4
5

Mínimo
(s)

Máximo
(s)

Conceito
GAS

Frequência

0

960

+2

5

961

1080

+1

6

1081

1200

0

4

1201

1320

-1

1

1321

1800

-2

0

60
40

Tabela 2. Parâmetros do GAS de erro percentual.

20
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

0
Participantes
Figura 9. Resultados do SUS (por participante).

No que se refere aos resultados da avaliação de
desempenho, a Figura 10 apresenta o tempo total de
cada voluntário ao realizar as 18 tarefas, e a Figura
11 apresenta o percentual de erros com relação ao

ISSN 2525-8311

Intervalo

1
2
3
4
5

Erro
()

Conceito
GAS

Frequência

0

+2

8

1

+1

6

2

0

2

3

-1

0

4

-2

0

3480

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

De acordo com a equação (1) e as Tabelas 1 e 2,
calculou-se o GAS para cada participante (Figura
12). Como neste trabalho foram considerados dois
objetivos (tempo e percentual de erros), o valor de C
é 6,2, conforme determinado pela literatura (KrasnyPacini et al, 2013). Assim, os valores de T variam de
25,2 a 74,8.
Segundo Krasny-Pacini et al (2013), para T igual
a 50, o resultado obtido é o esperado. Para valores de
T inferiores a 50, o resultado é pior do que o
esperado e para valores superiores a 50, o resultado é
melhor do que o esperado. Os valores calculados de
T para cada participante são apresentado na Figura
12. Assim, os resultados dos testes realizados
indicam um desempenho muito melhor do que o
esperado.
80

T

60
40
20
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

0
Participantes
Figura 12. Resultados do GAS (por participante).

6 Conclusão
Pode-se considerar que o sistema foi bem
avaliado pelos participantes, através do SUS, com
média geral de 92,5. Segundo Bangor, Kortum e
Miller (2008), produtos avaliados na faixa dos 90
pontos são considerados excepcionais, produtos
avaliados na faixa dos 80 pontos são bons, e produtos
avaliados na faixa dos 70 pontos são aceitáveis.
Dessa forma, mesmo o grupo das pessoas com
deficiência apresentou média de resultados (87,50)
que pode ser considerada uma boa avaliação do
sistema desenvolvido.
Vale ressaltar que a literatura aponta altos índices
de abandono de dispositivos de tecnologia_assistiva
(Wessels et al., 2003). Nesse sentido, o treino para
uso dos equipamentos, tais como o proposto por este
projeto, contribuem para que a pessoa com
deficiência possa ter uma experiência prévia com a
tecnologia. Por isso, as avaliações de usabilidade
obtidas neste estudo são de extrema importância,
pois indicam que os usuários demonstram satisfação
ao utilizar o sistema desenvolvido. O desempenho
dos participantes, utilizando o sistema pela primeira
vez, sem qualquer treino revelou que o resultado de
14 dos 16 participantes foi acima do esperado
(GAS>50), enquanto os 2 restantes tiveram resultado
esperado (GAS50).
Agradecimentos
Os autores agradecem  UFES pela estrutura de
laboratórios e equipamentos oferecidos, ao CNPq e 

ISSN 2525-8311

CAPES (Projeto PGPTA n 592014) pelo apoio
financeiro e pelas bolsas concedidas.
Referências Bibliográficas
Badler, N.I. (1997). Real-time virtual humans. In
Computer
Graphics
and
Applications,
Proceedings of The Fifth Pacific Conference on.
IEEE, p. 4-13.
Bangor, A. Kortum, P. e Miller, J.A. (2008). The
System Usability Scale (SUS) An Empirical
Evaluation, International Journal of HumanComputer Interaction 24(6).
Brooke, J. (1996). SUS a "quick and dirty" usability
scale. In JORDAN, P.W. et al (Eds.). Usability
Evaluation in Industry. London Taylor and
Francis. p.189-194.
Fink, J. (1999). Cyberseduction reality in the age of
psychotechnology.
Avatar
(computing).
Prometheus Books, p.47-53.
Halton, J. (2008). Virtual rehabilitation with video
games A new frontier for occupational therapy.
Occupational Therapy Now, 9(6), p. 12-14.
Kilner, C. e Tori, R. (2004). Introdução  Realidade
Virtual, Realidade Misturada e Hiper-realidade.
Realidade Virtual conceitos e tendências.
Editora Mania de Livro. São Paulo. p. 3.
Krasny-Pacini, A. et al. (2013). Goal attainment
scaling in rehabilitation a literature-based
update. Annals of Physical and Rehabilitation
Medicine. 56, 212-230.
Kurlander, D. Skelly, T. e Salesin, D. (1996). Comic
chat. In Proceedings of the 23rd annual
conference on Computer graphics and interactive
techniques. ACM, p. 225-236.
Luzo, M.C.M. Mello, M.A.F. e Capanema, V.M.
(2004). Recursos tecnológicos em terapia
ocupacional - órteses e tecnologia_assistiva. In
De Carlo, M.M.R.P. e Luzo, M.C.M. (orgs.).
Terapia ocupacional reabilitação física e
contextos hospitalares. São Paulo Roca, p. 99126.
Pedretti, L.W. Early, M.E. (2004). Desempenho
ocupacional e modelos de prática para disfunção
física. In Pedretti, L.W. Early, M.E. Terapia
ocupacional
capacidades
práticas
para
disfunções físicas. São Paulo Roca.
Rampinelli, M. et al (2012). Implementation of an
intelligent space for localizing and controlling a
robotic wheelchair. Biosignals and Biorobotics
Conference (BRC), ISSNIP, 1-4.
Silva, R. e Silva, A. (2011). Tecnologias para
construção de mundos virtuais um comparativo
entre as opções existentes no mercado, FAZU
em Revista, No. 08, pp. 211-215.
The Eye Tribe internet. 2016. Disponível em
httptheeyetribe.com
Wessels, R. et al. (2003). Non-use of provided
assistive technology devices a literature
overview. Technology and Disability 15(4),
231-238.

3481