XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

APLICACAO DE MARCOS FIDUCIAIS PARA CONTROLE SERVO VISUAL 2 12D
EM VEICULOS SUBMARINOS AUTONOMOS
Diego Cesar, Andre Conceicao, Marco Reis, Jan Albiez


Faculdade de Tecnologia SENAI CIMATEC
Nucleo de Robotica
Salvador, Bahia, Brasil


Universidade Federal da Bahia
Departamento de Engenharia Eletrica
Salvador, Bahia, Brasil
diego.cesar@fieb.org.br, andre.gustavo@ufba.br, marcoreis@fieb.org.br,
jan.albiez@fieb.org.br
Abstract The assets of the Oil and Gas industry need frequent inspections. Currently divers and remotely
operated vehicles perform this work, however autonomous underwater vehicles have been investigated in order to
replace the current methods and thus increase the periodicity and reduce the operational costs. Controlling the
vehicle movements with respect to the object to be inspected increases the accuracy when compared with the
global position based navigation and therefore visual servoing plays an important role on this field. This work
shows the application of a visual servoing task in an autonomous underwater vehicle using the artificial fiducial
markers as the visual references. The results in the simulated environment platform Gazebo are here presented
in the case of calm waters and under disturbances of ocean currents. An adaptive gain approach is compared
with a static gain and it shows better performance, mainly under ocean currents influences. On that cases it
presents faster response and null error on the steady state.
Keywords

visual servoing, autonomous underwater vehicles, Gazebo.

Resumo As estruturas da industria de oleo e gas necessitam inspecoes frequentes. Atualmente mergulhadores e robos operados remotamente realizam este trabalho, contudo pesquisas em robos submarinos autonomos
tem crescido na intencao de substituir os metodos utilizados atualmente para aumentar periodicidade e reduzir os
custos das operacoes. Controlar o movimento do veculo em relacao ao objeto que deseja-se inspecionar aumenta
a precisao quando comparado a navegacao em relacao a posicao global e por esse motivo o controle_servo_visual
mostra sua importancia nesse ramo. Este trabalho mostra a aplicacao de um controle_servo_visual em um veculo
autonomo submarino utilizando marcos fiduciais. Resultados em ambiente simulado na plataforma Gazebo sao
apresentados para os casos em que o robo opera em aguas tranquilas, mas tambem para casos com pertubacoes
de correntes martimas. Uma abordagem utilizando ganhos adaptativos e comparada com a utilizacao do ganho
estatico e mostra melhor performance principalmente nos casos com influencia das correntes martimas, onde
alem de apresentar uma resposta mais rapida consegue atingir erro nulo de regime.
Palavras-chave

.

Introducao

Ativos submarinos da industria de Oleo e Gas necessitam de inspecoes periodicas. Atualmente a
maior parte deste trabalho e realizado utilizando
robos operados remotamente (ROVs) ou mergulhadores. A utilizacao de robos submarinos autonomos para estes fins permitem a reducao de custos operacionais e maior frequencia nas inspecoes,
reduzindo tambem o risco de acidentes ambientais.
(Albiez et al., 2015)
O sistema_de_navegacao de um veculo submarino baseia-se principalmente nos seus sensores
inerciais e de velocidade. Estes servem como entrada para filtros que estimam a posicao do robo
em relacao a um referencial inercial. A covariancia dessa estimativa tende a aumentar com o passar do tempo impactando em resultados cada vez
menos confiaveis. Nesse contexto o controle servo
visual apresenta sua importancia, pois permite o
controle em relacao a um objeto e utiliza a camera
para realimentar a cadeia de controle. Aplicacoes

ISSN 2525-8311

conhecidas de movimentacao em que a navegacao
em relacao ao objeto alvo e prefervel sao a docagem do robo (Lee et al., 2003) ou inspecao de
tubulacoes (Rives and Borrelly, 1997).
Outras aplicacoes de controle_servo_visual em
robos submarinos sao auxiliar robos para inspecao e reconstrucao 3D de estruturas submarinas
(Brandou et al., 2007), auxiliar pilotos de ROVs
via controle assistido (Plotnik and Rock, 2006) e
controle em relacao a uma valvula para sua manipulacao (Evans et al., 2003).
Uma das contribuicoes deste trabalho esta na
utilizacao de marcos fiduciais para a realizacao do
controle visual. Os marcos fiduciais artificiais sao
padroes, semelhantes a um QR code, projetados
para que sejam facilmente detectados por sistemas de visao_computacional, provendo meios para
o calculo da pose da camera em relacao ao objeto.
Estes possuem IDs que sao codificados na imagem de acordo com protocolos pre-estabelecidos.
Suas aplicacoes iniciaram na area da realidade_aumentada (Mohamed, 2012), mas com o passar do

3622

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

tempo revelou-se util para aplicacoes em robotica
(Feng and Kamat, 2012).
Ao longo dos anos, varios tipos de marcos foram criados. Os primeiros foram o MAtrix (Rekimoto, 1998) e ARToolKit (Kato and
Billinghurst, 1999), logo depois outros sistemas
foram desenvolvidos, a maioria deles mantendo
a forma quadrada, como ARTag (Fiala, 2005),
ArUco (Garrido-Jurado et al., 2014) e AprilTags (Olson, 2011). Marcos com formato circular tambem foram desenvolvidos como Rune-Tag
(Bergamasco et al., 2011) e outros contendo informacoes no domnio da frequencia como Fourier
Tags (Xu and Dudek, 2011).
No contexto desse trabalho, experimentos preliminares no oceano, mostraram que os marcos
visuais apresentam uma alta taxa de deteccao
mesmo embaixo dagua, sendo capaz de fornecer
poses estaveis para a camera. A Figura 1 mostra o
cenario de um marco fiducial AprilTags de ID 184
sendo identificado na Baa de Todos os Santos em
Salvador.

Figura 1 Deteccao da AprilTags em ambiente real
Este trabalho propoe realizar o controle de um
veculo submarino autonomo (AUV) utilizando
marcos fiduciais artificiais captados por uma unica
camera no ambiente de simulacao Gazebo. Uma
abordagem utilizando ganho adaptativo e estudada e comparada com a aplicacao de ganho estatico em ambientes com aguas calmas e tambem
sobre o efeito de pertubacoes de corrente martimas.
O artigo esta dividido da seguinte forma A
Secao 2 detalha a fundamentacao teorica do controlador visual. A Secao 3 apresenta a metodologia aplicada. Os resultados sao apresentados e
discutidos na Secao 4. Por fim, as conclusoes do
trabalho sao apresentadas na Secao 5.

ISSN 2525-8311

2

Controlador Visual 2 12D

O universo do controle visual pode ser dividido
em duas grandes areas no que diz respeito a informacao realimentada. A primeira e o controle
visual baseado em imagem (IBVS), enquanto que
o segundo e chamado de controle visual baseado
em posicao (PBVS). A abordagem IBVS utiliza
uma camera para extrair caractersticas relevantes da imagem e compara-las com a posicao delas
no plano da imagem no momento em que a camera
esteja na posicao final. Isto significa que o controle
IBVS realiza um controle no domnio da imagem.
Por conta disto essa abordagem por vezes e chamada de 2D (Chaumette and Hutchinson, 2006).
Por outro lado, o PBVS utiliza a camera para
realizar extracao_de_caractersticas relevantes da
imagem e a partir do previo conhecimento do modelo e com os parametros de calibracao da camera,
calcula a pose do objeto em relacao a camera. A
pose calculada e realimentada na malha_de_controle e comparada com a pose desejada. Pelo fato
das entradas do controle se darem no espaco Euclidiano, o controle visual PBVS tambem e conhecido por controle visual 3D (Chaumette and
Hutchinson, 2006).
Quando comparados, o IBVS apresenta maior
robustez em relacao aos parametros de calibracao da camera, nao possui necessidade do conhecimento do modelo do objeto e requer menor custo
computacional. O IBVS possui um problema singularidade quando uma rotacao pura em torno do
eixo Z da camera e executada. Nesse caso, o movimento do pixel no plano da imagem e interpretado como um movimento translacional em Z e o
controlador identifica um erro inexistente na componente translacional, gerando movimentos indesejaveis (Chaumette and Hutchinson, 2006). O
PBVS nao possui esse problema, contudo apresenta dependencia de uma camera bem calibrada
e conhecimento previo do objeto identificado pelo
sistema de visao_computacional.
Buscando aproveitar os benefcios das duas
abordagens o controle_servo_visual hbrido foi proposto e por unir caratersticas do controle visual
3D e do 2D, este tipo de controlador e tambem
referenciado na literatura como controle visual 2
12D (Malis et al., 1999). Sua proposta principal e
o desacoplamento dos movimentos translacionais
e rotacionais.
Assim sendo, a Equacao 1 mostra a relacao
a velocidade do vetor de caractersticas da imagem st com a velocidade da camera Vc atraves
da matriz de interacao Lst .
st  Lst Vc

(1)

Contrariamente as abordagens IBVS e PBVS
a matriz de interacao e dividida em suas componentes translacionais e rotacionais. Dessa forma a

3623

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

Equacao 1 e reescrita, resultando na Equacao 2,
onde vc e c sao as velocidades translacionais e
rotacionais da camera, respectivamente.
st  Lv L  vc c T
 Lv vc + L c

(2)

Com o objetivo de definir uma lei de controle
para o controle visual hbrido, define-se primeiramente o erro entre a posicao desejada e a posicao
atual. Assim sendo, pode-se assumir que a variacao do erro e igual a variacao nas caractersticas
na imagem e  st . Desejando que o erro tenha um
decaimento exponencial, pode-se fazer e  e e
assim a equacao 2 fica
e  e  st  Lv vc + L c

(3)

A partir da Equacao 3, pode-se definir a lei de
controle para velocidade translacional da camera
na Equacao 4
vc  L+
v (et + L c )

(4)

Onde c vem da lei de controle PBVS e e definido na Equacao 5 como um parametro  que
multiplica a diferenca entre os angulos atuais e
desejados, na representacao theta-u
c  u

(5)

3

Metodologia

Os experimentos deste trabalho foram realizados
no ambiente de simulacao Gazebo1 . O Gazebo e
um simulador robotico de codigo aberto mantido
pela Open Source Robotics Foundation  capaz de
simular de maneira robusta e fidedigna as interacoes entre o robo e o ambiente fsico. No presente trabalho o Gazebo e utilizado para simular
o oceano levando em consideracao caractersticas
estaticas e dinamicas do fluido, como densidade,
viscosidade e correntes martimas.
Alem disso o Gazebo possui uma integracao
com o Rock Robotics 2 , o framework de desenvolvimento do projeto FlatFish (Watanabe et al.,
2015). Isso permite portabilidade quase que direta das rotinas e parametros de configuracao entre o robo simulado e o robo real. Desse modo, o
modelo do robo integrado ao Gazebo corresponde
com as caractersticas do prototipo fsico. Suas dimensoes sao de 220 cm x 105 cm x 50 cm e massa
de 275 Kg. Em termos de sensores e atuadores relevantes para este trabalho, o veculo e equipado
com quatro cameras com resolucao 2K (2048 x
2048) e seis propulsores que permitem atuacao em
cinco graus de liberdade (surge, sway, heave, pitch
e yaw ) (Albiez et al., 2015).
A Figura 2 mostra o robo FlatFish no ambiente simulado.

Assim, a Equacao 4 e a Equacao 5 definem a
lei de controle do controlador visual 2 12D, com
(Chaumette and Hutchinson, 2007)


1 0
x
1 
0 1 y 
Lv 
Zz
0
0 1


xy
(1 + x2 ) y
xy
x 
L   1 + y 2
y
x
0
As variaveis x e y sao as coordenadas do pixel
Zatual
no plano da imagem e z 
.
Zdesejado
Neste trabalho, o parametro  das Equacoes 4
e 5 sera utilizado com duas abordagens diferentes,
a primeira considerando-o como um ganho estatico e a segunda variando-o adaptativamente em
funcao do erro x, conforme a Equacao 6
(x)  a  exp(b  x) + c

(6)

Com a, b e c calculados em base nos ganho
no erro zero (0), ganho no erro infinito () e
a variacao do ganho quando o erro e igual a zero
(0), de acordo com 7
a  (0)  () b  (0)a c  ()

(7)

Assim, quando o erro e grande o ganho e ajustado para um valor baixo de modo a diminuir a
agressividade do controlador e quando o erro e
muito pequeno esse ganho e aumentado para amplificar o sinal de controle.

ISSN 2525-8311

Figura 2 FlatFish realizando uma inspecao em
um naufragio no Gazebo
A camera simulada foi configurada com resolucao reduzida de 720p (1280 x 720) de forma a
aumentar a velocidade de processamento na deteccao dos marcos e aumentar a frequencia do
controlador. Como o a tecnica de controle visual
adotada e monocular, a camera frontal esquerda
foi escolhida. Os graus de liberdades controlados
pelo controlador visual sao os lineares em x, y e z
(surge, sway e heave) e o angular em relacao a y
(pitch).
Com relacao ao marco fiducial, dentre as di1 www.gazebo.org
2 www.rock-robotics.org

3624

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

Resultados e Discussoes

Os resultados da simulacao para o cenario sem corrente martima sao apresentados nas Figuras 4 e 5.
A Figura 4 apresenta a posicao do veculo nos quatro graus de liberdade controlados. Para este caso,
pode-se observar que o controlador com ajuste de
ganho proporcional apresenta um tempo de acomodacao de cerca de 55 segundos. A mudanca
da estrategia_de_controle para utilizacao do ganho
adaptativo apresenta uma melhora de 63, uma
vez que o tempo de acomodacao cai para cerca de
20 segundos.
A Figura 5 mostra que a trajetoria de ambos
controladores sao praticamente as mesmas e que a
posicao final e alcancada por ambos controladores.
3 httpsvisp.inria.fr

ISSN 2525-8311

(b)

(c)

(d)

Seguimento de Referência
4
0
3

60

1

90

0

120

1

150

2
0

10

20
30
40
Esforço de controle

50

180
60

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0

0

0.1

0.1

0.2

0.2

0.3
10

surge
sway
heave

20

30
tempo (s)

yaw
proporcional
adaptativo

40

50

Posição Angular ()

2

Velocidade Angular (rads)

Posição Linear (m)

30

0

4

(a)

Figura 3 Posicao inicial e final do veculo no
mundo (a) e (b) e no plano da imagem (c) e
(d)

Velocidade Linear (ms)

versas bibliotecas citadas na secao 1 o padrao de
marcos AprilTags (Olson, 2011) foi escolhido pois
estudos anteriores mostraram que este apresenta
melhores resultados em ambientes aquaticos em
termos de taxa de deteccao, taxas de falsos negativos e falsos positivos (Cesar et al., 2015). Assim,
nos experimentos, uma AprilTag com ID  1 de
tamanho 0.40m x 0.40m foi adicionada ao Gazebo.
O ambiente foi simulado em duas condicoes
aguas tranquilas, onde nao ha presenca de correntes martimas e sob efeito de uma corrente martima constante que simula as condicoes da Baa
Aratu em Camacari-BA, local de testes do FlatFish. Neste ponto as correntes sao em media 0.4
ms (CODEBA, n.d.), que no ambito deste trabalho foram representadas como componentes nos
eixos X e Y do robo com magnitude de 0.283 ms
cada.
Para cada cenario, duas variacoes do controlador servo visual 2 12D foram avaliadas. Dada a
lei de controle definida na Equacao 4 a primeira
estrategia utiliza  como um ganho constante, ja
a segunda variacao seleciona o  adaptativamente
em funcao do erro x, conforme Equacao 6, onde x
e s  s 2 .
O controlador visual foi desenvolvido utilizando a biblioteca VISP (Visual Servoing
Plataform)3 e os cenarios considerados para o controlador com ganho proporcional   0.1 e o ganho adaptativo (0)  0.5, ()  0.08, (0) 
0.5
Todos os testes foram realizados com o robo
partindo da posicao inicial X  1.0, Y 
0.6, Z  3.0 e 30 de rotacao em relacao a Y com
posicao objetivo de x  0.0, y  0.0, z  1.0 e 0
de rotacao em relacao a Y. Considerando o eixo
optico, onde Z aponta para frente o eixo Y para
baixo e o X para a direita. A Figura 3 mostra
a posicao do veculo no mundo e dos marcos no
plano da imagem para as posicoes iniciais e desejadas.

0.3
60

referência

Figura 4 Seguimento de referencia para o caso
sem corrente martima

Para o caso onde e adicionada uma pertubacao constante de correntes martimas, o desempenho do controlador e mostrado nas Figuras 7
e 6. Observa-se da Figura 6 que o controlador
proporcional apresenta um erro de regime_permanente enquanto que a estrategia que utiliza o ganho adaptativo apresenta erro nulo de regime e
um tempo de acomodacao levemente superior.
A diferenca do erro em regime e observada
mais claramente na Figura 7, onde a linha contnua que representa a posicao dos pixels no plano

3625

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro
0

320

640

960

0

1280

240

240

480

480

720

720

Figura 5 Trajetoria dos pixels no plano da imagem - sem correntes martima

Seguimento de Referência
4
0
3

60

1

90

0

120

1

150

2
0

10

20
30
40
Esforço de controle

50

180
60

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0

0

0.1

0.1

0.2

0.2

0.3
0

10

surge
sway
heave

20

30
tempo (s)

yaw
proporcional
adaptativo

40

50

Posição Angular ()

2

0.3
60

referência

Figura 6 Seguimento de referencia para a pertubacao de corrente martima

da imagem para o caso do controlador proporcional nao alcanca a posicao final desejada. Com a
utilizacao do ganho proporcional, a medida que o
erro diminui o sinal de controle e diminudo proporcionalmente. No caso em que ha presenca de
correntes martimas, o sinal de controle e pequeno
e nao consegue vencer a acao da forca de pertubacao externa. O mesmo comportamento nao e observado no controlador_adaptativo, uma vez que
seu comportamento tende a aumentar o sinal de
controle para situacoes em que o erro e pequeno.
Desse modo as correntes sao vencidas e a posicao
desejada e alcancada.

ISSN 2525-8311

320

640

960

1280

pos. inicial prop.
pos. final prop.
trajetória prop.
pos. inicial adap.
pos. final adap.
trajetória adap.

Figura 7 Trajetoria dos pixels no plano da imagem - com correntes martima

A escolha dos valores para o ganho proporcional e limitada pelo comeco da missao, pois ganhos
elevados aumentam a agressividade do controlador
o que pode ocasionar a perda do objeto do campo
de visao da camera. No caso especfico deste trabalho o marco tem sua posicao inicial proxima as
bordas da imagem, local onde e possvel sintonizar
o controlador de uma maneira mais conservadora.
Para valores maiores que   0.1 o robo perdia a
visibilidade do marco.
5

Velocidade Angular (rads)

Posição Linear (m)

30

Velocidade Linear (ms)

0
0

pos. inicial prop.
pos. final prop.
trajetória prop.
pos. inicial adap.
pos. final adap.
trajetória adap.

Conclusoes

Neste trabalho foi apresentada uma breve revisao bibliografica de controladores visuais em robos
submarinos autonomos. Foi mostrada a gama de
marcos fiduciais e o desenvolvimento de um controlador servo visual 2 12D.
Foi observado que, no controlador visual, o
parametro de ajuste proporcional nao consegue rejeitar completamente a pertubacao constante da
corrente martima, apresentando offset no seguimento de referencia em regime_permanente. A
adocao de uma estrategia de ganho adaptativo nao
so consegue rejeitar a pertubacao como apresenta
menor tempo de acomodacao em relacao ao ganho
proporcional.
Em trabalhos futuros o controlador aqui apresentado sera embarcado no prototipo fsico e submetido a condicoes submarinas reais. Alem disso
abordagens que garantem a visibilidade do marco
em toda a duracao da tarefa serao investigadas.
Agradecimentos
O projeto FlatFish e parte de um programa em
desenvolvimento da BG Brasil. Os autores gostariam de agradecer, portanto, a BG Brasil, a Agencia Nacional de Petroleo (ANP), a Empresa Brasileira de Pesquisa e Inovacao Industrial (EMBRAPII) e a Faculdade de Tecnologia SENAI CIMATEC pelo apoio economico.

3626

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

Referencias
Albiez, J., Joyeux, S., Gaudig, C., Hilljegerdes,
J., Kroffke, S., Schoo, C., Arnold, S., Mimoso, G., Alcantara, P., Saback, R., Britto,
J., Cesar, D., Neves, G., Watanabe, T., Paranhos, P. M., Reis, M. and Kirchnery, F.
(2015). Flatfish - a compact subsea-resident
inspection auv, OCEANS 2015 - MTSIEEE
Washington, pp. 18.
Bergamasco, F., Albarelli, A., Rodola, E. and Torsello, A. (2011). Rune-tag A high accuracy
fiducial marker with strong occlusion resilience, Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on,
pp. 113120.
Brandou, V., Allais, A.-G., Perrier, M., Malis,
E., Rives, P., Sarrazin, J. and Sarradin, P.M. (2007). 3d reconstruction of natural underwater scenes using the stereovision system
iris, Oceans 2007-Europe, Vols 1-3 pp. 674
679.
Cesar, D., Gaudig, C., Fritsche, M., dos Reis,
M. A. and Kirchner, F. (2015). An evaluation of artificial fiducial markers in underwater environments, OCEANS 2015 - Genova,
pp. 16.
Chaumette, F. and Hutchinson, S. (2006). Visual
servo control. i. basic approaches, IEEE Robotics Automation Magazine 13(4) 8290.
Chaumette, F. and Hutchinson, S. (2007). Visual servo control. ii. advanced approaches
tutorial, IEEE Robotics Automation Magazine 14(1) 109118.
CODEBA (n.d.). Companhia das docas do estado
da bahia, goo.glnWRLsW. Acessado em 1104-2016.
Evans, J., Redmond, P., Plakas, C., Hamilton, K.
and Lane, D. (2003). Autonomous docking
for intervention-auvs using sonar and videobased real-time 3d pose estimation, OCEANS 2003. Proceedings, Vol. 4, pp. 2201
2210 Vol.4.

Garrido-Jurado, S., Munoz-Salinas, R. and
Madrid-Cuevas, F. (2014). Automatic generation and detection of highly reliable fiducial
markers under occlusion, Pattern Recognition
47(6) 2280  2292.
Kato, H. and Billinghurst, M. (1999). Marker
tracking and hmd calibration for a videobased augmented reality conferencing system, Augmented Reality, 1999.(IWAR99)
Proceedings. 2nd IEEE and ACM International Workshop on, IEEE, pp. 8594.
Lee, P.-M., Jeon, B.-H. and Kim, S.-M. (2003).
Visual servoing for underwater docking of an
autonomous underwater vehicle with one camera, OCEANS 2003. Proceedings, Vol. 2,
pp. 677682 Vol.2.
Malis, E., Chaumette, F. and Boudet, S. (1999). 2
frac12d visual servoing, IEEE Transactions
on Robotics and Automation 15(2) 238250.
Mohamed, B. (2012). Proposition of a 3d pattern
for e-learning augmented reality applications
based on artoolkit library, Education and eLearning Innovations (ICEELI), 2012 International Conference on, IEEE, pp. 14.
Olson, E. (2011). AprilTag A robust and flexible visual fiducial system, Proceedings of the
IEEE International Conference on Robotics
and Automation (ICRA), IEEE, pp. 3400
3407.
Plotnik, A. M. and Rock, S. M. (2006). Visual
servoing of an rov for servicing of tethered
ocean moorings, OCEANS 2006, pp. 16.
Rekimoto, J. (1998). Matrix a realtime object identification and registration method
for augmented reality, Computer Human Interaction, 1998. Proceedings. 3rd Asia Pacific, pp. 6368.
Rives, P. and Borrelly, J. J. (1997). Underwater pipe inspection task using visual servoing techniques, Intelligent Robots and Systems, 1997. IROS 97., Proceedings of the
1997 IEEERSJ International Conference
on, Vol. 1, pp. 6368 vol.1.

Feng, C. and Kamat, V. R. (2012). Augmented reality markers as spatial indices for indoor mobile aecfm applications, Proceedings of 12th
international conference on construction applications of virtual reality (CONVR 2012),
pp. 23524.

Watanabe, T., Neves, G., Cerqueira, R., Trocoli, T., Reis, M., Joyeux, S. and Albiez,
J. (2015). The rock-gazebo integration and
a real-time auv simulation, 2015 12th Latin
American Robotics Symposium and 2015 3rd
Brazilian Symposium on Robotics (LARSSBR), pp. 132138.

Fiala, M. (2005). Artag, a fiducial marker system using digital techniques, Computer Vision and Pattern Recognition, 2005. CVPR
2005. IEEE Computer Society Conference
on, Vol. 2, pp. 590596 vol. 2.

Xu, A. and Dudek, G. (2011). Fourier tag a smoothly degradable fiducial marker system with
configurable payload capacity, Computer and
Robot Vision (CRV), 2011 Canadian Conference on, IEEE, pp. 4047.

ISSN 2525-8311

3627