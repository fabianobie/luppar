XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

CPSC UM ALGORITMO DE ENXAME CONSTRUTIVO PARA AGRUPAMENTO DE DADOS

ANA KARINA F. PRIOR1, LEANDRO N. DE CASTRO1
Laboratório de Computação Natural, Faculdade de Computação e Informática e Programa de Pós-Graduação
em Engenharia Elétrica, Universidade Presbiteriana Mackenzie
Rua da Consolação 930, 01302-907, Consolação, São Paulo, SP, BRASIL
E-mails anakarina.prior@gmail.com, lnunes@mackenzie.br
Abstract
 The growing demand for information, along with the large amount of available data, has been stimulating the research in methods for text mining. This work introduces a new, constructive version of the Particle Swarm Clustering (PSC) algorithm, named cPSC (constructive PSC), which automatically determines the number of groups in a database. cPSC is applied
to a number of text mining problems and compared with other classical text clustering techniques.
Keywords
 text mining, swarm intelligence, PSC, cPSC
Resumo
 A crescente demanda por informação, aliada  grande quantidade de dados existentes tem estimulado a pesquisa em
métodos para a mineração e agrupamento_de_textos. Este trabalho tem como objetivo propor uma versão construtiva do algoritmo PSC (Particle Swarm Clustering), denominada cPSC, e mostrar que a mesma apresenta resultados relevantes na resolução de
problemas de agrupamento_de_textos, com a vantagem de encontrar automaticamente o número de grupos da base.
Palavras-chave
 .

utilizadas, além de uma análise sensitiva do algoritmo
e uma discussão sobre os experimentos realizados e
os resultados obtidos. O trabalho é concluído na Seção 5.

1 Introdução
A Internet, hoje em dia, pode ser vista como um
grande repositório de informações e recursos. Segundo Chen (2001), 80 do conteúdo que está disponível na Internet está em formato de texto. O crescimento desse grande repositório de informações e dos
mecanismos de busca tem estimulado a pesquisa em
métodos para mineração_de_textos.
A mineração_de_textos analisa documentos textuais com o objetivo de extrair padrões ou conhecimentos, interessantes e não triviais, a partir dos mesmos
(Weiss et al., 2005). A mineração_de_textos está presente em diversos sistemas utilizados no dia a dia,
como no mecanismo de busca do Google, no sistema
de recomendação de sites de comércio eletrônico
como Submarino, Amazon e TUILUX, sistemas de
classificação de spams, dentre outros.
O principal objetivo deste trabalho é o de propor
uma nova versão do algoritmo PSC (Particle Swarm
Clustering) (Cohen  de Castro 2006) que seja capaz
de detectar automaticamente o número de grupos em
um conjunto de dados. Para isso, é proposto um método dinâmico de crescimento e poda de partículas do
PSC. A fim de avaliar o desempenho deste algoritmo,
que é implementado e aplicado para agrupar duas
bases de dados textuais, as medidas de desempenho
utilizadas foram Entropia e Pureza (Zhao  Karypis,
2004) e os algoritmos utilizados para comparação
foram o k-médias (Chakrabarti, 2003) e o PSC original.
O presente documento está organizado da seguinte forma. A Seção 2 introduz o algoritmo PSC. A
Seção 3 introduz o algoritmo construtivo cPSC proposto. A Seção 4 apresenta uma breve descrição das
técnicas de mineração_de_textos e as bases de dados

2 PSC Agrupamento por Enxame de Partículas
O algoritmo de Agrupamento por Enxame de Partículas, também conhecido como PSC (Particle
Swarm Clustering) foi proposto por (Cohen  de
Castro, 2006) com o objetivo de desenvolver uma
nova ferramenta bioinspirada de agrupamento de
dados. O Algoritmo PSC é um método baseado em
Computação Natural (de Castro, 2007), mais especificamente em Inteligência de Enxame (Kennedy et
al., 2001). Ele se inspira no algoritmo PSO (Particle
Swarm Optimization) proposto por (Eberhart  Kennedy, 1995), que tem como fundamento o comportamento social humano. O PSO se baseia no princípio
de que os seres humanos tomam decisão com base na
sua experiência e também na experiência daqueles
com os quais ele interage.
Cohen e de Castro (2006) propuseram algumas
modificações no PSO com o objetivo de transformálo em uma ferramenta de agrupamento_de_dados. As
modificações propostas foram as seguintes
1.

2.

Criação e movimentação de um conjunto de
partículas no espaço dos dados de entrada, de
forma que elas se tornem protótipos de grupos naturais destes dados.
Adição de um termo de auto-organização, além dos termos social e cognitivo.

No algoritmo PSC, cada dado de entrada é apresentado ao enxame_de_partículas e a partícula com a
maior similaridade em relação ao dado de entrada
3300

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Passo 1 até que o número máximo de iterações, maxit, seja atingido.

será movida na direção dele, influenciada pela sua
melhor posição (termo cognitivo), pela posição da
partícula que esteve mais próxima do dado até o
momento (termo social) e pelo termo de autoorganização, que influencia as partículas a se moverem em direção aos dados de entrada. Esse novo termo de auto-organização é uma abordagem comumente utilizada em sistemas auto-organizados (Kohonen,
2000).
A velocidade das partículas é atualizada de acordo com a seguinte equação

O pseudocódigo do PSC é apresentado a seguir
Procedure X  PSC (dataset, maxit,
npart, , 1, 2, 3, 4, vmax, vmin)
y  dataset
Inicialize X  aleatoriamente
Inicialize vi  aleatoriamente, vi 
vmin , vmax
Inicialize dist i
t  1
Enquanto t < maxit faça,
 Calcule a similaridade entre
os documentos e as partículas
Para j  1 até N faça,  para
cada dado
Para i  1 até npart faça,
dist i(j)  similaridade (yj ,
xj )
Fim para
I  max(dist)  partícula
vencedora é selecionada (aquela
com a maior similaridade em relação aos dados de entrada)
Se f (xI) < f (pI) então
pI  xI
Fim se
Se f (xI) < f (gj) então
gj  x I
Fim se
vi(t+1) 
.vi(t)+
1(pij(t)xi(t))+
2(gj(t)xi(t))+
3(y
jx i(t))
vi  vmin , vmax 
xi(t + 1)  xi(t) + vi(t + 1)
Fim para
Para i  1 até npart do,
Se (xi ! win) então
vi(t+1) 
4(xmostwinxi(t)) vi  vmin
.vi(t)+
, vmax 
xi(t + 1)  xi(t) + vi(t + 1)
Fim se
Fim para
  0.95 * 
t  t + 1
Fim enquanto
Fim procedure
Algoritmo 1 Pseudocódigo do algoritmo PSC

2(gj(t)xi(t))
vi(t+1)  .vi(t) +
1(pij(t)xi(t)) +
j
+
3(y xi(t))
(1)
onde  é o termo de inércia que controla a
convergência das partículas, pij(t) é o vetor que
contem a melhor posição na história da particula i em
relação ao dado de entrada j gj(t) é o vetor que
contem a posição da melhor partícula até o momento
em relação ao dado de entrada j e yj é a posição do
objeto (dado de entrada) j.
A posição das partículas é atualizada de acordo
com a seguinte equação
xi(t+1)  xi(t) + vi(t+1)

(2)

Os termos 1, 2 e 3 apresentados na Equação
(1) são vetores de pesos aleatórios que exercem influência nos termos cognitivo (melhor posição individual), social (melhor posição global) e de autoorganização (distância da partícula em relação ao
objeto), respectivamente.
As partículas são movidas no espaço baseando-se
apenas na similaridade das mesmas em relação aos
dados de entrada e sem utilizar informação alguma de
custo ou qualidade da solução, o que permite que o
PSC seja caracterizado como um algoritmo nãosupervisionado.
A cada iteração os seguintes passos são executados
1.

Para cada objeto de entrada, a partícula vencedora i é selecionada (ou seja, aquela que
possuir uma maior similaridade em relação
ao dado de entrada) dentre todas as partículas
do enxame.

2.

A partícula selecionada é utilizada para atualizar os termos social, cognitivo e de autoorganização.

3.

É verificado se existem partículas que não
venceram durante a iteração. A velocidade
dessas partículas será atualizada na direção
da partícula que mais venceu (xmostwin) nessa
iteração. Isso é feito para evitar que as partículas fiquem estagnadas.

4.

Atualiza-se o termo de inércia e retorna ao

Em tarefas de agrupamento_de_textos normalmente trabalha-se com um conjunto de dados textuais
com um grande número de atributos. Esse conjunto
de dados deve ser representado no modelo de Espaço
Vetorial (Salton et al., 1975, Gravano et al., 1999),
onde o conteúdo de cada documento é formalizado
como um ponto num espaço multidimensional e representado por um vetor u  w1 , w2, ..., wn e wi, i 
1, 2, ..., n é o peso do termo no documento.
Para obter melhores resultados de agrupamento
de textos o termo de inércia deve ter uma influência
em todos os termos da equação da seguinte maneira

3301

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

la é considerada a partícula mais estimulada e é clonada senão a quantidade de partículas permanece
inalterada (de Castro et al., 2003). O processo de
crescimento das partículas é verificado a cada  iterações, sendo   2 por definição.
Se a partícula candidata é clonada, a nova partícula gerada recebe os valores da média entre a posição
da partícula e do documento que possui maior afinidade a ela.

vi(t+1)  .vi(t) +
1(pij(t)xi(t)) +
2(gj(t)xi(t))
j
(3)
+
3(y xi(t)) 
Com o objetivo de utilizar o algoritmo PSC para
trabalhar com agrupamento_de_textos deve-se utilizar
a medida do Cosseno para calcular a similaridade
entre os documentos e as partículas do enxame.
A medida do Cosseno é muito conhecida na literatura e bastante aplicada a problemas de agrupamento_de_textos. De forma resumida, ela calcula o produto interno dos vetores normalizados. A seguinte equação ilustra a medida do Cosseno

3.2 Poda das partículas
O processo de poda das partículas verifica o nível
de concentração das partículas. Se uma partícula p
possui seu nível de concentração igual a zero por
uma quantidade de iterações maior do que um limiar
pré-definido, então esta partícula pode ser eliminada.

similaridade(za,z)  cos(za,z)  (zaz)(za2*z2)
(4)
onde za e z são vetores, z2 é a norma Euclidiana do
vetor z, e zaz corresponde ao produto interno dos
vetores za e z.

3.3 Critério de parada
O critério de parada verifica se em uma janela de
 iterações a diferença da soma das partículas é menor do que 0.01 nesses casos o algoritmo encerra a
execução.
O pseudocódigo do cPSC é apresentado a seguir

3 cPSC Constructive PSC
O algoritmo cPSC (Constructive Particle Swarm
Clustering) tem como principal objetivo detectar
automaticamente o número de grupos existentes em
uma base de dados, ao contrário do PSC que recebe
esse valor como parâmetro de entrada (npart). Para
que isso seja possível, o cPSC emprega uma estratégia de duplicação e poda de partículas. Essa estratégia segue os mesmos princípios que o PSC com a
adição de três novas funções inspiradas na rede neuroimune ABNET (AntiBody NETwork) (de Castro,
2003)
1.
2.
3.

Procedure X  cPSC (dataset, maxit,
npart, , 1, 2, 3, vmax, vmin, , )
y  dataset
Inicialize aleatoriamente uma partícula no enxame
Inicialize vi  aleatoriamente, vi 
vmin , vmax
Inicialize dist i
t  1
Enquanto o critério de convergência
não foi satisfeito faça,
 Calcule a similaridade entre
os documentos e as partículas
Para cada dado faça,
Para i  1 até npart faça,
dist i(j)  similaridade (yj ,
xj )
Fim para
I  max(dist)  partícula
vencedora é selecionada
(aquela com a maior similaridade em relação aos
dados de entrada)
Se f (xI) < f (pI) então
pI  xI
Fim se
Se f (xI) < f (gj) então
gj  x I
Fim se
vi(t+1) 
.vi(t)+
1(pij(t)xi(t))+
2(gj(t)xi(t
3(yjxi(t))
))+
vi  vmin , vmax 
xi(t + 1)  xi(t) + vi(t + 1)
Fim para
Se a iteração é múltipla de ,
então
Cresça se necessário

Crescimento (clonagem) de partículas
Poda de partículas
Critério de parada.

Alem das três funções também são introduzidos
dois novos parâmetros, o parâmetro  e o limiar de
afinidade , que exercem influência no crescimento
das partículas. O limiar de afinidade  é uma constante obtida empiricamente a partir de um conhecimento
sobre a afinidade média da base de dados.
Os três novos processos do algoritmo são descritos a seguir.
3.1 Crescimento das partículas
Durante a execução do algoritmo é determinado o
nível de concentração de cada partícula, ou seja, o
número de documentos que essa partícula reconhece.
Quando o nível de concentração da partícula for maior que um, ela se torna candidata a ser clonada. A
partícula que possuir o maior nível de concentração
será escolhida como candidata.
Se a afinidade da partícula candidata em relação
ao documento que possui maior afinidade a ela for
maior do que o limiar de afinidade , então a partícu-

3302

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Fim se
Se o nível de concentração de uma
particular é zero então
Elimine a partícula do enxame
Fim se
  0.95 * 
 Verifica o critério de parada
t  t + 1
Fim enquanto
Fim procedure
Algoritmo 2 Pseudocódigo do algoritmo cPSC

P(Sr)  1 max(n i ) .
r
nr i
A pureza global pode ser definida como
Pglobal 

r 1

E (S r ) .

(8)

Para avaliar o desempenho do cPSC, PSC e do kmédias, três bases de dados públicas e rotuladas foram escolhidas. A primeira foi a base Reuters-21578
(Lewis et al., 2004) compilada por David Lewis e originalmente recolhida pelo Grupo Carnegie de notícias da Reuters em 1987. Esses dados são normalmente empregados levando em conta os documentos
das classes mais frequentes, como, por exemplo, das
115, 90, ou 10 categorias mais frequentes (Sebastiani, 2002 Joachims, 1997). Nos experimentos a serem
relatados aqui, foram obtidos os textos das 10 categorias mais frequentes, mais conhecidas como earn,
acquisition, money-fx, grain, crude, trade, interest,
ship, wheat e corn, totalizando 7193 documentos.
Para avaliar o desempenho dos algoritmos em relação a um aumento na base de dados textuais, a base
foi dividida em três subamostras com 500, 1000 e
2000 melhores atributos, selecionados como aqueles
de maior ganho de informação, onde cada subamostra
contém o número de categorias da coleção, isto é, 10
categorias.
A segunda base de dados utilizada neste trabalho
foi a Spambase (UCI Repository of Machine Learning
Databases) recolhida por George Forman. Esta base
contem 4601 instâncias de e-mails com 48 atributos,
nos quais 1813 são spam e 2788 não são. A coleção
de e-mails foi feita através de um postmaster e alguns
indivíduos que contribuíram de forma independente
a coleção de e-mails que não eram spam veio de emails pessoais e de trabalho. Os anúncios de produtos
eou sites da Internet, sistemas de fazer dinheiro rápido, correntes e pornografia foram considerados spam.
Essa base de dados já estava pré-processada.
A terceira base de dados utilizada foi a 20 Newsgroups recolhida por Ken Lang (Lang, 1995). Esta
base contém aproximadamente 20.000 emails de notícias particionados em 20 grupos. Estes dados foram
empregados levando em conta os documentos das
classes
rec.autos,
rec.motorcycles,
rec.sport.baseball, rec.sport.hockey. Além disso, a
base foi dividida em uma subamostra com os 500
melhores atributos, selecionados como aqueles de
maior ganho de informação.

onde c é o numero de classes no conjunto de documentos, e nri é o número de documentos da classe i
no cluster Sr. A entropia global pode ser calculada
como a soma das entropias de cada cluster, ponderadas pelo tamanho de cada cluster
nr

P( S r ) .

4.2 Bases de Dados

Não é sempre que os bancos de dados textuais
possuem dados estruturados. Com o objetivo de extrair conhecimento de um conjunto de dados textuais
não estruturados devem-se utilizar algumas técnicas
de pré-processamento de textos, de forma que ao
final do processo obtenha-se um conjunto estruturado
de dados pronto para ser utilizado nos algoritmos de
agrupamento. Os seguintes passos de préprocessamento de textos foram utilizados nesse trabalho 1) tokenização 2) remoção de stopwords 3)
stemming 4) cálculo das medidas tf-idf 5) geração
do dicionário 6) seleção de atributos pelo ganho de
informação 7) comparação de documentos e 8) agrupamento (Weiss et al., 2005).
Para avaliar o desempenho da ferramenta proposta neste trabalho, foram utilizadas as métricas de Entropia e Pureza. A Entropia e a Pureza são medidas
de avaliação amplamente utilizadas na literatura para
avaliar o desempenho de algoritmos de agrupamento,
desde que conheçamos a priori os grupos da base de
dados (apenas para efeito de benchmarking) (Crabtree et al., 2005), (Zhao e Karypis, 2004).
A entropia define a homogeneidade dos grupos
formados, ou seja, de que forma as classes de documentos estão distribuídas em cada cluster, sendo que
baixa entropia indica clusters mais homogêneos. Dado um cluster Sr de tamanho nr, a entropia E(Sr) do
cluster pode ser medida da seguinte maneira
i
i
k
nr
n
E(Sr)   1
(5)
log r .

log c i 1 n r
nr

c

nr

onde nr é definido acima.
Uma solução de agrupamento ideal será aquela
que apresenta documentos de uma única classe dentro
de cada cluster fazendo com que a entropia seja igual
a zero e a pureza seja igual a um.

4.1 Mineração de Textos Materiais e Métodos

n

c

n
r 1

4 Avaliação de Desempenho

Eglobal 

(7)

(6)

A pureza fornece a razão da classe dominante no
cluster em relação ao tamanho do mesmo. Valores de
pureza próximos a um indicam um subconjunto puro
da classe dominante no grupo. A pureza pode ser
calculada da seguinte maneira

3303

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Tabela 3. Número de partículas, Entropia e Pureza para diferentes
valores de .

As Tabelas 1 e 2 mostram as informações referentes ao número de tokens e documentos das bases
Reuters e 20 Newsgroups.


Número de
partículas
Entropia
Pureza

Tabela 1. Número de documentos nas dez maiores classes da base
Reuters (RE) número total de documentos (NTD) utilizados em
cada subamostra número de tokens em cada dicionário gerado
(NT).
Categoria

1
2
3
4
5
6
7
8
9
10
NTD
NT

500
1649

1000
1649

2000
1649

181

181

181

389

389

389

2877

2877

2877

433

433

433

347

347

347

538

538

538

197

197

197

369

369

369

212

212

212

7192
500

7192
1000

7192
2000

0,3

0,5

15

5

4

0.220.02
0.780.02

0.460.06
0.700.04

0.640.06
0.640.01

Para avaliar a influência do termo de inércia ()
no tamanho do enxame e no número de iterações para
convergência três valores foram escolhidos  
0.09, 0.5, 0.95. Os resultados são apresentados na
Tabela 4. Foi possível observar que o termo de inércia () exerce pouca influência no número de partículas do enxame, mas exerce uma grande influência no
número de iterações para convergência.
Tabela 4. Número de partículas, Entropia, Pureza e número de
iterações para diferentes valores de .


Número de
partículas
Entropia
Pureza
Iterações

Tabela 2. Número de documentos nas quatro classes da base 20
Newsgroups (20N) utilizadas nas simulações número total de
documentos (NTD) utilizados em cada subamostra número de
tokens em cada dicionário gerado (NT).
Categoria
1
2
3
4
NTD
NT

0,1

500
977
989
985
996
3947
500

0.09

0.5

0.95

15

18

21

0.220.02
0.780.02
140

0.200.01
0.790.01

0.180.02
0.800.01

175

190

O parâmetro  controla o crescimento do enxame
e exerce uma grande influência no número de iterações para convergência. Valores altos de  resultam
em um maior tempo de convergência. Foi possível
observar que o parâmetro  não exerce influência nos
valores de Entropia e Pureza.
Esta análise simplificada permite sugerir a seguinte configuração de parâmetros para a aplicação genérica do algoritmo
o Limiar de afinidade entre as partículas e os
dados   0,1
o Termo de inércia   0,09
o Parâmetro do crescimento do enxame   2.
Os seguintes parâmetros foram utilizados para executar o algoritmo cPSC   0,09,   2, vmax  0,1, 1,
2, 3  0, 1.
Foi possível observar também que  é sensível ao
tamanho da base de dados. Para realizar as simulações o parâmetro  foi ajustado com diferentes valores para cada base, tal que o algoritmo conseguisse
detectar um número ideal de grupos em cada base de
dados que fosse próximo ao número real de grupos
da base.

4.3 Análise de Sensibilidade
A aplicação do cPSC ao problema de agrupamento_de_textos requer a definição dos seguintes parâmetros , , vmax, 1, 2, 3 e do limiar de afinidade .
Esta seção apresenta uma breve discussão de como os
principais parâmetros do algoritmo cPSC foram escolhidos para realizar as simulações.
Com o objetivo de estudar a influência desses
parâmetros no desempenho do cPSC, uma análise
sensitiva simplificada do algoritmo foi realizada,
aplicando o mesmo a base Reuters com 500 atributos.
Foram realizadas dez simulações e os resultados
apresentados nas tabelas a seguir mostram a média e
o desvio padrão de dez execuções. As simulações
foram executadas utilizando os seguintes parâmetros
  0.1,   0.09,   2, vmax  0.1, 1, 2, 3  0
1, variando de acordo com cada análise.
A Tabela 3 mostra que o parâmetro  influencia a
especificidade das partículas e, assim, o número final
de partículas no enxame quanto maior o valor de ,
menor o número de partículas no enxame e viceversa. Foi possível observar que um aumento no número de partículas no enxame (valores menores de )
resultou em melhores valores de Entropia e Pureza.

4.4 Resultados
Como o algoritmo cPSC define automaticamente
o número de grupos da base de dados (k do k-médias
e o número de partículas do PSC), ele foi executado
primeiro, depois calculou-se a média do número de
iterações e do número de grupos encontrados pelo
algoritmo e os mesmos foram adotados como o valor
3304

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

teve um desempenho melhor, em média, do que o
PSC e o K-Médias.
Em relação ao percentual de classificação incorreta, para a base Reuters, os algoritmos cPSC e PSC
tiveram um desempenho semelhante, já o K-Médias
teve um desempenho inferior. Para as bases Spambase e 20 Newsgroups o algoritmo cPSC encontrou as
menores percentuais de classificação incorreta.
É importante ressaltar que apesar de ter resultados similares ao PSC, o algoritmo cPSC detecta automaticamente o número de grupos da base de dados.
No caso dos algoritmos PSC e K-Médias o número
de grupos que devem ser encontrados na base de dados é definido pelo usuário. Em geral, os resultados
mostram que os algoritmos são razoavelmente robustos em relação ao seu desempenho.
Para avaliar a significância estatística da diferença de desempenho dos algoritmos uma análise de
variância (teste ANOVA) foi realizada. Para todos os
resultados (Reuters 500, Reuters 1000, Spambase e
20 Newsgroups), com exceção dos valores de Entropia encontrados para a base Reuters com 2000 atributos, a hipótese nula não pode ser rejeitada, o que significa que os valores de Entropia e Pureza são equivalentes, apesar de, na maioria dos casos, o desempenho absoluto do cPSC ter sido superior. Para os
resultados de Entropia da base Reuters com 2000
atributos foi possível concluir que o algoritmo cPSC
teve um melhor desempenho. Mesmo assim, ao analisarmos os desempenhos de melhor e pior caso, verificamos uma superioridade em termos de qualidade
da solução quando comparado aos outros algoritmos.

de k do K-Médias, o número de partículas do PSC, e
o número de iterações do PSC executado posteriormente. Isso é feito para que a comparação entre os
algoritmos considere os resultados de agrupamentos
encontrados para o mesmo número de grupos. Para
cada subamostra foram realizadas dez simulações
para cada algoritmo. Os resultados apresentados nas
tabelas a seguir mostram a média e o desvio padrão
de dez execuções para cada base de dados e algoritmo e cada medida de avaliação considerada.
Tabela 5. Média  desvio padrão das medidas de Entropia (E),
Pureza (P) e Percentual de Classificação Incorreta (CI) dos algoritmos cPSC, PSC e k-médias aplicados a base Reuters.

Reuters
cPSC

PSC
KMédias

E
P
CI
E
P
CI
E
P
CI

500
0,220,02
0,780,02
22,072,17
0,220,01
0,780,02
22,431,73
0,230,01
0,760,02
23,392,23

1000
0,220,01
0,780,02
22,011,39
0,220,01
0,780,03
22,122,50
0,230,01
0,770,02
23,472,08

2000
0,210,02
0,790,03
21,222,54
0,220,01
0,780,01
21,810,86
0,230,02
0,770,03
23,372,58

Tabela 6. Média  desvio padrão das medidas de Entropia (E),
Pureza (P) e Percentual de Classificação Incorreta (CI) dos algoritmos cPSC, PSC e k-médias aplicados a base Spambase.
Spambase
cPSC

PSC

K-Médias

E
P
CI
E
P
CI
E
P
CI

0,440,14
0,740,05
25,454,68
0,470,02
0,730,03
27,383,17
0,470,03
0,700,04
29,714,15

Tabela 8. Melhor resultado de Entropia e Pureza encontrado para
cada base de dados.
Melhor Resultado

Tabela 7. Média  desvio padrão das medidas de Entropia (E),
Pureza (P) e Percentual de Classificação Incorreta (CI) dos algoritmos cPSC, PSC e k-médias aplicados a base 20 Newsgroups.

20 Newsgroups
E
cPSC
P
CI
E
PSC
P
CI
E
K-Médias
P
CI

500
0,210,09
0,910,07
8,636,95
0,220,08
0,900,10
10,379,87
0,280,10
0,840,11
16,4211,63

Entropia

Algoritmo

Pureza

Algoritmo

Reuters 500

0.19

cPSC

0.81

cPSC

Reuters 1000

0.19

cPSC

0.81

cPSC

Reuters 2000

0.18

cPSC

0.83

cPSC

Spambase

0.23

cPSC

0.83

cPSC

20Newsgroups

0.17

PSC

0.95

PSC

Tabela 9. Melhor resultado de Entropia e Pureza encontrado para
cada base de dados.
Pior Resultado
Entropia

É possível observar que todos os algoritmos tiveram um desempenho similar em termos de Entropia e
Pureza. Observando os resultados apresentados nas
Tabelas 5 e 7 o algoritmo cPSC e o algoritmo PSC
tiveram um desempenho semelhante, em média, seguidos pelo K-Médias com resultados inferiores. Na
Tabela 6 é possível observar que o algoritmo cPSC

3305

Algoritmo
PSC
K-Médias
PSC
K-Médias

Pureza

Algoritmo

0.72

K-Médias

0.73

PSC
K-Médias

Reuters 500

0.25

Reuters 1000

0.25

Reuters 2000

0.27

K-Médias

0.72

K-Médias

Spambase

0.74

cPSC

0.62

K-Médias

20Newsgroups

0.47

cPSC

0.70

K-Médias

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

A Figura 1 ilustra o crescimento do enxame em
uma execução típica do algoritmo cPSC aplicado a
base de dados Reuters 500. O número de partículas
vai aumentando de duas em duas iterações devido ao
parâmetro  ter sido definido como   2. A partir da
quadragésima iteração o algoritmo estabiliza até satisfazer o critério de parada.

As Tabelas 8 e 9 mostram os melhores e piores
valores absolutos de Entropia e Pureza encontrados
para cada base de dados.
O algoritmo cPSC obteve melhores resultados absolutos de Entropia e Pureza para as bases Reuters
(todas as amostras) e Spambase. O algoritmo KMédias obteve a maioria dos piores resultados. Para
os resultados de Entropia e Pureza da base Reuters
1000 e Entropia da base Reuters 500 o algoritmo KMédias e o PSC obtiveram os mesmos piores valores.
Apenas para o pior valor de Entropia da base Spambase e 20Newsgroups o cPSC obteve o pior resultado.
É possível observar que o algoritmo cPSC obteve
o melhor e o pior resultado de Entropia para a base
Spambase. Isso pode ser explicado pelo fato de que
como ele detecta automaticamente o número de grupos na base de dados, esse número pode variar de
uma execução para outra. Por exemplo, em uma determinada execução ele pode encontrar dois grupos
na base Spambase e na execução seguinte ele pode
encontrar três grupos. Essa pequena variação no número de grupos encontrados pode alterar o valor de
Entropia e Pureza. Encontrando um maior número de
grupos na base de dados o resultado de Entropia pode
melhorar já que os grupos encontrados podem ser
mais homogêneos.
De acordo com a Tabela 10, o algoritmo cPSC
encontrou um número razoável de partículas próximo
ao número real de grupos de cada base de dados.

5 Conclusão e Perspectivas Futuras
Este trabalho teve como principal objetivo propor
um novo algoritmo de agrupamento_de_textos baseado no PSC. O algoritmo proposto, denominado de
cPSC (Constructive Particle Swarm Clustering) tem
como objetivo principal detectar automaticamente o
número de grupos na base de dados e segmentar os
dados em diferentes grupos representativos dos grupos naturais da base.
Os resultados encontrados sugerem que o algoritmo cPSC é apropriado para resolver problemas de
agrupamento_de_textos. Apesar de encontrar resultados similares, em média, ao algoritmo PSC, o algoritmo proposto tem a grande vantagem de detectar
automaticamente o número de grupos da base de dados, o que é definido manualmente tanto no algoritmo PSC quanto no K-Médias.
Os trabalhos futuros incluem testes comparativos
com outros algoritmos, testes com outras bases de
dados, utilização de medidas alternativas de avaliação e análise assintótica de complexidade dos algoritmos.

Tabela 10. Média, maior valor (max), menor valor (min) e desvio
padrão das partículas encontradas pelo algoritmo cPSC encontrados para cada base de dados.

Agradecimentos

Quantidade de Partículas
Média

Max

Min

Desvio

Reuters 500

15

16

13

0,92

Reuters 1000

15

16

12

1,27

Reuters 2000

15

16

15

0,23

Spambase

3

6

2

1,17

20Newsgroups

4

4

3

0,32

Os autores agradecem ao CNPq, ao Mackenzie e
ao Mackpesquisa pelo apoio.
Referências Bibliográficas
Crabtree, D., X. Gao, and P. Andreae, Universal
Evaluation Method for Web Clustering Results,
Technical Report of Victoria University of Wellington, (2005).
Chakrabarti, S., Mining the Web  Discovering
Knowledge from Hypertext Data, Morgan
Kaufmann, (2003).
Chen, H., Knowledge Management Systems A Text
Mining Perspective. University of Arizona
(Knowledge Computing Corporation), Tucson,
Arizona, 2001.
Cohen, S. C. M. de Castro, L. N. Data Clustering
with Particle Swarms. In International Conference on Evolutionary Computation, Proceedings of World Congress on Computational Intelligence, pp. 6256-6262, 2006.
de Castro, L. N. Von Zuben, F. J. de Deus Jr, G.
The construction of a Boolean competitive
neural network using ideas from immunology.

Figura 1. Crescimento do enxame em uma execução do algoritmo
cPSC aplicado a base de dados Reuters 500.

3306

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Neurocomputing (Amsterdam), v. 50, p. 51-85,
2003.
Gravano, L. Garcia-Molina, H. Tomasic, A. Gloss
Text-source discovery over the internet. ACM
Transactions on Database Systems, 24(2)229264, June 1999.
Joachims, T., Text Categorization with Support Vector Machines Learning with Many Relevant
Features, Proceedings of ECML-98, 10th European Conference on Machine Learning, pp.137142, (1998).
Kennedy, J Eberhart, R., Particle Swarm Optimization. In Proceedings of the IEEE International
Conference on Neural Networks, Vol. 4, IEEE
Press, USA, 1995, pp. 1942-1948, (1995).
Kennedy, J. Eberhart, R. and Shi, Y.. Swarm Intelligence, Morgan Kaufman Publishers, (2001)
Kohonen, T. Self-Organizing Maps, Springer-Verlag,
2000.
Lang, K. Newsweeder Learning to filter netnews. In
Proceedings of the Twelfth International Conference on Machine Learning, pages 331339,
1995.
Lewis, D. Reuters-21578 Text Categorization Text
Collection,
2004.
Disponível
em
<
httpdit.unitn.itmoschittcorpora.>. Acesso
em 8 mar. 2010.
Sebastiani, F. Machine learning in automated text
categorization. ACM Computing Surveys,
34(1), pp. 1-47, 2002.
UCI Repository of Machine Learning Databases, On
line
Datasets,
Disponível
em
<httparchive.ics.uci.edumldatasetsSpambas
e>. Acesso em 8 mar. 2010.
Weiss, S. Indurkhya, N. Zhang, T. Damerau, F.
Text Mining Predictive Methods for Analyzing
Unstructured Information, Springer, 2004.
Zhao, Y., and Karypis, G. Empirical and Theoretical
Comparisons of Selected Criterion Functions
for Document Clustering, Machine Learning
55(3), pp. 311-331 (2004).

3307