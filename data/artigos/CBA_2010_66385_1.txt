XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

ESTIMACAO DE PARAMETROS EM SISTEMAS LINEARES SUJEITOS A SALTOS
MARKOVIANOS COM ALGORITMOS DE FILTRAGEM SUB-OTIMOS
Pedro Grunauer Kassab, Oswaldo Luiz do Valle Costa


Laboratorio de Automacao e Controle
Escola Politecnica da Universidade de Sao Paulo


Laboratorio de Automacao e Controle
Escola Politecnica da Universidade de Sao Paulo
Emails pedro.kassab@poli.usp.br, oswaldo@lac.usp.br
Abstract This paper proposes a methodology for the identification of Markov-jump linear systems. Given
a sequence of noisy observations of the state variable, our objective is to estimate it along with the (unknown)
parameters that drive the system in the state-space. As it is well known, the optimal filtering in this class of
systems requires exponentially increasing computing power, in proportion to the sample size, and is not feasible
in practice. We resort, therefore, to a sub-optimal algorithm, whose results are used for a maximum likelihood
identification according to the methodology presented here. Simulations demonstrate a very good convergence.
Keywords Discrete time, Markov jump linear systems, parameter estimation, maximum likelihood, suboptimal filtering
Resumo Este trabalho propoe uma metodologia de identificacao para sistemas_lineares sujeitos a saltos
markovianos. Dada uma sequencia de observacoes ruidosas da variavel de estados, busca-se estima-la juntamente
com os parametros (desconhecidos) que descrevem o sistema_dinamico no espaco_de_estados. Como e bem
conhecido, a filtragem_otima nesta classe de sistemas tem requisitos computacionais exponencialmente crescentes
em funcao do tamanho da amostra, e torna-se inviavel na pratica. Recorre-se, portanto, a um algoritmo sub-otimo
de filtragem, cujos resultados sao utilizados na identificacao por maxima_verossimilhanca segundo a metodologia
apresentada. Simulacoes realizadas demonstram muito boa convergencia.
Palavras-chave 

1

cabilidade pratica destes modelos. Com efeito,
esta questao foi analisada em algumas publicacoes como Tugnait (1982), Hamilton (1990), Baccarelli and Cusani (1996) e Elliott and Krishnamurthy (1999), mas constitui ainda uma questao
em aberto. Isto se deve ao fato de o problema
de identificacao ser indissociavel do problema de
filtragem, que esta sujeito a complicacoes computacionais importantes, como se vera na secao 2.4.1.
Isto levou ao desenvolvimento de um grande
numero de estimadores sub-otimos, com distintas
razoes entre custo_computacional e desvio em relacao ao otimo. Os algoritmos mais amplamente utilizados sao o IMM (Blom and Bar-Shalom, 1988),
o GPB (Bar-Shalom and Li, 1993), e o algoritmo
linear (Costa, 1994). Mais recentemente, utilizamse tambem algoritmos baseados em simulacoes,
como os filtros de partculas (Doucet et al., 1999).
Todos estes algoritmos apresentam desvios em relacao ao algoritmo otimo. Para alguns destes algoritmos (IMM e GPB), nao ha (no conhecimento
dos autores) uma demonstracao formal na literatura de que se trata de estimadores nao-viesados,
sendo os mesmos apenas truncamentos do algoritmo otimo.
Trata-se de um problema complexo, para o
qual ainda nao ha solucoes satisfatorias na literatura que sejam de conhecimento dos autores.
O que se pretende apresentar neste estudo e uma
metodologia pratica de estimacao dos parametros

Introducao

Os sistemas_lineares_sujeitos_a_saltos_markovianos
(Markov-Jump Linear Systems, em ingles) representam uma alternativa bastante pratica para modelar sistemas_estocasticos cujos parametros variem no tempo. Trata-se de formular uma representacao em termos de um sistema linear no espaco_de_estados, cujos parametros sejam funcao
de um outro processo estocastico, possivelmente
nao observavel diretamente. Postula-se que o processo de que dependem os parametros do sistema
no espaco_de_estados seja uma cadeia de Markov.
Desta forma, busca-se reproduzir as caractersticas de sistemas sujeitos a mudancas repentinas em
seu modo de funcionamento.
Esta classe de modelos tem sido objeto de um
grande numero de estudos, entre os quais e possvel destacar Bar-Shalom and Li (1993), Costa
et al. (2005), Hamilton (1994) e Elliott et al.
(1995) como textos de referencia. Estes modelos foram aplicados com sucesso a diversos casos
de interesse pratico, especialmente em aplicacoes
como o rastreamento_de_alvos em manobra, controle_de_sistemas sujeitos a falhas, modelagem de
variaveis economicas sujeitas a alteracoes conjunturais, alem de outros sistemas de natureza analoga.
O problema de identificacao nesta classe de
sistemas e um aspecto fundamental para a apli-

788

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

desconhecidos do sistema por meio do metodo de
maxima_verossimilhanca, com base em uma filtragem realizada por estimadores sub-otimos. Uma
prova de convergencia esta fora do escopo deste
artigo, mas a convergencia dos parametros sera
evidenciada em simulacoes numericas ilustrativas.

2
2.1

Desenvolvimentos preliminares

Notacao

Utilizam-se neste texto, salvo mencao explcita em
contrario, letras latinas maiusculas (A, B) para
denotar conjuntos. Com letras maiusculas em negrito (C, D), representam-se transformacoes lineares Rm  Rn , onde Rm e Rn sao espacos vetoriais sobre o corpo de escalares R. As letras
minusculas em negrito (x, y) fazem referencia aos
vetores, elementos de Rp . Os termos em fonte
Fraktur (F, S) fazem referencia a -campos.

A abordagem deste estudo difere daquela
apresentada por Tugnait (1982) (o principal tratamento do tema ate o momento), que utiliza o
algoritmo otimo de filtragem em uma janela da
sequencia observada. O metodo do trabalho citado consome recursos computacionais exponencialmente crescentes com o tamanho da amostra,
de forma que so e possvel realizar a estimacao
com base em um numero reduzido de observacoes
- quatro, no estudo original. Alem disto, Tugnait
(1982) considera apenas o caso em que os parametros pertencem a um conjunto finito e discreto
de possibilidades, conhecidas ex ante. Pretendese, aqui, aplicar o estimador de maxima_verossimilhanca a diversos parametros do sistema no
espaco_de_estados, simultaneamente, sem estabelecer um conjunto universo finito para as possibilidades. Isto seria inviavel no metodo de Tugnait
(1982) devido ao numero reduzido de amostras
consideradas. O metodo proposto aqui pretende
utilizar um filtro sub-otimo aplicado a totalidade
da serie observada (sem truncamentos) ao inves
de utilizar uma estimacao otima em um pequeno
subconjunto da amostra.

2.2

Definicoes

Considere-se um espaco de probabilidades
(, F, P ).
Sejam (x(t))tN , (y(t))tN , ((t))tN processos estocasticos tais que x(t)  Rp , y(t)  Rq e
(t)  M  N+ para todo t.
Sejam dois processos (v(t)) e (w(t)) independentes, com (v(t)) e (w(t)) i.i.d., seguindo uma
distribuicao normal com variancia unitaria e media nula. Seja (t) uma cadeia de Markov em
tempo_discreto com espaco_de_estados M e matriz de transicao P. Assume-se que  (t) seja uma
cadeia de Markov nao-periodica e irredutvel.
Defina-se (Yt )tN , uma sequencia de filtragens
de um processo (de estados) conjunto (x(t), (t)),
decorrentes do conhecimento das realizacoes observadas de y(t). Segue que
Yt  (y(1  t)).

Mais recentemente, em (Doucet and Ristic,
2002), (Jilkov and Li, 2004) e (Orguner and Demirekler, 2008), apresentam-se propostas de filtros
adaptativos para estimacao das probabilidades de
transicao entre modos, dado que sejam conhecidos os demais parametros dinamicos do sistema,
sem a restricao de que pertencam a um numero
finito de possibilidades conhecidas. Como observa
(Orguner and Demirekler, 2008), houve poucos
avancos no tema de identificacao desta classe de
sistemas desde Tugnait (1982), mas este voltou
recentemente a ser um tema bastante ativo. Este
estudo pretende apresentar uma contribuicao no
campo da identificacao_de_sistemas_lineares_sujeitos_a_saltos_markovianos.

e a filtragem gerada por y(1  t)
2.3

Especificacao estocastica dos SLSM

A classe de sistemas_lineares_sujeitos_a_saltos_markovianos em tempo_discreto e descrita pelas seguintes equacoes de diferencas
x (t)
y (t)

 A(t) x (t  1) + F(t) v (t)
 C(t) x (t) + G(t) w (t)

(1a)
(1b)

em que Ai , Ci , Fi e Gi sao matrizes de dimensoes
apropriadas. Sejam Ai e Gi matrizes quadradas.
Na forma funcional exposta em 1, explicitase a dependencia das matrizes A, C, F e G (que
descrevem a dinamica do sistema no espaco_de_estados) com relacao ao processo estocastico ((t)).
Deste modo, associa-se a cada possvel (t)  i
uma quadra de matrizes Ai , Ci , Fi e Gi , que regulara tanto a equacao de estados quanto a equacao
de sadas. Este e, portanto, um caso de sistema
linear a parametros variantes no tempo. A variacao temporal destes parametros, por sua vez, esta
condicionada pelo processo ((t)), governado pela
matiz de transicao P.
Considerando-se que w (t) e v (t) tem distribuicoes conhecidas, chame-se esta distribuicao de

As conclusoes demonstrarao que, dado que
a aproximacao do filtro sub-otimo seja razoavelmente proxima, e possvel obter boas estimativas
dos parametros, de forma que se permitiria um
desempenho adequado de um sistema de rastreamento e controle associado ao filtro_adaptativo.
Isto abre espaco para a aplicacao desta classe de
modelos em muitos casos de interesse pratico em
que nao se conhecam a priori os parametros que
regem o sistema em questao, ou em casos em que
estes possam variar no tempo.

789

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

, tal que

condicionando-se tambem ao conhecimento (que
se presumiu) de  e . A matriz Qpq e a matriz de covariancia do erro de estimacao associado
a estimativa xpq . Iniciando-se com uma estimativa inicial arbitraria para x00 e Q00 , iteram-se
as equacoes para k  1, 2, . . .

  N (0, I)
onde I e a matriz identidade de dimensao adequada.
Conforme o valor do processo estocastico
( (t)) no instante t, escolhe-se um conjunto
(Ai , Ci , Fi , Gi ) dos possveis (A1 , C1 , F1 , G1 ),
(A2 , C2 , F2 , G2 ), . . . , (AM , CM , FM , GM ).
Denomine-se, entao, esta colecao de parametros
(a qual se soma tambem a matriz de transicao P,
que tambem nao e necessariamente conhecida)

 ,
(A1 , C1 , F1 , G1 ) ,
(A2 , C2 , F2 , G2 ) , . . . ,
(AM , CM , FM , GM )  P

Qkk1  Ak Qk1k1 A0k + Fk F0k
1
Kk  Qkk1 C0k Ck Qkk1 C0k + Gk G0k
xkk1  Ak xk1k1

xkk  xkk1 + Kk y(k)  Ck xkk1
Qkk  (I  Kk Ck ) Qkk1

O problema de filtragem diz respeito a estimacao de processos estocasticos nao observados, com
base no conhecimento de um outro processo que
guarda alguma forma de correlacao com aquele.
Contextualizando-se o sistema definido em 1 a luz
da teoria de filtros, chame-se x sinal w, rudo
y, processo observado. O problema se define pela
otimizacao do valor esperado de alguma funcao
(chamada funcao-objetivo) do erro de estimacao,
sendo a mais comum a media quadratica dos erros.
E nesta acepcao que se entende aqui o problema
de filtragem.
Considera-se, primeiramente, o problema de
filtragem, isoladamente. Para isto, supoe-se que
os parametros  sejam conhecidos, e que a cadeia
de Markov  seja observavel diretamente. Os resultados desta analise serao utilizados na sequencia para deduzir a estimacao_de_parametros.

onde a ultima passagem segue da definicao 2, e
se garante pela propriedade de otimalidade do filtro de Kalman (vide, por exemplo Simon (2006)).
Alem disto,


0
E y (k) y (k) Yk1 , (1  k)  

 E (Ck x (k) + Gk w (k)) 
0

(Ck x (k) + Gk w (k)) Yk1 , (1  k) 
 Ck Qkk1 C0k + Gk G0k

Portanto,
y (k)  Ck xkk1  N (0, k )
e
 21

k

Considerando-se o sistema definido na expressao
1, suponha-se, inicialmente, que (t) e previamente conhecido para todo t, e que  e conhecido a
priori. Desta forma, se supoem conhecidos todos
os parametros dinamicos do sistema, para cada t.
Trata-se, como mencionado, de um sistema linear
no espaco_de_estados sujeito a um rudo de medida
e um processo de inovacao normalmente distribudos. E bem conhecido que o filtro otimo para este
caso, no sentido do erro medio quadratico de estimacao, e o filtro de Kalman a parametros variantes no tempo.
Seja

Qpq



, k

Filtragem otima

xpq

(7)
(8)

E y (k) Yk1 , (1  k)  
 E Ck x (k) + Gk w (k) Yk1 , (1  k) 
 Ck xkk1

Algoritmos de Filtragem

2.4.1

(5)
(6)

onde Kk e uma matriz auxiliar, normalmente chamada ganho de Kalman. E importante notar,
tambem, que

que nao se assume, em geral, que seja conhecida
a priori, e constitui o objeto de estimacao.
2.4

(4)


y (k)  Ck xkk1  N (0, I)  

(9)

1

onde k2 representa o fator de Cholesky da matriz
 de variancia a priori de y (k).
E evidente que a equacao 9 so e valida para
o caso hipotetico em que a cadeia  e observavel.
No entanto, pode-se utilizar esta expressao para
auferir o quao provavel e que uma determinada
sequencia seja a verdadeira. Para a sequencia ver
12
dadeira, o conjunto dos k
y (k)  Ck xkk1
e distribuido como uma normal padrao.
A partir daqui, deixa-se de supor que a
sequencia  e conhecida, mas se supoe ainda que
os parametros  sao conhecidos (isto sera mantido
ate o termino desta secao 2.4). Defina-se

Hi (k) , (1)  1i , (2)  2i , . . . , (t)  ki
(10)
a sequencia de realizacoes de , onde o subscrito i
denota que esta e a i-esima entre as possveis M k

, E x(p)Yq  (1  q) 
(2)


0
, E (xpq  x(p))(xpq  x(p)) (3)

a estimativa da variavel de estados x em t  p, dadas as observacoes de y realizadas em t  0, . . . , q,

790

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

sequencias de tamanho k que se poderiam formar,
dado que em cada posicao ha M possibilidades.
E interessante criar um mapeamento que defina
exatamente a qual sucessao de modos correspondera esta sequencia i. Associe-se ao r-esimo numero da sequencia 1i , . . . , ri , . . . ti na equacao 10
o r-esimo algarismo do numeral iM (ou seja, do
numero i escrito na base M ).1
Defina-se, inicialmente xjkk como a estimativa sobre x(k) produzida pelo j-esimo filtro de
Kalman a parametros variantes. Pelo teorema de
Bayes, obtem-se que a probabilidade de que uma
sequencia de modos de operacao Hj (k) seja a correta e igual a
P Hj (k)y (1  k)   

dos modos, e que a expressao 12 calcula a probabilidade de que cada um destes modos esteja em
operacao, o proximo passo e combinar ambos os
resultados. Seja xokk a estimativa do filtro otimo,
que se busca. Segue que
xokk



E x(k)Yk  
k
MX
1

E x(k)Hn (k), Yk   P Hn (k)Yk  

n0



k
MX
1

xnkk P Hn (k)Yk  

n0

que e a estimativa otima que se buscava.

Py(1k)Hj (k)PHj (k)
Py(1k)

2.4.2

Algoritmo GPB2

O algoritmo GPB2 (Bar-Shalom and Li, 1993)
apresenta uma alternativa de menor custo_computacional ao algoritmo otimo, implicando uma
perda de desempenho. Se o algoritmo otimo corresponde a um banco de M t filtros em paralelo,
de maneira analoga, o algoritmo GPB2 requer
M 2 filtros em paralelo. Uma representacao esquematica pode ser encontrada em (Bar-Shalom and
Li, 1993). O algoritmo consiste, essencialmente,
em um truncamento da forma

utilizando a lei das probabilidades totais ao denominador, obtem-se
P Hj (k)y (1  k)   



Py(1k)Hj (k)PHj (k)
PM k 1
Py(1k)Hn (k)
n0

(11)
onde
P y (1  k) Hn (k)  
(12)
t



Y
1
 k 2 y (k)  Ck xnkk1

k1

xokk 

para todo historico n. O valor e obtido da equacao 9, dos valores obtidos das expressoes 4-8. O
fator da direita do numerador da expressao 11 e
a probabilidade conjunta a priori da sequencia,
dada por

k
MX
1

xnkk P Hn (k)Yk  

n0
M
1
X



M
1
X

E x(k)(k), (k  1) y(k), y(k  1)  

(k1)0 (k)0

 P (k), (k  1)y(k), y(k  1) 
i
i (13)
P Hj (k)  0  p0 ,1i  p1i ,2i  . . .  pk1
,k

, xokk

onde pi,j e o elemento (i, j) da matriz de transicao
P.
Note-se que ha tres condicoes iniciais que precisariam ser determinadas 0 , x00 e Q00 . Por
simplicidade, assume-se aqui a ergodicidade, supondo que os modos naturais do sistema decairao
com suficiente velocidade, e atribui-se a estas um
valor arbitrario. Mais rigorosamente, estas condicoes precisariam ser estimadas juntamente com ,
o que nao sera feito aqui. O modo de faze-lo, no
entanto, e identico ao procedimento que se apresentara para os demais parametros.
Calculou-se, desta forma, a probabilidade de
que cada historico Hj (t) seja o que realmente se
produziu, entre os M t , possveis. Isto conclui a
estimacao do processo ((t)). Pode-se agora utilizar a lei das probabilidades totais para encontrar
as estimativas otimas para a variavel de estados
x(t). Dado que nas expressoes 4-8 foram calculadas as estimativas otimas condicionais a cada um

(14)

onde cada (k), (k  1) sao os M 2 historicos
truncados, considerando-se apenas os dois instantes mais recentes, k  t e k  t  1. Portanto,
todos os historicos que diferem apenas em valores anteriores sao agregados juntamente com todas as demais sequencias que tenham em comum
os mesmos resultados da cadeia de Markov nos
dois ultimos instantes. Para realizar o calculo expresso na formula 14, iteram-se as expressoes 4-8
utilizando-se as observacoes y(k), y(k  1). Notese, no entanto, que e necessario fornecer valores
para xk2k2 e Qk2k2 . Estes valores devem
ser obtidos durante uma fase de truncamento da
filtragem_otima.
Sejam xjkk , para j  1, . . . , M e k  0, . . . , t,
aproximacoes pseudobayesianas de x(k), dadas as
observacoes y(1  k). Este algoritmo propagara
um numero de variaveis de estado com ordem de
grandeza de M entre iteracoes  ao contrario do algoritmo otimo, que propaga um numero da ordem
de M k variaveis2 . A essencia do algoritmo subotimo consiste em efetuar, a cada iteracao, uma

1 Por exemplo, se M  2 e t  4, o historico de ndice
10, entre os 0 a 15 possveis, sera a sequencia 0110, ou
102 , onde cada algarismo se associa ao modo vigente em
um perodo entre t  1 e t  4.

2 Para

791

obter a probabilidade de cada um dos M k+1 his-

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

reducao de complexidade. Em t  k, propagandose para a proxima iteracao M probabilidades associadas aos possveis valores de (k) e M vetores de valores esperados condicionais de x e suas
respectivas matrizes de covariancia, obtem-se M 2
possibilidades para (k), (k + 1), M 2 vetores
de valores esperados condicionais de x e M 2 matrizes de covariancia (para cada possibilidade de
(k), (k + 1)). Estes M 2 valores esperados e
covariancias serao reduzidos, a cada iteracao) a M
valores esperados e covariancias. Idealmente, isto
deve ser feito de forma a perder o mnimo possvel
de informacao sobre funcao densidade de probabilidade das variaveis de estado3 . No entanto, nao
e adequado para o desempenho do algoritmo que
se acrescente uma complexidade excessiva a esta
reducao, de forma que se utilizara aqui o procedimento pseudobayesiano simples.
Chame-se x1kk , . . . , xM
kk as M estimativas e

se dos valores encontrados no passo anterior para xjkk , Qjkk1 e Qjkk , e calculase

1
Kbk1  Qjk1k1 F01 Qjkk1
(16)
Qjk1k



Qjk1k1 

 Kbk1

xjkk



Qjkk1

Qjkk



(17)
0


Kbk1


 xjk+1k + Kbk1 xjkk  xjk+1k

(18)
Este passo melhora o desempenho do rastreamento, mas nao interfere na funcao
verossimilhanca. Deixa-se como opcional.
2. Calcular a probabilidade de cada modo, de
forma analoga a equacao 12. Para j 
1, . . . , M 

Q1kk , . . . , xM
kk

as M matrizes de covariancia armazenadas para o instante k. Atribua-se, inicialmente

P (k)  jy(k), y(k  1)  

x1kk  . . .  xM
kk  x00

Lj (k)P (k)  j
 PM
n1 Ln (k)P (k)  n

Q1kk  . . .  QM
kk  Q00
onde as estimativas iniciais x00 , Q00 sao arbitrarias (conforme mencionado na secao precedente)
seja tambem uma condicao inicial 0 arbitraria.
Itere-se para os instantes k  2, 3 . . . , t

(19)

onde as estimativas P (k)  j sao as estimativas a priori definidas na expressao 13.
3. Calcular a verossimilhanca total ponderada
para o instante k, atribuindo-se

1. Itere-se para os filtros j  0, 1, . . . , M 2  1
I Encontrar a sequencia de modos correspondente a j, utilizando a expressao 10
para encontrar 1j e 2j 
II Realizar a aquisicao de y(k  1) e y(k).
Utilizar as expressoes 4-8, comecando-se
com xjk2k2 e Qjk2k2 . Utilizam-se
os parametros dinamicos correspondentes aos 1j e 2j encontrados no item anterior. Calcular xjk1k1 , xjkk ,Qjk1k1 ,

L(k) 

M
X

Ln (k)P (n)  j

(20)

n1

4. Prosseguir para o proximo ciclo, utilizando
xjkk e Qjk1k1 como condicoes iniciais, para
j  1, . . . , M .
Finalmente, calcula-se a verossimilhanca total do
modelo. Dado que esta e uma funcao implcita
dos parametros , defina-se

Qjkk
III Calcular a verossimilhanca associada a
passagem do j-esimo filtro, utilizando a
expressao utilizada em 12. Para k, seja
  Qjkk . Atribua-se



1
Lj (k)    2 y (k)  C2 xjkk1
(15)
IV (Opcional) Utilizar um passo do smoother RTS4 para calcular xjk1k . Parte-

L0 () ,

t
Y

L(k)

(21)

log L(k)

(22)

k2

e
L () ,

t
X
k2

a log-verossimilhanca associada. Isto conclui o algoritmo. Na proxima secao, busca-se realizar a
otimizacao de L .

toricos em t  k + 1, e necessario propagar para a proxima
iteracao as M k probabilidades modais, os M k vetores de
valores esperados condicionais de x e suas respectivas matrizes de covariancia em t  k.
3 Vide Hershey and Olsen (2007) para uma discussao sobre reducao de misturas gaussianas baseada na divergencia
de Kullback-Leibler.
4 Rauch-Tung-Striebel (ver, por exemplo, (Simon,
2006))

3

Metodologia para estimacao de
parametros

Os algoritmos apresentados na secao 2.4 permitem
o calculo das estimativas condicionais aos parametros . O proposito deste estudo e, no entanto,

792

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

justamente a estimacao destes parametros que se
supuseram conhecidos ate este momento. Com
efeito, e bastante vantajosa a abordagem de se estudar inicialmente a verossimilhanca condicional.
O problema consiste em encontrar o argumento  que minimiza a funcao custo L , tal que

(c) Atribua-se
r  L (ui+1 )  L (ui )

(23)

(d) Atribua-se s  d .Calcule-se a nova
aproximacao da matriz hessiana, dada
por

  arg max L()


Bi+1  Bi +
Pode-se realizar uma maximizacao numerica
desta funcao. Para isto, e suficiente que se possa
calcular o valor da funcao J em cada ponto - o
que foi descrito nas secoes precedentes.
Neste trabalho, utilizaram-se metodos de gradiente para realizar estas maximizacoes. Note-se
que a funcao possui maximos locais, que se encontram em solucoes degeneradas, em que nao ha
diferenciacao entre os modos. Este problema e facilmente detectavel (verificando-se a igualdade dos
parametros entre os modelos), e pode ser contornado escolhendo-se outra condicao inicial aleatoriamente.
Utilizou-se nos experimentos o algoritmo
BFGS (Broyden-Fletcher-Goldfarb-Shanno), que
se caracteriza por ser um metodo quasi -Newton,
cuja matriz Hessiana e aproximada pelos sucessivos gradientes. O metodo utilizado pode ser sintetizado no seguinte algoritmo.

Bi s (Bi s)
rr0

0
rs
s0 Bi s

0

(24)

Ao se atingir o ponto otimo, cessa-se a otimizacao. A matriz hessiana final e utilizada
na obtencao de intervalos de confianca para
as estimativas.
4

Desempenho da estimacao e
convergencia

Realizaram-se dois ensaios, considerando-se em
cada um amostras progressivas entre T  1 e
T  3000 pontos. Em ambos, considerou-se o
caso escalar, com rudos normalmente distribudos, e uma cadeia de Markov com dois estados
possveis. Supos-se que os parametros C e G, referentes a equacao de observacao, eram bem conhecidos. O exerccio consiste, portanto, em estimar simultaneamente os parametros A1 , A2 , F1 ,
F2 , p11 e p22 . Realizou-se uma otimizacao concomitante por maxima_verossimilhanca dos seis parametros. Utilizou-se a matriz de transicao


0, 9 0, 1
P
0, 2 0, 8

I Escolhe-se uma estimativa inicial para os parametros desconhecidos. Estes sao reunidos
em um vetor u0 . Crie-se um mapeamento M
que realiza esta transformacao, e seja M1
o mapeamento inverso. Seja, portanto, i 
M1 (ui ). Por simplicidade,
 defina-se igualmente L(u)  L M1 (u) . O mapeamento
M transforma o conjunto formado pelas matrizes A1 , . . . , AM , C1 , . . . , CM , F1 , . . . , FM ,
G1 , . . . , GM e P em um vetor real u.

e os demais parametros conforme expostos na Tabela 1.
Os dois ensaios foram realizados com o mesmo
conjunto de parametros, variando-se a potencia do
erro de medida, para que se verificasse a robustez
da identificacao com respeito aos desvios do processo de filtragem.
Utilizaram-se como estimativas iniciais
A1 (0)  1, A2 (0)  1, F1 (0)  1, F2 (0)  1,
p11 (0)  0, 5 e p22 (0)  0, 5.
As figuras 1, 3 e 5 mostram a convergencia
dos parametros A, F e P no Caso I, em que esta
relacao sinal rudo (tambem chamada signal-tonoise ratio, ou SNR) e de 4. As figuras 2, 4 e 6
exibem o Caso II, em que SN R  1.
Nas figuras 1, 2, 3, 4, 5 e 6, as linhas tracejadas representam os parametros originais utilizados
para gerar a serie de dados observada. As pontilhadas sao intervalos de confianca a 95. Verificase a convergencia das estimativas para os valores
reais, mesmo sendo bastante grande o numero de
parametros que se otimizam simultaneamente.
Observa-se que os parametros A e P e F convergem de forma aparentemente nao viesada, persistindo uma pequena variabilidade em torno dos
valores originalmente utilizados para gerar a serie

II Pela expressao 22, calcule-se L(0 ), a logverossimilhanca de 0 , e seu respectivo gradiente L (u0 ), que deve ser calculado numericamente. Sejam Bi matrizes quadradas, para
todo i. Define-se B0  I, a matriz identidade
apropriada.
III Ate que se atinja um ponto crtico, itere em
passos i  1, 2, . . .
(a) Realize-se uma busca linear na direcao
d  Bi L (ui ), ate que se encontre
um fator  tal que o ponto ui+1  d
satisfaca a L (ui+1 ) < L (ui ).
(b) Verifique-se a consistencia dos parametros para determinar se o ponto ui+1 e
valido. As variancias devem ser positivas, e as linhas da matriz de transicao devem somar um. Se o ponto for
invalido, retorna-se ao passo anterior e
realiza-se nova busca linear.

793

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Tabela 1 Numeros considerados nos experimentos
Experimento Modelo
A
F
C
G
Relacao SinalRudo


I
1
0, 9
1,
2
1
0,
3
4


2
0, 8
0, 8 1
0, 2


II
1
0, 9
1
1, 2 1 1, 2
2
0, 8
0, 8 1
0, 8

Figura 1 Convergencia dos parametros A1 e A2 ,
Caso I

Figura 4 Convergencia dos parametros F1 e F2 ,
Caso II

Figura 2 Convergencia dos parametros A1 e A2 ,
Caso II

Figura 5 Convergencia dos parametros p11 e p22 ,
Caso I

Figura 3 Convergencia dos parametros F1 e F2 ,
Caso I

Figura 6 Convergencia dos parametros p11 e p22 ,
Caso II

794

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

de dados. No Caso II, em que os erros de estimacao sao mais elevados (devido a potencia do erro
de medida), verifica-se convergencia mais lenta.
Ainda assim, percebe-se uma clara convergencia
dos parametros.
Note-se que este experimento assume ergodicidade dos processos. Confirmou-se, em um experimento adicional, que esta premissa e adequada.
Alem disto, nao se comentou sobre a robustez do
algoritmo numerico com relacao as estimativas iniciais u0 , o que se pode constatar em um outro
teste emprico. Os resultados referentes a ambas
as questoes encontram-se em (Kassab, 2010).
5

Doucet, A. and Ristic, B. (2002). Recursive
state estimation for multiple switching models with unknown transition probabilities,
IEEE Transactions on Aerospace and Electronic Systems 38(3) 10981104.
Elliott, R. J., Aggoun, L. and Moore, J. B. (1995).
Hidden Markov models estimation and control, Springer, New York.
Elliott, R. and Krishnamurthy, V. (1999). New
finite-dimensional filters for parameter estimation of discrete-time linear gaussian models, , IEEE Transactions on Automatic
Control 44(5) 938951.

Conclusoes

Hamilton, J. D. (1990). Analysis of time series
subject to changes in regime, Journal of Econometrics 45 3970.

Os experimentos realizados confirmam a factibilidade da estimacao_de_parametros na classe de sistemas_lineares_sujeitos_a_saltos_markovianos com
algoritmos de filtragem sub-otimos. Conseguiu-se
uma convergencia satisfatoria na identificacao, a
despeito do uso de um algoritmo computacionalmente mais simples do que o filtro otimo. Estes
resultados mostram que o metodo de identificacao proposto pode ser util no tratamento de sistemas_lineares sujeitos a saltos cujos parametros
sejam desconhecidos ou estejam sujeitos a variacoes, e apresentam uma direcao bastante interessante para futuras pesquisas que possam estender
e aprofundar o tema.

Hamilton, J. D. (1994). Time series analysis,
Princeton University Press, Princeton.
Hershey, J. R. and Olsen, P. A. (2007). Approximating the KullbackLeibler divergence
between gaussian mixture models, IEEE International Conference on Acoustics, Speech,
and Signal Processing.
Jilkov, V. P. and Li, X., R. (2004). Online bayesian estimation of transition probabilities for
markovian jump systems, IEEE Transactions
on Signal Processing 52(6) 16201630.
Kassab, P. G. (2010). Filtragem e identificacao
em sistemas_lineares_sujeitos_a_saltos_markovianos, Masters thesis, Escola Politecnica da
Universidade de Sao Paulo, Sao Paulo.

Referencias
Baccarelli, E. and Cusani, R. (1996). Recursive
Kalman-type optimal estimation and detection of hidden Markov chains, Signal Processing 51(1) 5564.

Orguner, U. and Demirekler, M. (2008). Maximum likelihood estimation of transition
probabilities of jump Markov linear systems, IEEE Transactions on Signal Processing 56(10) 5093  5108.

Bar-Shalom, Y. and Li, X. (1993). Estimation and
Tracking Principles, Techniques and Software, Artech House, Norwood.

Simon, D. (2006). Optimal State Estimation Kalman, H Infinity, and Nonlinear Approaches,
Wiley-Interscience, Hoboken, NJ, USA.

Blom, H. and Bar-Shalom, Y. (1988). The interacting multiple model algorithm for systems with markovian switching coefficients,
IEEE Transactions on Automatic Control
33(8) 780783.

Tugnait, J. (1982). Adaptive estimation and identification for discrete systems with Markov
jump parameters, Automatic Control, IEEE
Transactions on 27(5) 10541065.

Costa, O. (1994). Linear minimum mean square
error estimation for discrete-time markovian jump linear systems, Automatic Control,
IEEE Transactions on 39(8) 16851689.
Costa, O., Fragoso, M. D. and Marques, R. P.
(2005). Discrete-time Markov Jump Linear
Systems, Springer Verlag, London.
Doucet, A., Gordon, N. J. and Krishnamurthy, V.
(1999). Particle filters for state estimation of
jump Markov linear systems, IEEE Transactions on Signal Processing 49 613624.

795