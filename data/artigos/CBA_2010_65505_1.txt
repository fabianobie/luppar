UMA ABORDAGEM CONSTRUTIVA PARA BAGGING DE CLASSIFICADORES
HETEROGENEOS
Diego S. C. Nascimento, Andre L. V. Coelho


Universidade de Fortaleza  Unifor
Mestrado em Informatica Aplicada  MIA
Av. Washington Soares, 1321, Edson Queiroz
CEP 60.811-905, CE  Brasil
Emails silveiraal@gmail.com, acoelho@unifor.br
Abstract This work presents a constructive approach to building ensembles of heterogeneous classifiers via
Bagging. For this purpose, a greedy algorithm is adopted so as to select the types of learning machines to be
trained over the resampled data generated by Bagging. The ultimate goal is to promote an increase in the
final ensembles generalization and diversity levels. Experiments were conducted over 18 classification problems
taken from the UCI repository whereby the acurracy values obtained by constructive heterogeneous Bagging are
contrasted with those produced by three models of homogeneous Bagging. The results achieved evidence gains
in terms of generalization for the constructive approach in a significant number of cases.
Keywords Committee Machines, Heterogeneous Bagging, RBF Neural Networks, Decision Trees, Nearestneighbor Classifiers.
Resumo Este trabalho apresenta uma abordagem construtiva para a sntese de ensembles de classificadores
heterogeneos via Bagging. Para esse fim, um algoritmo de natureza gulosa e utilizado para selecionar automaticamente os tipos de classificadores a serem treinados sobre conjuntos de dados reamostrados com reposicao
via Bagging. O objetivo e proporcionar incrementos nos nveis de generalizacao e diversidade. Experimentos
foram conduzidos sobre 18 problemas de classificacao extrados do repositorio UCI, de modo a se contrastar
os valores de acuidade obtidos via Bagging heterogeneo construtivo e aqueles produzidos por tres modelos de
ensembles homogeneos. Os resultados obtidos evidenciam ganhos de desempenho, em termos de capacidade de
generalizacao, por parte da abordagem construtiva em um numero significativo dos casos analisados.
Palavras-chave .

1

vez que algumas amostras deverao ser escolhidas
repetidamente ao passo que outras nao serao aproveitadas, o tamanho efetivo de cada novo conjunto
sera menor que o do original, nao havendo praticamente nenhuma chance de eles serem identicos.
Desse modo, garante-se que diferentes estimadores treinados sobre os diferentes conjuntos derivados representarao hipoteses distintas sobre a funcao geratriz dos dados (Breiman, 1996 Opitz and
Maclin, 1999 Dietterich, 2000b). Os K modelos
treinados sobre os diferentes conjuntos derivados
tem suas sadas combinadas via procedimentos de
votacao simples ou majoritaria (Kuncheva, 2004).
Ja os metodos da segunda classe de abordagens utilizam apropriadamente diferentes algoritmos de aprendizado (redes_neurais, arvores_de_decisao, maquinas de vetores-suporte, classificadores
baseados em vizinhanca, entre outros) de forma
a levar a geracao de componentes com diferentes nveis de especializacao e precisao, capazes de
explorar diferentes regioes do espaco de hipoteses (Canuto et al., 2007). Desse modo, diferentes
vieses (bias) em termos de representacao e busca
podem levar a diferentes padroes de generalizacao,
incorrendo em ganhos de diversidade do modelo
de ensemble resultante (Dietterich, 2000a Dietterich, 2000b).
Ate o presente, existem na literatura poucos estudos empricos avaliando a combinacao, em

Introducao

O conceito de comites_de_maquinas (Haykin,
1999 Kuncheva, 2004 Coelho, 2004) estipula a fusao de modulos independentes de estimacao (denominados de componentes ou especialistas) em
busca de uma decisao global que seja potencialmente mais eficaz que a de qualquer estimador individual. Dentre os diferentes arranjos de comites
de maquinas existentes, notadamente um grande
numero de trabalhos vem sendo conduzidos sobre
aqueles de natureza estatica, conhecidos como ensembles ou sistemas multi-classificadores (Haykin,
1999 Kuncheva, 2004).
Recentemente, duas classes de abordagens
destinadas a geracao de ensembles vem recebendo
bastante atencao na literatura. A primeira classe
toma como base metodos de redistribuicao aleatoria dos dados de treinamento enquanto a segunda e baseada na utilizacao de diferentes tipos
de algoritmos de aprendizado. Para os metodos
da primeira classe, destaca-se Bagging (Bootstrap
Agregation and Combining), proposto por Breiman (1996). De acordo com esse metodo, K conjuntos de treinamento diferentes sao produzidos
a partir de um repositorio comum via reamostragem aleatoria com reposicao das amostras. Cada
um dos novos conjuntos de dados tera o mesmo
numero de amostras do original. Entretanto, uma

1719

um so arcabouco conceitual, de diferentes abordagens de promocao de diversidade em ensembles (Nascimento and Coelho, 2009). Como um
passo nesse sentido, o objetivo deste artigo esta
na caracterizacao e avaliacao de uma abordagem
hbrida de comites_de_maquinas, denominada de
Bagging Heterogeneo Construtivo, segundo a qual
diferentes algoritmos de aprendizado podem ser
recrutados para a inducao dos componentes do ensemble sobre os dados reamostrados gerados por
Bagging padrao. Como meio de selecao automatica dos diferentes tipos de indutores (componentes) de acordo com as nuances do problema em
vista, adota-se um algoritmo de busca gulosa.
Na Secao 2, e conduzida uma breve discussao conceitual sobre ensembles, bem como sobre
o conceito de diversidade em ensembles. Ja a Secao 3 e destinada a abordagem Bagging heterogeneo construtivo, dando enfase ao procedimento
de geracao dos componentes via diferentes algoritmos de aprendizado. Para fins de validacao da
proposta, foi conduzido um estudo emprico envolvendo 18 problemas de classificacao de diferentes
origens e nveis de dificuldade, o qual e descrito na
Secao 4. Como forma de analise dos resultados, os
valores de desempenho obtidos via Bagging heterogeneo sao contrastados com aqueles produzidos
por tres modelos de ensembles homogeneos redes
neurais RBF, arvores_de_decisao e classificadores
baseados em vizinhanca. O artigo e concludo na
Secao 5, a qual traz perspectivas sobre outros trabalhos em andamento.
2

o custo_computacional em se obter um mesmo nvel de desempenho.
Existem varias abordagens para se promover diversidade em ensembles, sendo as mais comuns (Dietterich, 2000a Kuncheva and Whitaker, 2003 Coelho, 2004) 1) metodos que manipulam os dados de treinamento, ou seja, variam a
apresentacao dos dados por estrategias de reamostragem 2) metodos que atuam sobre o ponto de
partida para a busca realizada sobre o espaco de
hipoteses 3) metodos que manipulam a arquitetura dos componentes, ou seja, variam a arquitetura de cada componente de forma que diferentes
conjuntos de hipoteses estejam acessveis a cada
um deles e 4) metodos que atuam sobre a forma
de exploracao do espaco de hipoteses, ou seja, direcionam a busca para a melhor hipotese.
Notadamente, o algoritmo Bagging e a estrategia de ensembles heterogeneos pertencem as
classes 1 e 3, respectivamente. No caso do Bagging, Breiman (1996) argumenta que os estimadores mais propcios para serem combinados via este
metodo sao os de genero instavel, dentre os quais
figuram os modelos neurais e as arvores_de_decisao. Estimadores instaveis apresentam alta sensibilidade a pequenas mudancas nas condicoes de
treinamento por exemplo, perturbacoes no conjunto de dados ou condicoes iniciais podem acarretar a geracao de hipoteses bastante discrepantes
no que diz respeito a sua capacidade de generalizacao. Contudo, o autor nada menciona sobre o
impacto de se ter diferentes tipos de estimadores
sobre o desempenho do algoritmo Bagging.
Uma das metricas mais comuns para mensurar diversidade em ensembles e a EstatsticaQ (Kuncheva and Whitaker, 2003), pela qual o
grau de divergencia entre dois classificadores k e
k 0 pode ser calculado conforme a Equacao (1)

Ensembles de Estimadores

Em uma arquitetura tpica de ensembles, cada
novo padrao de entrada e tratado de forma redundante por K diferentes modulos-componentes. Estes produzirao independentemente suas estimativas, sendo estas fundidas por um modulo de combinacao para dar origem a decisao consensual. Em
problemas de classificacao, para se combinar as
respostas individuais, e comumente utilizado algum procedimento de votacao, quer seja simples,
majoritario ou ponderado. No caso de problemas
de regressao, a media simples ou ponderada sao
os operadores mais utilizados (Haykin, 1999 Kuncheva, 2004).
Uma questao primordial nesse contexto e a da
diversidade. Cada componente do ensemble deve
apresentar um bom desempenho quando aplicado
isoladamente porem, o grupo deve apresentar alta
dissimilaridade no que tange aos padroes de erro
individuais sobre as diferentes regioes do espaco de
entrada, de forma que a diversidade das respostas
produzidas possa contribuir na sntese de uma melhor hipotese sobre os dados (Kuncheva and Whitaker, 2003 Kuncheva, 2004 Coelho, 2004). Caso
nao haja essa diversidade, o papel dos componentes sera praticamente o mesmo, nao compensando

Qk,k0 

N 11 N 00  N 01 N 10
,
N 11 N 00 + N 01 N 10

(1)

sendo que N 11 e N 00 denotam, respectivamente,
o numero de amostras classificadas corretamente
e incorretamente por k e k 0 , ao passo que N 10
indica o numero de amostras classificadas corretamente por k e incorretamente por k 0 . O inverso
se aplica a N 01 . A Estatstica-Q assume valores
entre 1, 1, sendo que valores positivos altos indicam forte correlacao entre os padroes de erro,
valores negativos indicam nao-correlacao, ao passo
que valores proximos a zero indicam independencia. Ja a diversidade do ensemble Q() e dada
pela media sobre todos os possveis acoplamentos entre pares de componentes (Kuncheva, 2004),
sendo calculada como na Equacao (2).

Q() 

K1
K
X X
2
Q(k, k 0 ).
K(K  1)
0
k1 k k+1

1720

(2)

E valido enfatizar que, embora existam na literatura varias metricas para mensurar quantitativamente o nvel de diversidade em ensembles (sejam elas baseadas em medidas par-a-par entre os
K classificadores ou baseadas em medidas sobre
todo o grupo (Kuncheva and Whitaker, 2003)),
nao existe ainda nenhum estudo teorico garantindo formalmente que haja uma correlacao forte
entre essas medidas de diversidade e a precisao
dos sistemas multi-classificadores resultantes. Ou
seja, nao se pode garantir que um incremento dessas medidas de diversidade impliquem um incremento proporcional na acuidade dos ensembles.
De qualquer maneira, a Estatstica-Q foi adotada
aqui para avaliacao dos modelos gerados pela nova
abordagem por conta de sua facilidade de interpretacao e de calculo, e por ser uma das metricas
mais comumente adotadas na literatura, permitindo, assim, a comparacao dos resultados obtidos com aqueles apresentados em trabalhos correlatos (Nascimento and Coelho, 2009 Canuto
et al., 2005 Coelho, 2006 Canuto et al., 2007).

3

Bagging Heterogeneo Construtivo

Dado um problema de classificacao para o
qual se tem disponvel um repertorio com M tipos de indutores diferentes, a tarefa de selecionar o melhor arranjo de K componentes de um
ensemble heterogeneo a ser treinado via Bagging
pode ser modelada como um problema tpico de
otimizacao_combinatoria (particularmente, como
um problema de alocacao). Dado que o espaco de
busca de configuracoes factveis e de grandeza exponencial (O(K M )), a resolucao desse problema
via metodos tradicionais torna-se intratavel computacionalmente, o que nos motivou lancar mao
de uma abordagem construtiva.
A Teoria Psicologica Construtivista, proposta
por Piaget (1979), define o conhecimento como
fruto de acoes mutuas indissociaveis entre sujeito
e o seu meio. Nesta concepcao, nao ha enfase nas
experiencias adquiridas (empirismo) e nem na bagagem hereditaria (inatismo), mas sim na relacao
e interacao entre esses dois elementos. Em particular, as abordagens construtivistas de aprendizado_de_maquina frequentemente empregam algoritmos gulosos, uma vez que estes sao bastante
eficientes, progredindo com grande rapidez em direcao a uma solucao melhor. E notavel perceber a
facilidade de funcionamento de um algoritmo guloso porque, normalmente, a melhoria da qualidade de um estado ocorre de maneira progressiva.
Por outro lado, em alguns casos, esta abordagem
apresenta a dificuldade de ficar limitada a otimos
locais e platos.
Recentemente, alguns esforcos vem sendo realizados na concepcao de modelos de ensembles seguindo esse paradigma (Akhand and Murase, 2007). No contexto deste estudo, a estrategia seguida foi a de construir um comite heterogeneo de forma incremental e determinstica
(vide Figura 1). Desta forma, a abordagem heterogenea construtiva leva em consideracao dois
aspectos importantes na construcao de ensembles.
O primeiro aspecto esta diretamente relacionado
ao incremento contnuo da quantidade de componentes, uma vez que essa acao tende em tese a
proporcionar ganhos de acuidade para o modelo
de ensemble resultante (Witten and Frank, 2005).
Por outro lado, o ganho de acuidade do ensemble tende a ser cada vez menor a medida que o
numero de componentes se eleva. Em contrapartida, o segundo aspecto toma como base estudos
que vem comprovando que a utilizacao de todos
os componentes pode degradar a precisao do ensemble (Zhou et al., 2002).
A abordagem construtiva heterogenea via
Bagging tenta encontrar um equilbrio entre a
quantidade de componentes do ensemble e o nvel de acuidade do modelo resultante. Para tanto,
a cada iteracao, seleciona-se um componente produzido por um dentre M diferentes tipos de algo-

Com relacao as abordagens de ensembles heterogeneos, em (Wang et al., 2000), e realizado
um estudo envolvendo a combinacao de redes_neurais e arvores_de_decisao para incremento da diversidade os autores concluem que um numero
relativamente maior de redes_neurais parece ser
uma boa estrategia para se obter nveis mais elevados de generalizacao. Por outro lado, Tsoumakas
et al. (2004) e Tsoumakas et al. (2005) investigaram uma abordagem de poda de ensembles heterogeneos baseada em testes estatsticos que determinam se diferencas no desempenho preditivo
de diferentes classificadores sao significativas. Somente os classificadores com ndices de desempenho significativamente melhores que os demais sao
retidos e subsequentemente combinados via voto
ponderado. Uma desvantagem dessa abordagem
e que ela nao leva em consideracao os nveis de
diversidade dos classificadores para realizar a selecao.
Ja Soares et al. (2006) utilizaram como componentes em seu estudo redes_neurais MLP, redes_neurais RBF, classificadores Nave Bayes, maquinas de vetores-suporte (SVM) e classificadores baseados em regras proposicionais, propondo
duas tecnicas de selecao de componentes com algoritmos de agrupamento e k-nearest neighbours
(KNN). Por sua vez, no estudo de Canuto et al.
(2007), foram utilizadas redes MLP (padrao e
fuzzy) e RBF, o algoritmo KNN, SVMs, arvores
de decisao e o algoritmo JRIP, analisando-se o impacto da escolha dos membros sobre o modelo final
de ensemble. Essa investigacao, porem, nao considerou metodos de reamostragem para treinamento
dos componentes.

1721

Figura 1 Execucao da abordagem heterogenea construtiva para Bagging.
ritmos de aprendizado. Inicialmente, o modelo de
ensemble contem apenas um componente, sendo
este escolhido de acordo com o seu ndice de acuidade operando sozinho (mensurado via validacaocruzada). Em seguida, na segunda iteracao, serao gerados M novos classificadores, um para cada
tipo de indutor, e cada classificador sera recrutado
separadamente para operar conjuntamente com o
componente inserido na primeira iteracao. Ao final da segunda iteracao, o classificador cuja inclusao trouxer o maior ganho de desempenho para o
ensemble atual sera aquele efetivamente escolhido
para integrar a configuracao heterogenea daqui em
diante. Esse processo iterativo de avaliacao e selecao continua ate que o numero maximo de componentes K seja atingido ou ate que o ndice de
desempenho (tambem mensurado via validacaocruzada) do ensemble resultante da iteracao atual
seja pior ou igual ao ndice de desempenho do ensemble da iteracao anterior  nesse caso, o modelo
de ensemble final sera aquele produzido na iteracao anterior. Deve-se notar que um mesmo tipo
de classificador pode ser recrutado em diferentes
iteracoes do algoritmo construtivo  vide Figura 1.
Cada estado da busca gulosa associada a esse
processo construtivo representa uma configuracao heterogenea especfica de ensemble. A representacao de um estado e, portanto, vetorial e
inteira, sendo que, nos experimentos reportados
aqui, cada elemento da representacao assume um
valor no intervalo 1, 10. Isso porque M  10 e os
valores de 1 a 10 indicam, respectivamente, os indutores RBF, J48, SMO, Nave Bayes, IBk, REP
Tree, Decision Stump, OneR, PART e Decision
Table, disponveis no ambiente WEKA (Witten
and Frank, 2005). Vale destacar que alguns desses
algoritmos geram modelos instaveis (RBF, J48,
PART), ao passo que outros nao (SMO, IBk). O
objetivo e perceber se a combinacao de componentes reconhecidamente instaveis com outros estaveis traz algum ganho em termos de diversidade
e generalizacao.

4

Experimentos e Analise dos Resultados

Um prototipo da abordagem Bagging heterogeneo construtivo foi implementado na linguagem
Java, lancando-se mao dos insumos providos pelo
ambiente WEKA (Witten and Frank, 2005). E
valido mencionar que esse framework vem sendo
recentemente bastante adotado como base de desenvolvimento e validacao de novas abordagens
de aprendizado_de_maquina, notadamente aquelas baseadas em comites_de_maquinas (Soares
et al., 2006 Canuto et al., 2007 Tsoumakas
et al., 2004). As configuracoes default dos parametros de controle dos M  10 tipos de maquinas
listados na secao anterior foram adotadas nos experimentos descritos na sequencia.
Para fins de validacao da proposta, foram conduzidos experimentos sobre 18 problemas de classificacao extrados do repositorio UCI (Asuncion
and Newman, 2007), a maioria dos quais (senao todos) tambem ja serviu de alvo de investigacao em trabalhos correlatos na linha de comites_de_maquinas (Opitz and Maclin, 1999 Dietterich, 2000b Canuto et al., 2007 Tsoumakas
et al., 2005). As bases de dados relativas a esses problemas estao indicadas na primeira coluna
da Tabela 1, sendo que uma descricao das suas
propriedades em termos de numero de amostras,
numero e tipos de atributos, numero e distribuicao das classes, e existencia de atributos faltantes pode ser encontrada em (Coelho, 2004 Opitz
and Maclin, 1999 Canuto et al., 2007 Tsoumakas
et al., 2005).
Tendo em mente a obtencao de resultados estatisticamente significativos, para cada um dos
problemas foram criados aleatoriamente (i.e. mediante diferentes sementes para o gerador de numeros aleatorios) 10 conjuntos de particoes de
treinamento e teste, observando-se a divisao de
66,6 e 33,4, respectivamente. O particionamento feito foi do tipo estratificado, ou seja, respeitando as proporcoes originais das classes em

1722

Figura 2 Particionamento da base de dados original em treinamento e teste.
Tabela 1 Tabela contendo os valores de erro medio de teste e Estatstica-Q para os modelos Bagging
homogeneos formados por redes_neurais RBF, arvores_de_decisao e classificadores baseados em vizinhanca.
Base
anneal
breast-cancer
bupa
colic
credit-a
diabetes
glass
haberman
heart-c
hepatitis
ionosphere
iris
segment
sick
sonar
vehicle
vote
zoo

RBF
Teste
0,08800,0236
0,28030,0207
0,36300,0402
0,21780,0105
0,19690,0198
0,25990,0173
0,33480,0342
0,25220,0102
0,17140,0260
0,15780,0301
0,09780,0189
0,04950,0111
0,11210,0104
0,03640,0025
0,24600,0467
0,33980,0188
0,06720,0184
0,13030,0424

Est.-Q
0,8845
0,7977
0,5395
0,8842
0,9693
0,8899
0,5774
0,8474
0,9226
0,6179
0,9456
0,4344
0,9381
0,9793
0,3855
0,8523
0,9620
0,1741

J48
Teste
0,11050,0181
0,29470,0207
0,34540,0343
0,15450,0174
0,14880,0108
0,25420,0083
0,32980,0318
0,26670,0097
0,20950,0275
0,18240,0132
0,08830,0228
0,06670,0136
0,05160,0084
0,01760,0030
0,27590,0494
0,28120,0154
0,04320,0077
0,13180,0441

cada particao. O processo de particionamento e
ilustrado na Figura 2. Sobre os dados de treinamento, foram conduzidos tanto a geracao de ensembles homogeneos via Bagging padrao, como a
abordagem heterogenea construtiva. Durante o
processo de construcao do ensemble heterogeneo,
a combinacao dos varios arranjos de componentes
e avaliada com base em validacao-cruzada estratificada de 10 folds (Witten and Frank, 2005). Ja
os dados de teste foram usados para se avaliar os
ndices de generalizacao dos modelos de ensemble resultantes da fase de treinamento, estes por
sua vez treinados sobre toda a particao de treinamento.

Est.-Q
0,8087
0,8128
0,3534
0,9590
0,8698
0,5288
0,5025
0,7717
0,5415
0,5883
0,4040
0,2556
0,8925
0,9824
0,0971
0,4481
0,8756
0,5510

IBk
Teste
0,07450,0082
0,31910,0400
0,40350,0260
0,21900,0224
0,20330,0209
0,31820,0187
0,35250,0338
0,33080,0337
0,21860,0334
0,18920,0289
0,14890,0118
0,05660,0179
0,05330,0063
0,05270,0042
0,22120,0330
0,34410,0114
0,07870,0225
0,08330,0217

Est.-Q
0,4229
0,2823
0,3432
0,6957
0,5942
0,4396
0,3584
0,3830
0,3340
0,3245
0,2949
0,3578
0,7474
0,8557
0,1681
0,4561
0,2944
0,4642

(RBF), arvores_de_decisao (J48) e classificadores
baseados em vizinhanca (IBk). Ja na Tabela 2,
sao apresentados os ndices de desempenho exibidos por Bagging heterogeneo construtivo e uma
comparacao com os tres modelos homogeneos de
Bagging. Vale ressaltar que, embora esses resultados tenham sido obtidos para K  10 (tanto
para o caso homogeneo como para o caso heterogeneo), os aspectos qualitativos de comparacao se
mantem para outros valores desse parametro.
A analise e feita aqui em termos das taxas medias de erro de teste. A coluna Quant. Comp.
da Tabela 2 informa a quantidade media de componentes utilizados pela abordagem construtiva.
Ja as tres ultimas colunas contem os valores de
significancia estatstica (p-values) resultantes da
aplicacao do teste de hipotese (Teste-T bicaudal

A Tabela 1 apresenta os resultados de erro
medio de teste e Estatstica-Q para os modelos homogeneos de Bagging formados por redes_neurais

1723

Tabela 2 Tabela contendo o erro medio de teste, o valor da Estatstica-Q, a quantidade de componentes, todos relativos ao melhor modelo Bagging heterogeneo construtivo, alem dos p-values do Teste-T
comparando o seu desempenho ao dos tres modelos homogeneos de ensembles.
Base
anneal
breast-cancer
bupa
colic
credit-a
diabetes
glass
haberman
heart-c
hepatitis
ionosphere
iris
segment
sick
sonar
vehicle
vote
zoo

Bagging Heterogeneo Construtivo
Teste
Est.-Q
Quant. Comp.
0,03260,0130 0,4090 2,70001,6364
0,30430,0120
0,8893
2,30001,0593
0,36870,0443
0,5629
3,50001,8409
0,17400,0237
0,8408
3,00001,5635
0,15190,0117
0,8781
2,00001,3333
0,25710,0248
0,8302
1,90001,1005
0,40140,0453
0,6363
2,10001,1005
0,27760,0282
0,8746
1,70000,6749
0,17940,0244
0,9210
2,00000,8165
0,17060,0213
0,5294
2,30001,1595
0,09260,0255
0,6904
3,30000,9487
0,05760,0234
0,6000
1,40000,5164
0,04510,0104 0,7102 4,60002,2211
0,01910,0027
0,9079
2,90001,1005
0,25910,0519
0,5266
2,50001,4337
0,30840,0199
0,6906
2,30001,4944
0,04560,0099
0,9574
2,20000,9189
0,13790,0252
0,9091
1,60000,5164

RBF
0,0005
0,0106
0,5962
0,0014
0,0001
0,8002
0,0129
0,0154
0,4999
0,2780
0,5116
0,3092
0,0000
0,0000
0,4841
0,0103
0,0034
0,5291

Teste-T
J48
0,0000
0,1180
0,1228
0,0060
0,3536
0,7616
0,0107
0,2466
0,0158
0,0510
0,6193
0,2146
0,1548
0,1053
0,5289
0,0104
0,3328
0,7374

IBk
0,0000
0,2704
0,0504
0,0003
0,0001
0,0000
0,0350
0,0009
0,0007
0,0882
0,0001
0,9074
0,0541
0,0000
0,0263
0,0008
0,0012
0,0003

Tabela 3 Tabela contendo os valores de ocorrencia dos tipos de componentes recrutados por Bagging
heterogeneo construtivo.
Base
anneal
breast-cancer
bupa
colic
credit-a
diabetes
glass
haberman
heart-c
hepatitis
ionosphere
iris
segment
sick
sonar
vehicle
vote
zoo

RBF
0,1111
0,0435
0,1515
0,1333
0,0952
0,1053
0,0476
0,2353
0,3500
0,2609
0,3636
0,3571
0,0476
0,0690
0,1200
0,0870
0,0909
0,0625

J48
0,0741
0,3478
0,0909
0,3333
0,0952
0,1579
0,2381
0,1176
0,0000
0,1304
0,1212
0,0000
0,1429
0,3448
0,0400
0,2174
0,3182
0,0625

SMO Nave Bayes
IBk
REP Tree Decision Stump OneR PART Decision Table
0,0370
0,1111
0,0370
0,0370
0,0000
0,0000 0,0000
0,5926
0,0435
0,1304
0,1304
0,0435
0,0870
0,1739 0,0000
0,0000
0,0606
0,0303
0,0909
0,0909
0,1515
0,0606 0,2424
0,0303
0,0000
0,0333
0,0667
0,1333
0,0333
0,0667 0,1000
0,1000
0,1429
0,0476
0,0476
0,0952
0,3333
0,0476 0,0952
0,0000
0,2632
0,2632
0,0526
0,0000
0,0526
0,0000 0,0526
0,0526
0,0476
0,0952
0,2857
0,2381
0,0000
0,0000 0,0000
0,0476
0,0588
0,1765
0,0000
0,0000
0,0588
0,1176 0,1765
0,0588
0,2500
0,3500
0,0000
0,0000
0,0500
0,0000 0,0000
0,0000
0,0435
0,3913
0,0000
0,0870
0,0435
0,0000 0,0000
0,0435
0,1818
0,0909
0,0000
0,0606
0,0909
0,0000 0,0303
0,0606
0,0714
0,1429
0,1429
0,0000
0,0714
0,0714 0,0000
0,1429
0,0476
0,0238
0,2619
0,0476
0,0714
0,0000 0,1429
0,2143
0,0000
0,1034
0,0345
0,2069
0,1034
0,0000 0,1379
0,0000
0,0400
0,0800
0,4000
0,0800
0,0400
0,0400 0,0800
0,0800
0,2174
0,0435
0,0870
0,1304
0,0435
0,0000 0,1739
0,0000
0,2727
0,0000
0,0000
0,1364
0,0909
0,0909 0,0000
0,0000
0,2500
0,3750
0,1875
0,0000
0,0625
0,0000 0,0000
0,0000

pareado) sobre as taxas de erro de teste produzidas pelas abordagens para os 10 conjuntos de particoes. Esse teste estatstico tem como objetivo
avaliar a equivalencia entre duas medias amostrais, supondo independencia e normalidade das
observacoes  no caso, das taxas de erro (Witten
and Frank, 2005). No nosso caso, adotou-se um
nvel de confiabilidade de 95 ou seja, se o valor
de significancia ficar abaixo de 5, entao a hipotese nula (i.e. equivalencia de desempenho entre as abordagens) e rejeitada. Com isso, pode-se
apontar para cada base de dados qual abordagem
(homogenea ou hererogenea) apresentou maior ndice de generalizacao, levando-se em consideracao
o menor erro de teste. Nos casos em que os valores
de significancia ficaram acima de 5, considerouse que o desempenho de generalizacao exibidos pe-

las abordagens sao equivalentes.
De forma geral, os resultados obtidos pela
abordagem heterogenea construtiva via algoritmo
Bagging foram animadores. Em se tratando da
capacidade de generalizacao, a abordagem construtiva, quando comparada ao modelo homogeneo
formado por redes_neurais artificiais RBF, foi superior em sete casos (valores em negrito para a coluna Teste-T), equivalente em oito (valores em
italico), e inferior em apenas tres. Ja quando comparada ao modelo homogeneo formado por arvores_de_decisao (J48), a abordagem construtiva foi
superior em dois problemas, equivalente em 13, e
inferior em apenas tres. E, por fim, a abordagem
construtiva foi comparada ao modelo de ensemble
homogeneo formado por classificadores baseados
em vizinhanca (IBk). Nesse caso, a nova aborda-

1724

gem foi superior em 10 casos, equivalente em cinco
e inferior em apenas tres. Esses resultados vem a
confirmar a estabilidade da abordagem construtiva quando aplicada a varios problemas de diferentes complexidades.
Os nveis de diversidade apresentados pelas
abordagens homogeneas e heterogenea tambem foram analisados mediante a Estatstica-Q. Essa
analise e muito importante visto que, como Kuncheva and Whitaker (2003) advogam, a diversidade e um fator primordial para se obter maiores
ganhos de generalizacao em ensembles. Os ndices
de diversidade (valores em negrito para a coluna
Est.-Q) apresentados pela abordagem heterogenea construtiva foram significativamente superiores apenas para os problemas anneal e segment
ja para os demais, os nveis se mantiveram equivalentes ou inferiores aos modelos homogeneos.
Para Bagging heterogeneo construtivo, os varios tipos de componentes foram recrutados com
diferentes frequencias para os diferentes problemas, nao havendo um unico tipo que prevalecesse
sobre os demais, conforme exibido na Tabela 3 (os
valores em negrito informam os tipos de componentes com maior frequencia para cada base de dados). Isso reforca o papel da abordagem construtiva em localizar os tipos mais adequados de componentes de acordo com as nuances do problemaalvo. Um aspecto importante a ser observado esta
relacionado a utilizacao de indutores instaveis a
serem combinados via Bagging (Breiman, 1996).
Ou seja, os melhores ndices de desempenho foram alcancados adotando-se algoritmos que refutam esse conceito, notadamente, as maquinas de
vetor-suporte (SMO) e o algoritmo baseado em
estatstica bayesiana (Nave Bayes). Outro benefcio proporcionado pela abordagem construtiva
e referente a diminuicao da quantidade de componentes efetivamente utilizados nos modelos de
ensemble, o que permitiu uma reducao do custo
computacional (eficiencia) referente ao tempo de
processamento de novas instancias de teste.
De certo modo, este trabalho vem corroborar com a pesquisa de Canuto et al. (2007), que
tambem avalia o impacto da escolha de diferentes
tipos de indutores em ensembles, sendo que a configuracao dos modelos foi realizada aqui de forma
automatica, mediante a abordagem construtiva.
O trabalho tambem complementa os resultados
obtidos em (Nascimento and Coelho, 2009), no
qual constatou-se os benefcios de se combinar
o algoritmo Boosting (Haykin, 1999 Kuncheva,
2004 Opitz and Maclin, 1999) com o conceito de
ensembles heterogeneos, tanto em termos de capacidade de generalizacao como em termos de incremento da diversidade em ensembles. No caso
da abordagem heterogenea construtiva aqui apresentada, obteve-se ganhos frente aos tres modelos
homogeneos avaliados em termos de capacidade de
generalizacao, mas nao em termos de incremento

da diversidade, conforme atestado acima.
5

Conclusao

Neste artigo, uma nova abordagem heterogenea construtiva destinada a sntese de ensembles
de classificadores via Bagging foi caracterizada e
empiricamente avaliada, tomando por base o desempenho exibido por ensembles homogeneos formados por redes_neurais RBF, arvores_de_decisao e
classificadores baseados em vizinhanca. Os resultados experimentais apontam ganhos em termos
de generalizacao (taxa media de erro sobre as particoes de teste), mas nao em termos de diversidade
(Estatstica-Q).
Como extensao da analise apresentada aqui,
pretende-se realizar estudos mais amplos, comparando o desempenho de modelos heterogeneos de
Bagging e Boosting. Outro caminho a ser explorado envolve a aplicacao de modelos heterogeneos
de ensembles em tarefas de regressao e previsao
de series_temporais.
Agradecimentos
Os autores agradecem a Fundacao Cearense
de Apoio ao Desenvolvimento Cientfico e Tecnologico (Funcap) pela ajuda financeira referente a
uma bolsa de mestrado. O segundo autor agradece
ao Conselho Nacional de Desenvolvimento Cientfico e Tecnologico pelo suporte financeiro referente
a uma bolsa de produtividade em pesquisa (processo  3129342009-2).
Referencias
Akhand, M. A. H. and Murase, K. (2007). A minimal neural network ensemble construction
method A constructive approach, Journal
of Advanced Computational Intelligence and
Intelligent Informatics 11(6) 582592.
Asuncion, A. and Newman, D. J. (2007). UCI
Machine Learning Repository, University of
California at Irvine, httpics.uci.edu
mlearnMLRepository.html.
Breiman, L. (1996). Bagging predictors, Machine
Learning 24(2) 123140.
Canuto, A. M. P., Abreu, M. C. C., de M. Oliveira, L., Jr., J. C. X. and de M. Santos,
A. (2007). Investigating the influence of the
choice of the ensemble members in accuracy
and diversity of selection-based and fusionbased methods for ensembles, Pattern Recognition Letters 28(4) 472486.
Canuto, A. M. P., de M. Oliveira, L., Jr., J. C. X.,
de M. Santos, A. and Abreu, M. C. C. (2005).

1725

Performance and diversity evaluation in hybrid and non-hybrid structures of ensembles,
Procs. of the Fifth International Conference
on Hybrid Intelligent Systems, pp. 285290.

Tsoumakas, G., Angelis, L. and Vlahavas, I.
(2005). Selective fusion of heterogeneous classifiers, Intell. Data Anal. 9(6) 511525.
Tsoumakas, G., Katakis, I. and Vlahavas, I.
(2004). Effective voting of heterogeneous
classifiers, in J.-F. Boulicaut, F. Esposito,
F. Giannoti and D. Pedreschi (eds), Procs. of
European Conference on Machine Learning
(ECML 2004), Vol. 3201 of Lecture Notes in
Artificial Intelligence, pp. 465476.

Coelho, A. L. V. (2004). Evolucao, simbiose e hibridismo aplicados a engenharia de sistemas
inteligentes modulares Investigacao em redes_neurais artificiais, comites_de_maquinas
e sistemas_multiagentes, PhD thesis, Faculdade de Engenharia Eletrica e Computacao,
Universidade Estadual de Campinas.

Wang, W., Jones, P. and Partridge, D. (2000). Diversity between neural networks and decision
trees for building multiple classifier systems,
Procs. of the First International Workshop
on Multiple Classifier Systems, pp. 240249.

Coelho, G. P. (2006). Geracao, selecao e combinacao de componentes para ensembles de redes
neurais aplicadas a problemas de classificacao, Masters thesis, Universidade Estadual
de Campinas.

Witten, I. H. and Frank, E. (2005). Data Mining
Pratical Machine Learning Tools and Techiniques, 2a. edn, Elsevier.

Dietterich, T. G. (2000a). Ensemble methods in
machine learning, Procs. of the First International Workshop on Multiple Classifier Systems, Springer-Verlag, London, UK, pp. 1
15.

Zhou, Z.-H., Wu, J. and Tang, W. (2002). Ensembling neural networks Many could be
better than all, Artificial Intelligence 137(1
2) 239263.

Dietterich, T. G. (2000b). An experimental comparison of three methods for constructing
ensembles of decision trees Bagging, boosting and randomization, Machine Learning
40(2) 139158.
Haykin, S. (1999). Neural NetworksA Comprehensive Foundation, Prentice Hall.
Kuncheva, L. I. (2004). Combining Pattern Classifiers Methods and Algorithms, Wiley.
Kuncheva, L. I. and Whitaker, C. J. (2003). Measures of diversity in classifier ensembles, Machine Learning 51 181207.
Nascimento, D. S. C. and Coelho, A. L. V. (2009).
Ensembling heterogeneous learning models
with boosting, in C. S. Leung, M. Lee and
J. H. Chan (eds), Procs. of 16th. International Conference on Neural Information Processing (ICONIP), Vol. 5863 of Lecture Notes
in Computer Science, pp. 512519.
Opitz, D. and Maclin, R. (1999). Popular ensemble methods An empirical study, Journal of
Artificial Intelligence Research 11 169198.
Piaget, J. (1979). A Construcao do Real na Crianca, Zahar.
Soares, R. G. F., Santana, A., Canuto, A. M. P.
and de Souto, M. C. P. (2006). Using accuracy and diversity to select classifiers to
build ensembles, Procs. of the IEEE International Joint Conference on Neural Networks,
pp. 22892295.

1726