Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

NAVEGAÇÃO ASSISTIDA DE ROBÔS BASEADA EM RECONHECIMENTO E SÍNTESE DE FALA

CAETANO M. RANIERI
Instituto de Ciências Matemática e de Computação, Universidade de São Paulo
Avenida Trabalhador São-carlense, 400  Centro, 13566-590 - São Carlos - SP
E-MAILS cmranieri@yahoo.com.br

SILAS F. R ALVES, IVAN N. SILVA
Departamento de Engenharia Elétrica, Escola de Engenharia de São Carlos, Universidade de São Paulo
Avenida Trabalhador São-carlense, 400  Centro, 13566-590 - São Carlos - SP
E-MAILS salves@usp.br, insilva@sc.usp.br

HUMBERTO FERASOLI-FILHO
Departamento de Computação, Faculdade de Ciências, Universidade Estadual Paulista
Av. Eng. Luiz Edmundo Carrijo Coube, 14-01, Vargem Limpa, 17033-360 - Bauru, SP
E-MAILS cmranieri@yahoo.com.br
Abstract Interactive robots can help people with or without disabilities. In this sense, research has been made in order to help
children with motor disabilities to explore the world around them, which is important for their cognitive development. However,
most of these initiatives lack on natural and intuitive interfaces, or are prohibitively expensive to be adopted in a larger scale.
This paper describes an experimental environment to use speech recognition and synthesis to improve human-robot interaction
(HRI) with children. The proposed system main goal is to perform activities with physically disabled children, however it can be
used with other children. Thus, robots that are attractive, small-sized and relatively low-cost are used to implement such environment. The system recognizes a set of simple speech commands, which allows human-assisted navigation.
Keywords human-robot interaction, speech interaction, assistive technologies, social robots, mobile robotics.
Resumo Robôs interativos podem ajudar as pessoas com ou sem deficiência. Neste sentido, tem-se pesquisado, no intuito de
ajudar crianças com deficiência motora a explorar o mundo ao seu redor, o que é importante para o seu desenvolvimento cognitivo. No entanto, a maioria dessas iniciativas não possui em interfaces naturais e intuitivas, ou são proibitivamente caras para serem adotadas em larga escala. Este artigo descreve um ambiente experimental que utiliza o reconhecimento e síntese de fala para
melhorar a interação_humano-robô (HRI) com as crianças. O principal objetivo do sistema proposto é a realização de atividades
com crianças com deficiência física, no entanto, ele pode ser usado com outras crianças. Assim, os robôs que são atraentes, de
pequeno porte e de custo relativamente baixo são utilizados para implementar tal ambiente. O sistema reconhece um conjunto de
comandos de fala simples, que permitem a navegação humana assistida.
Palavras-chave . Para melhorar a interface, uma abordagem é
dotar os sistemas com emoções, permitindo que os
seres humanos identifiquem a intenção do robô (Breazeal and Scassellati, 1999). Além disso, robôs com
emoções podem servir como base para experimentos
em estudos sobre as emoções dos seres vivos e neurobiologia (Arbib and Fellous, 2004).
Alguns projetos consistem na implementação e
validação adicional de robôs socialmente interativos,
lidando com diferentes aspectos ou aplicações (Malfaz and Salichs, 2004) (Aoyama and Shimomura,
2005) (Breazeal and Scassellati, 1999 Hollinger et
al., 2006). O sistema apresentado neste artigo tem
como objetivo fornecer uma interface para permitir
que um usuário humano controle parcialmente um
robô_móvel dotado de aspectos sociais. O robô apresentado pode servir como uma ferramenta para atividades educativas ou lúdicas para as crianças com e
sem deficiência. Projetos futuros podem aplicar este
sistema em um robô maior para ajudar pessoas idosas.

1 Introdução
O desenvolvimento de robôs socialmente interativos
têm diferentes motivações. Estes robôs podem ajudar
pacientes com certos tipos de deficiência, proporcionando meios de terapia para o autismo (Werry and
Dautenhahn, 1999) ou deficiências motoras graves
(Ranieri et al., 2012). Por outro lado, eles também
podem ajudar as pessoas sem deficiência a realizar
tarefas. Neste último, a literatura aponta para diferentes aplicações de acordo com a idade do público
para as crianças, estes robôs podem servir como tutores ou brinquedos interativos, para os adultos, como
assistentes pessoais, e para os idosos, como companhia ou auxiliares na realização de atividades diárias
(Malfaz and Salichs, 2004).
Uma questão importante para a pesquisa no
campo da robótica social é o desenvolvimento de
Interação Humano-Robô (IHR), com base em interfaces naturais, tais como a interação_por_fala (Aoyama

79

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

dizado, internalizando a impressão de que elas são
incapazes de realizar quaisquer atividades por conta
própria. Com o uso de robôs_móveis, crianças portadoras de deficiência motora severa podem realizar
ações que não estariam aptas a desempenhar sem
ajuda de terceiros. Isso pode lhes dar alguma independência para criar e concretizar suas ideias. Com
isso, existe a expectativa de que elas sintam-se úteis e
motivadas a aprender coisas novas (Ferasoli Filho et
al., 2012).
Um smartphone operado com Android e um robô
móvel são os principais dispositivos do ambiente
proposto. Conforme descrito na seção IV, o robô tem
um suporte mecânico para um smartphone, e um elo
Bluetooth que conecta ambos os dispositivos.
O firmware do robô não possui software_de_controle,
que é realizado unicamente pelo smartphone. Portanto, todo o controlador funciona em um aplicativo de
smartphone, responsável por ambas as funções de
controle do robô e a interface humano-robô. O reconhecedor da Google é responsável pelo reconhecimento_de_fala no sistema descrito, e o eSpeakTTS é
responsável pela síntese de voz em português brasileiro.
Uma vez que um usuário inicia o aplicativo, o
sistema funciona como representado na Fig. 1. O
robô perambula evitando obstáculos e, periodicamente, muda o ângulo de inclinação do smartphone até
que o sistema detecte um rosto na imagem capturada
pela câmera do smartphone. Essa detecção é realizada com uso do classificador em cascata proposto por
Viola e Jones (2001), disponibilizado pela biblioteca
OpenCV4Android. Quando um rosto é reconhecido,
o robô encerra todos os tipos de movimentos, e o
smartphone sintetiza uma frase falada em português
brasileiro através de seus alto-falantes. Nesta frase, o
sistema solicita um comando de voz. Para isso, o
usuário humano pode falar um dentre alguns dos comandos disponíveis, todos em língua_portuguesa.

2 Motivação
A inclusão de crianças com deficiência, em atividades diárias apresenta vários desafios. Elas precisam
de ferramentas especializadas e pessoal treinado, que
estão associados custos elevados. Ainda assim, esta é
uma questão em crescimento constante no Brasil,
onde o número de alunos especiais no ensino público
cresceu de 752.305 em 2011 para 840.433 em 2012
(Brasil, INEP, 2013). No caso de crianças com deficiências motoras graves, o uso de robótica lhes permitiu interagir com o mundo, o que é importante para
o seu desenvolvimento cognitivo (Alvarez et al.,
2013 Tsotsos et al., 1998).
Estas crianças são geralmente incapazes de usar
as interfaces de usuário (UI), tradicionais, tais como
o teclado do computador e mouse, ou joystick. Elas
precisam de diferentes interfaces de usuário que não
dependam de manipulação precisa e que sejam intuitivas. Um canal de comunicação comum para os seres
humanos, mas que ainda é um desafio para os robôs,
é a fala. Ainda que o reconhecimento_de_fala e o processamento_de_linguagem_natural apresentem vários
problemas em aberto, eles podem fornecer uma maneira fácil de interação com algumas limitações.
Há também pesquisas que sugerem que as crianças podem considerar robôs como seres vivos
(Turkle, 2007) -, embora esse tipo de robô ainda esteja fora do alcance com a tecnologia atual - o que pode ajudar a criar cenários de interação interessante
entre crianças e robôs para dar suporte a educação.
No entanto, o custo elevado dos robôs, por vezes,
impede a sua utilização na sala de aula.
Neste sentido, o uso de smartphones pode ser
uma abordagem promissora. Originalmente criados
para servir como assistentes pessoais avançados, os
smartphones aumentaram sua relevância no mercado,
expandiram suas funcionalidades, melhoraram a sua
conectividade e eficiência_energética, e tiveram seu
custo reduzido. Em geral, os smartphones convergiram para um conjunto mínimo de dispositivos, que
estão disponíveis em suas arquiteturas de hardware,
tais como câmeras, acelerômetros, telas sensíveis ao
toque, Wi-Fi ou Bluetooth, e captura e reprodução de
áudio. Cada um desses recursos fornece uma capacidade útil para robôs interativos. Este conjunto de
dispositivos pode melhorar o hardware do robô ao
fornecer novos sensores e atuadores, além de proporcionar uma unidade de processamento versátil. Assim, propõe-se a sua aplicação em um robô_móvel de
entretenimento.
3 Visão Geral do Sistema
Incluir crianças fisicamente debilitadas em atividades recreativas ou educativas, essenciais para o seu
desenvolvimento cognitivo, pode não ser uma tarefa
fácil. Por outro lado, deixar de incluir essas crianças
em tais atividades pode desmotiva-las para o apren-

Fig. 1 .Máquina de estados relacionada ao sistema implementado

80

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

turar vídeo e o microfone do smartphone, ou um fone
de ouvido externo, para capturar áudio. Como atuadores, o sistema utiliza os motores do robô, cujo acionamento resulta na locomoção robô ou na mudança
da inclinação do smartphone.

O smartphone utiliza seu próprio microfone ou
um fone de ouvido externo para capturar qualquer
som longo e alto o suficiente para ser um comando
reconhecível. Se o reconhecedor de fala detecta uma
sentença, ele retornará um conjunto de até 10 possibilidades e a confiança delas. Se qualquer uma dessas
sentenças corresponder a um dos comandos disponíveis, tal comando é executado. Caso contrário, o robô
pede que o usuário repita o comando. Durante a execução de um comando, se o robô encontra um obstáculo, ela se retira, da mesma maneira quando detecta
um obstáculo enquanto perambula.
Os comandos disponíveis referem-se a ações discretas e simples, que podem ser utilizadas para proporcionar uma navegação assistida para o robô. Para
uma melhor compreensão, a Tabela 1 lista os comandos possíveis em Inglês. As ações relacionadas a cada comando também são descritas.

Fig. 2 .Arquitetura de controle implementada.

4 Robôs
Algumas das dificuldades enfrentadas pela robótica assistiva são o custo e a experiência necessária
para trabalhar com robôs (Goodrich and Schultz,
2007). Robôs adaptados para IHR são caros e requerem pessoal especializado, e muitos pesquisadores,
especialmente nas áreas de ciência cognitiva e interfaces humano-computador, não tem acesso a eles
(Burke et al., 2004).
A fim de fornecer uma plataforma robótica com
baixo_custo, desenvolveu-se dois robôs de 100 USD
que são fáceis de replicar e proporcionam alta flexibilidade, Roburguer, fig. 3 (a), e a sua última versão,
Pomodoro, fig. 3 (b). Estes robôs foram criados para
o entretenimento de crianças, portanto, eles usam
cores vivas para chamar a atenção delas, e seu corpo
é projetado com formas arredondadas para não prejudicar o usuário. A estrutura do corpo utiliza peças
de acrílico planas que podem ser facilmente replicadas.
Atualmente trabalha-se para fornecer a estes robôs habilidades emocionais, que podem explorar a
exibição das faces que descrevem um estado emocional, como mostrado na fig. 3. Atualmente, essas faces
não são ainda utilizados, e são mostrados na figura
para ilustrar a possibilidade de implementar esse recurso.

Tabela 1. Comandos disponíveis para a interação de voz.
Comando
Pode ir
Círculo
Girar para trás
Frente
Sentido horário
Sentido anti-horário

Ação
Finaliza interação_por_fala.
Move em uma trajetória circular.
Vira 180  em sentido horário.
Siga em frente, a 6,0 cms, para 1,5 s.
Vire 30 no sentido horário.
Vire 30 para a esquerda.

3.1 Arquitetura de Controle
A arquitetura_de_subsunção, proposta por Rodney Brooks, é a base para a arquitetura_de_controle
implementada no sistema descrito. Esta arquitetura
consiste na organização do sistema em módulos
comportamentais hierárquicos, chamados níveis de
competência, cada qual compreendendo um subsistema_de_controle. Quanto mais elevado o nível de
competência, mais específico o subsistema definido
por ele. Cada nível de competência pode suprimir
entradas ou inibir saídas de comportamentos dos níveis inferiores.
Conforme apresentado na Fig. 2, quatro níveis de
competência compõe a arquitetura_de_controle desenvolvida. Do menor para o maior, são eles evitar obstáculos, perambular, procurar rostos e interação por
fala. No nível evitar obstáculos, os sensores de proximidade são continuamente verificados. Quando o
sistema detecta um obstáculo, o robô recua. Quando
está no nível perambular, o robô se move aleatoriamente pelo ambiente. No nível procurar rostos, o
ângulo de inclinação do smartphone é modificado
periodicamente com o objetivo de aumentar a probabilidade de detectar um rosto humano. Finalmente, no
nível de interação_por_fala, o robô começa, após a
detecção de um rosto, uma interação verbal pela qual
o usuário pode controlar o robô dando comandos de
voz. Uma vez que tal interação começa, as saídas de
procurar rostos e perambular são inibidas.
Como sensores, o sistema utiliza sensores de
proximidade reflexão de luz infravermelha para detectar obstáculos, a câmera do smartphone para cap-

(a)

(b)

Fig. 3 .Robôs Roburguer (a) e Pomodoro (b).

81

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Os robôs também possuem sensores e atuadores
que permitem uma navegação segura, evitando quedas e colisões, conforme apresentado na Tabela 2.
Além disso, um smartphone foi adotado como o
computador embutido.
Tabela 2. Dispositivos disponíveis no Pomodoro.
Dispositivo

Qtd.

Função

Sensor de solo
Sensor de linha no solo
Sensor de proximidade
Sensor de distância
Motor CC
Servo-motores

5
2
4
1
2
2

Evitar queda
Seguir linha
Evitar colisão
Detecção de Objeto (Pomodoro)
Tração Diferencial
Mover smartphones (pan-tilt)

Fig. 4 .Experimento com o robô Roburguer.



O hardware é composto por dois módulos separados a placa embutida, com o circuito para acionar
os motores e ler sensores apresentados na Tabela II, e
um smartphone, responsável pela a arquitetura de
controle. A placa embarcada implementa um sistema
supervisor que não é autônomo, mas recebe comandos de um computador através de uma conexão Bluetooth. Neste caso, o computador é um smartphone
que será anexado ao robô.
O smartphone foi adotado devido ao seu relativo
baixo_custo, conectividade, sensores e poder de processamento. Neste projeto, smartphones foi usado
para capturar o discurso do usuário, procurar o rosto
do usuário a imagem da câmera de dentro, e reproduzir uma fala sintetizada.



5 Experimentos e Resultados



Para validar o sistema desenvolvido, algumas experiências foram realizadas pelo Laboratório de Integração de Sistemas e Dispositivos de Laboratório Inteligente (LISDI) da Unesp, campus Bauru. Embora o
sistema tenha sido experimentado apenas por adultos
sem sinais de deficiência, foi possível avaliar os aspectos técnicos do sistema e sua aplicação como uma
ferramenta para interação_homem-robô.
Nos experimentos, realizados em laboratório para verificar o funcionamento do sistema, o robô foi
colocado sobre uma superfície plana, medindo 80 cm
x 60 cm. Uma parede com 5 cm de altura rodeia esta
plataforma, mostrada na Fig. 4. O smartphone, um
Samsung Galaxy Y com uma câmera traseira e sem
câmera frontal, foi colocado sobre o robô com sua
câmera de volta apontando para frente. Assim, a tela
não pode ser vista pelo utilizador.
Estes experimentos consistiram em testes individuais de cada um dos quatro níveis de competência,
verificando sua funcionalidade adequada. Para registrar os resultados, quatro vídeos foram produzidos,
cada um relacionado a um nível de competência. Estes
vídeos
estão
disponíveis
em
httpwww2.fc.unesp.brgisdispeech. Os procedimentos para testar cada nível de competência e os
respectivos resultados estão descritos abaixo.



82

Evitar obstáculos o robô foi deixado parado
na superfície até que um obstáculo fosse posicionado na frente de seus sensores de proximidade. Desta forma, foi possível conduzir
o robô para lugares diferentes na superfície,
posicionando sucessivamente o obstáculo ao
lado de sensores convenientes.
Perambular um obstáculo foi deixado na
plataforma. O robô, movido em direções diferentes, segue perambulando seguindo os
princípios do nível. Mostra-se que o robô
pode evitar as bordas da plataforma. Quando
o obstáculo situado na plataforma é detectável pelos sensores de proximidade do robô,
o sistema reage rápido o suficiente para evitar colisões. Embora os obstáculos nem
sempre sejam detectáveis antes das colisões
ocorrerem, a integridade do robô é assegurada, pois o robô se move lento o suficiente
para evitar danos durante as colisões.
Buscar rostos neste nível, o comportamento
do robô é semelhante ao comportamento visto no nível perambular. Buscar rostos acrescenta alterações periódicas na inclinação do
smartphone que não afetam os comportamentos definidos pelos níveis mais baixos.
Interação de fala compreende o sistema
como um todo. O teste foi feito enquanto
havia uma conexão de internet Wi-Fi estável, requisito para este nível para funcionar
corretamente. Enquanto não havia nenhum
rosto para ser detectado, o sistema funcionou de forma semelhante ao nível procurar
rostos nível. Usando os sensores de proximidade, foi possível conduzir o robô para
uma posição na qual o rosto do utilizador
pudesse ser detectado. Quando um rosto foi
detectado, todos os movimentos do robô se
encerraram e a interação_por_fala se iniciou.
Todos os comandos implementados foram
experimentados, tendo operado conforme o
esperado. Durante a execução do comando
"frente", o usuário colocou a mão na frente
de um sensor de proximidade, que detectou
como um obstáculo. O robô se retirou e,
através da fala sintetizada, pediu por outro
comando.

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Agradecemos ao Laboratório de Automação Inteligente (LAI), do Departamento de Engenharia Elétrica, do Centro de Tecnologia da Universidade Federal do Espírito Santo pelo apoio.

6 Conclusão
Este trabalho apresentou o uso de uma arquitetura de
controle receptiva aos comandos humanos e suportada pelo uso de smartphones. Pesquisa e detecção de
rostos foi eficaz e interessante dentro da premissa de
que o robô se comporta como um animal de estimação. A interação de voz, durante esta fase de desenvolvimento, apenas interpreta e executa comandos.
Neste sentido, o sistema interativo mostrou resultados
que incentivam a exploração desta área, adaptando e
expandindo-o a fim de atender s demandas reais.
Os próximos passos do desenvolvimento do trabalho contemplarão o refinamento da arquitetura de
controle e do robô_móvel para a realização de testes
com crianças com deficiência. Espera-se que as ações
comportamentais de robôs prendam a atenção das
crianças, dando a ideia de interagir com um pequeno
animal de estimação.
A latência entre o reconhecimento de um comando e a execução da ação correspondente não
compromete a interação. A interação verbal mais rica
entre o usuário e o robô, que aproximaria a ideia de
um ser vivo artificial, será abordada em trabalhos
futuros, com uso de processamento de linguagem
natural - outro campo de pesquisa desafiador. Também neste contexto, a utilização mais incisiva da visão_computacional também pode aumentar as possibilidades de interação com humanos e robôs com o
ambiente_externo, o que estimula o interesse em aumentar o uso desta tecnologia. Por exemplo, a análise
de emoção baseada em expressões faciais podem
melhorar a interação_humano-robô, assim como o
reconhecimento de objetos, a compreensão de cena e
de situação pode melhorar a colaboração entre robôs
e seres humanos ou outros robôs.
Neste trabalho, foi utilizado um smartphone
Samsung Galaxy Y, que não possui câmera frontal.
Em trabalhos futuros, usando um smartphone com
câmera frontal, será possível introduzir expressões
faciais, exibindo-os na tela do smartphone. Isto encorajaria experimentos envolvendo emoções.
A necessidade de algoritmos sofisticados, que
exigem poder computacional do sistema robótico
para respostas rápidas, pode ser solucionado pela
modularidade fornecida pela arquitetura, a qual permite o uso de Wi-Fi e de uma base computacional
remota. Com o rápido desenvolvimento dos dispositivos de hardware móveis, no entanto, espera-se que
o poder de processamento dos smartphones cresça,
alcançando a maior parte dos requisitos para tais projetos.

Referências Bibliográficas
Alvarez, L., Rios, A.M., Adams, K., Encarnação, P.,
Cook, A.M., 2013. From Infancy to Early
Childhood The Role of Augmentative
Manipulation Robotic Tools in Cognitive and
Social Development for Children with Motor
Disabilities, in Pons, J.L., Torricelli, D., Pajaro,
M. (Eds.), Converging Clinical and Engineering
Research on Neurorehabilitation, Biosystems 
Biorobotics. Springer Berlin Heidelberg, pp.
905909.
Aoyama, K., Shimomura, H., 2005. Real world
speech interaction with a humanoid robot on a
layered robot behavior control architecture, in
Robotics and Automation, 2005. ICRA 2005.
Proceedings of the 2005 IEEE International
Conference on. IEEE, pp. 38143819.
Arbib, M.A., Fellous, J.-M., 2004. Emotions from
brain to robot. Trends Cogn. Sci. 8, 554561.
Brasil, INEP, 2013. Censo Escolar da Educação
Básica 2012 Resumo Técnico. Instituto
Nacional de Estudos e Pesquisas Educacionais
Anísio Teixeira.
Breazeal, C., Scassellati, B., 1999. How to build
robots that make friends and influence people,
in Intelligent Robots and Systems, 1999. IROS
99. Proceedings. 1999 IEEERSJ International
Conference on. Presented at the Intelligent
Robots and Systems, 1999. IROS 99.
Proceedings. 1999 IEEERSJ International
Conference
on,
pp.
858863
vol.2.
doi10.1109IROS.1999.812787
Burke, J.L., Murphy, R.R., Rogers, E., Lumelsky,
V.J., Scholtz, J., 2004. Final Report for the
DARPANSF Interdisciplinary Study on HumanRobot Interaction. IEEE Trans. Syst. Man
Cybern. Part C Appl. Rev. 34, 103112.
Emery, N.J., 2000. The eyes have it the
neuroethology, function and evolution of social
gaze. Neurosci. Biobehav. Rev. 24, 581604.
eraso i i o, ., a deira, .A. ., Pegoraro, R.,
A es, S. . dos R., a ad o, ., astos i o,
T.F., 2012. Use of Myoelectric Signals to
Command Mobile Entertainment Robot by
Disabled Children Design and Control
Architecture, in Proceedings of the 3rd IEEE
Biosignals
and
Biorobotics
Conference
(ISSNIP). Presented at the 3rd IEEE Biosignals
and Biorobotics conference (ISSNIP), Manaus.
Goodrich, M.A., Schultz, A.C., 2007. Human-robot
interaction a survey. Found. Trends Hum.Comput. Interact. 1, 203275.
Hollinger, G.A., Georgiev, Y., Manfredi, A.,
Maxwell, B.A., Pezzementi, Z.A., Mitchell, B.,

Agradecimentos
Agradecemos  FAPESP (Fundação de Amparo 
Pesquisa do Estado de São Paulo) financiou este trabalho, processos 201212050-0 e 201301293-1.

83

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Mann, R., 1998. PLAYBOT A visually-guided
robot for physically disabled children. Image
Vis. Comput. 16, 275292. doi10.1016S02628856(97)00088-7
Turkle, S., 2007. Authenticity in the age of digital
companions. Interact. Stud. 8, 501517.
Viola, P., Jones, M., 2001. Rapid object detection
using a boosted cascade of simple features, in
Proceedings of the IEEE Computer Society
Conference on Computer Vision and Pattern
Recognition, CVPR. Presented at the IEEE
Computer Society Conference on Computer
Vision and Pattern Recognition, CVPR, pp. I
511.
Werry, I., Dautenhahn, K., 1999. Applying mobile
robot technology to the rehabilitation of autistic
children, in Procs SIRS99, 7th Symp on
Intelligent Robotic Systems. Presented at the 7th
Symp on Intelligent Robotic Systems, pp. 265
272.

2006. Design of a social mobile robot using
emotion-based decision mechanisms, in
Intelligent Robots and Systems, 2006 IEEERSJ
International Conference on. IEEE, pp. 3093
3098.
Malfaz, M., Salichs, M.A., 2004. A new architecture
for autonomous robots based on emotions, in
Fifth IFAC Symposium on Intelligent
Autonomous Vehicles.
Ranieri, C.M., Alves, S.F. dos R., Ferasoli Filho, H.,
Caldeira, M.A.C., Pegoraro, R., 2012. An
Environment Endowed with a Behavior-Based
Control Architecture to Allow Physically
Disabled Children to Control Mobile Robots, in
Proceedings of Robocontrol 2012 - 5th
Workshop in Applied Robotics and Automation.
Presented at the Robocontrol 2012 - 5th
Workshop in Applied Robotics and Automation.
Tsotsos, J.K., Verghese, G., Dickinson, S., Jenkin,
M., Jepson, A., Milios, E., Nuflo, F., Stevenson,
S., Black, M., Metaxas, D., Culhane, S., Ye, Y.,

84