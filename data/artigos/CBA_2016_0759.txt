XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

A LOW-COST POSITION AND VELOCITY ESTIMATION SYSTEM FOR
MULTIROTOR AERIAL VEHICLES USING A STATIC KINECT SENSOR
Luiz Manoel Santos Santana, Davi Antonio dos Santos, Icaro Bezerra Viana,
Raphael Ballet


Instituto Tecnologico de Aeronautica, Praca Mal. Eduardo Gomes, 50. Vila das Acacias, 12228-900.
Sao Jose dos Campos, Sao Paulo, Brasil
Emails luizmss@ita.br, davists@ita.br, icaro@ita.br, raphaelballet@hotmail.com
Abstract Indoor estimation of position and velocity of a multirotor aerial vehicle (MAV) is frequently
required for experimental evaluation of control laws and on-board navigation systems. The present work proposes
a low-cost indoor position and velocity estimation system using a static Kinect sensor fixed on the ceiling and
pointing downwards. The Kinect sensor consists of an RGB camera, an infrared projector and a CMOS camera.
Using the RGB camera, it is possible to determine the horizontal position of the vehicle. On the other hand,
the infrared projector together with the CMOS camera provide depth images which allows altitude estimation.
The Kinect measurements are acquired in a desktop computer and processed in MATLAB. The data processing
includes 3D position determination from a camera model and 3D positionvelocity estimation using a Kalman
filter. The proposed system is demonstrated and evaluated experimentally by means of the feedback control of
an MAV.
Keywords

State estimation, multirotor aerial vehicles, Kinect sensor.

Resumo Um sistema de estimacao de posicao e velocidade de multicopteros em ambiente interior e frequentemente requerido para fins de avaliacao de leis de controle e algoritmos de navegacao. O presente trabalho
propoe um tal sistema de baixo_custo usando um sensor Kinect fixado ao teto e apontado verticalmente para
baixo. O sensor Kinect e composto de uma camera RGB, um emissor de sinal infravermelho e uma camera
CMOS. Mediante a camera RGB, e possvel determinar a posicao horizontal do veculo. A camera CMOS, por
sua vez, prove uma imagem de profundidade baseada no tempo de viagem do sinal infravermelho emitido. Com
essa ultima imagem, e possvel determinar a altitude de veculo. As medidas do Kinect sao adquiridas num computador e processadas em MATLAB. O processamento de dados inclui a determinacao de posicao 3D a partir
do modelo do sensor, assim como estimacao de posicaovelocidade 3D usando um filtro de Kalman. O sistema
proposto e demonstrado e avaliado experimentalmente mediante do controle_realimentado de um MAV.
Palavras-chave

.

Introduction

In the last few years, the world has seen an
increasing interest for unmanned aerial vehicles
(UAV) in both industry and academia. In particular, small multirotor aerial vehicles (MAV)
have become very popular due to their simplicity, low cost, and capability to fly in confined areas. These vehicles are used in several applications, such as precision agriculture (Zhang and
Kovacs, 2012), disaster monitoring (Alvissalim
et al., 2012), search and rescue (Naidoo et al.,
2011), surveillance (Grover, 2015), powerline inspection (Luque-Vega et al., 2014), aerial photography (Widodo and Sunardi, 2014), and building inspection (Emelianov et al., 2014 Bulgakov
et al., 2014).
Many papers on control and navigation of
MAVs have appeared in the literature in the last
five years (Prado and dos Santos, 2014 Viana
et al., 2015a Viana et al., 2015b dos Santos
et al., 2013 Crowther et al., 2011 Mahony et al.,
2012 Yan et al., 2013). In such works, experimental evaluation is always required to assess the
performance of the proposed methods. In particular, indoor flight tests are more common for allowing an easier control of the flight environment.
Some consolidated research groups have used ex-

ISSN 2525-8311

pensive commercial tracking systems based on infrared cameras (Campbell et al., 2012 Ducard and
DAndrea, 2009 Zhou and Schwager, 2014).
The recent cost reduction of the so-called
time-of-flight cameras has encouraged many research applications. In particular, the Microsoft
Kinect sensor appears in many of those applications. Examples of Kinect applications are found
in estimation of robots 3D position (Siradjuddin
et al., 2012 El-laithy et al., 2012 Ganganath
and Leung, 2012), in 3D object tracking (Chow
et al., 2012), in medicine (Clark et al., 2012), and
in education (Hsu, 2011), just to cite a few.
The present paper proposes a low-cost position and velocity estimation system for indoor
evaluation of MAV guidance and navigation methods. The system consists of a Kinect sensor fixed
on the ceiling and pointing downwards, and a computer for data processing. The MAV under test
carries a circular red mark for providing contrast
with respect to the floor (the background). The
Kinect images are processed in MATLAB using
color and circle segmentation for 3D position determination, as well as a Kalman filter for position
smoothing and 3D velocity estimation. The proposed system is evaluated experimentally through
static and flight tests with an MAV.
The remaining text is organized in the follow-

2671

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

ing manner. Section 2 details the main components of the proposed estimation system. Section 3 details the implementation of the system.
Section 4 evaluates the performance of the proposed system experimentally. Finally, Section 5
concludes the paper.
2

The System Components

also receive attitude and throttle commands via
an Wi-Fi connection from an external computer.
For more details about the navigation and control
technology used in the AR.Drone, we suggest to
read the reference (Bristeau et al., 2011).
In the present work, a circular red mark is attached on the top of the AR.Drone, as depicted in
Figure 2. In this case, there is a sufficient contrast
between the vehicle and the floor.

The proposed low-cost 3D positionvelocity estimation system consists of three main hardware
components a Kinect sensor fixed on the ceiling
and pointing downwards a ground computer for
image processing and state estimation and the
object to be tracked, which, in particular, is an
MAV. Figure 1 illustrates the overall system.
Kinect

IR FOV

MAV

Figure 2 The AR.Drone with a circular red mark.

2.3

Figure 1 The overall positionvelocity estimation
system.
The following subsections describe the main
components of the system.
2.1

Kinect Sensor

The Kinect sensor is a low-cost time-of-flight camera offered by Microsoft for the XBoxs video game
consoles and for Windows operating system. It
combines an RGB sensor with a depth sensor. The
latter consists of an infrared (IR) projector and a
monochrome CMOS sensor (Nakamura, 2011). In
our estimation system, it provides the raw data
sufficient for determining the 3D position of a red
mark placed on the top of an MAV.
The Windows version of the Kinect sensor is
adopted in the present work. It is installed on the
ceiling at a height h from the floor and pointing
downwards vertically. Its field of view (FOV) is of
53o about XC and 47o about YC .
2.2

Ground Computer

The ground computer receives the Kinect data via
an USB interface. The RGB and depth images
are acquired and processed in MATLAB, using
commands available in its Image Processing Toolbox. In short, from the depth image, we immediately obtain the vehicles vertical coordinate z
(altitude). On the other hand, the RGB images
are segmented for separating the circular red mark
from the backgroud. The horizontal coordinates
(x and y) of the marks centroid are then computed in pixels. Using a pinhole camera model,
this centroid is converted to millimeters. The x,
y, and z are used as measurement in a Kalman filter (KF) that estimates 3D position and velocity.
Finally, the ground computer delivers the KF position and velocity via UDP protocol to an external
computer responsible for the automatic position
control.
3

Position and Velocity Estimation

The implementation of the position and velocity estimation system is divided into three parts
image processing, position determination, and
Kalman filtering.

Multirotor Aerial Vehicle

The multirotor aerial vehicle (MAV) chosen for
evaluating the proposed estimation system is a
Parrot AR.Drone 2 quadrotor vehicle. It is a very
popular low-cost MAV suitable for indoor operation. Originally, it was developed to be manually
controlled by a smartphone applicative, but it can

ISSN 2525-8311

3.1

Image Processing

The image processing is conducted in three steps
in the following sequence
1. Conversion of the color representation from
the RGB model to the HSV model.

2672

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

2. Image segmentation using thresholding in the
HSV space. The output of this operation is
a binary image where the original red pixels
are converted into white and the other pixels
are converted to black.
3. Circle recognition using the Hough transform.
The output of this operation is the pixel coordinates of the black circle of the binary image
generated in 2.
The above image processing methods are
standard. For the readers who are interested in
the details about them, we suggest reading the
reference (Gonzalez et al., 2009).
3.2

Denote the algebraic vectors representing
BG
CG
r
and r CG in SG by rG and rG , respectively. On the other hand, denote the algebraic
BC
vector representing r BC in SC by rC . Moreover, denote the attitude matrix representing the
attitude of SC w.r.t. SG by DCG . Using the
above notation, one can rewrite equation (1) as
BG

BG

rG
CG

where rG

DCG

ZC

YI

XI
BC

H
 CG

XB

 GB

YB


0
 sin   ,
cos 

ZG

O

YG

XG

zC
xI ,
f
zC
yC 
yI ,
f

xC 

Figure 3 Cartesian coordinate systems and a pinhole camera model.
Let the geometric vectors r BC and r BG describe the CM position w.r.t. SC and SG , respectively. On the other hand, let the geometric vector
r CG describe the position of C w.r.t. SG . From
the figure, one can write

ISSN 2525-8311

BG

 r

(4)
(5)

Kalman Filtering

x(t)  Ax(t) + w(t)

r

(3)

In this section, we design a discrete-time Kalman
BG
filter for estimating the MAV position rG
,
BG
T
T
rx ry rz  and velocity rG
, vx vy vz  .
To begin with, define the state vector x ,
rx ry rz vx vy vz T . Now, we describe the position
dynamics as the integral of a sum of velocity and
velocity noise. On the other hand, we model the
velocity dynamics as the integral of acceleration
noise. Therefore, the continuous-time state-space
model for x is given by

image plane


0
cos 
sin 

which corresponds to a rotation of  rad about
BC
T
XC , and rC , xC yC zC  has to be computed
from the output of the image processing.
Suppose that, from the image processing, it
was found that the centroid of the red mark is
located at (xI , yI ) in SI coordinates. On the other
hand, consider that zC is directly provided by the
depth camera. Therefore, using a pinhole camera
model (Hartley and Zisserman, 2003), the other
BC
two components of rC can be computed by

3.3
P

ZB

(xC , yC , zC )

1
 0
0

f

XC

(xI , yI )

T

where f is the camera focal length, which can be
estimated using standard calibration packages.

C

YC

(2)

, 0 0 h is supposed to be known,


Position Determination

Figure 3 illustrates an MAV and four Cartesian
coordinate systems (CCS). The body CCS SB ,
XB , YB , ZB  is attached to the vehicles structure, with its origin at vehicles center of mass
(CM) and the ZB axis perpendicular to the rotor
plane and pointing upwards. The ground CCS
SG , XG , YG , ZG  is fixed on the ground with
the origin at a known point O and the ZG axis
pointing upwards, aligned with the local vertical.
The camera CCS SC , XC , YC , ZC  is static
with respect to SG  its origin is placed at the camera optical center C and its ZC axis points downwards, parallel to the camera optical axis. Finally,
the image CCS SI , XI , YI  is parallel to the
XY plane of SC and is centered at the camera
principal point P .


T
BC
CG
 DCG rC + rG ,

CG

+ r

BC

.

(1)

(6)

where w  R6 is the continuous-time state noise
vector and


033
I3
A,
.
(7)
033 033
The discrete-time state equation equivalent to
(7) is immediately obtained as
xk+1  xk + wk ,

(8)

2673

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

where   R66 is the state transition matrix
given by


I3
Ts I3

,
(9)
033
I3

Table 1 Statistical test with 10 samples.

ex
ey
ez
x
y
z
x
y
z

w1
0.004
0.045
0.034
0.004
0.045
0.734
0.001
0.001
0.007

w2
0.001
0.050
0.012
0.501
-0.800
0.687
0.002
0.002
0.008

w3
0.048
0.033
0.058
-0.451
-0.783
0.758
0.001
0.005
0.005

w4
0.002
0.019
0.056
-0.497
0.730
0.756
0.002
0.002
0.008

w5
0.016
0.008
0.012
0.484
0.758
0.712
0.005
0.006
0.009

with Ts representing the sampling time and wk 
R6 is the discrete-time state noise vector, which
is assumed to be a zero-mean white Gaussian sequence with covariance Qk .
Assume that the initial state is a Gaussian
vector with known mean x and covariance P.
Now, define the filter measurement vector y
to be the CM position as computed by equation
BG
(2), i.e., y , rG . Therefore, from the state
definition, one can establish the following discretetime measurement equation

Define the following metric to evaluate the
system performance regarding its capability to estimate position

yk+1  Cxk+1 + vk+1 ,

eik  kpik  pik k.

(10)

where C  R36 is the measurement matrix given
by


C  I3 033
(11)
and vk+1 is the measurement noise, which is assumed to be a zero-mean white Gaussian sequence
with known covariance Rk+1 .
Finally, using the state-space model given by
(8) and (10), the discrete-time formulation of the
Kalman filter algorithm (Bar-Shalom et al., 2004)
can be immediately applied to optimally estimate
the state vector xk over time.
4

Results

The low-cost position and velocity estimation
system proposed in this paper is now evaluated experimentally. For this end, two experiments are conducted a static test and a flight
test of feedback position control of an AR.Drone
2 quadrotor vehicle. The KF covariance matrices P0 , Q
Rk are tuned with values
k , and 2
P0 
diag
1.0

10
I3 , 1.0  102 I3 , Qk 

8
diag 1.0  10 I3 , 1.0  107 I3 , and Rk  1.0
105 I3 . Using least-squares estimation, the camera focal length is calibrated in f x  570 and
f y  533 . The Kinect is installed at H  3.3
m above the floor. The sampling time is set to
Ts  0.08 s.
4.1

Static Evaluation

The first test to evaluate the estimation system
present in Section 23 is a static one. The target, which is a circular red mark with a diameter
of 10 cm, is placed with its center at a given position pi with zero velocity. The position pi is
then measured by means of a measuring tape and
estimated with the proposed system. Denote the
position measure by pi and the corresponding estimate by pi .

ISSN 2525-8311

(12)

The above test is repeated to obtain 10 samples of
eik . The sample mean i and standard deviation
 i are registered in Table 1. The test is realized
at five different positions, corresponding to i 
1, 2, ..., 5.
where it is maintained static validation of the
positions estimated by the proposed system were
made during tests with metric tapes. For this evaluation, it was taken 10 measurements for five desired variables of position (waypoints) in a 3D indoor environment. The test waypoints are defined
as w1  0 0 0.7T m, w2  0.5  0.75 0.7T m,
w3  0.5  0.75 0.7T m, w4  0.5 0.75 0.7T
m, w5  0.5 0.75 0.7T m. The precision of this
test are showed in Table 1 which includes summary statistics such as the mean , standard deviation , and the error between the desired values
and the mean position of each dimension provided
by the Kalman Filter output.
As the reader can see in Table 1, estimated
position errors stay below 2 cm in most samples,
and is around 5 cm in the worst case, that is acceptable for our application.
4.2

Closed-Loop Validation

In this subsection, experimental results validate
the proposed estimation system by using a position controller to guide the AR.Drone quadrotor in the environment. The waypoints chosen for the flight test are trajectories composed
by a set of straight lines from the initial position ri  0 0 0.5T passing by the waypoints
w1  0.4 0 0.5T , w2  0.4  0.5 0.5T , w3 
0.4  0.5 0.5T , w4  0.4 0.5 0.5T , w5 
0.4 0.5 0.5T . The position controller is composed
by the altitude and horizontal controllers. The altitude control is a Proportional (P) controller and
the horizontal control is a Proportional-Derivative
(PD) controller. The constant velocity chosen in
the trajectory generation was v  0.5 ms2 .

2674

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

Analyzing the flight data obtained through
the proposed system, Figure 4 shows the innovation ek during the flight test. As it can be seen in
Figure 4 the variable ek tends to converge to zero,
except for the waypoint switching transients.
ex

0.6

ey

ez

ekm

0.4
0.2
0
0.2
0.4
0

5

10

Times

15

20

25

Figure 4 Innovation in a flight test.

G

Z m

YGm

XGm

For evaluation of the position estimation were
generated separate graphics for each position state
comparing with their desired values, see Figure 5.
Note that the estimated positions are well close to
the waypoints references, where the position error
oscillate by 0.02m around their desired values,
that is a good precision.
0.5
0
0.5
0
0.5
0
0.5
0
0.55

5

10

15

20

25

5

10

15

20

25

5

10

15

0.5
0.45
0

Kalman Filter Estimation
Waypoint References

Times

20

25

Figure 5 Position state estimation.

5

Conclusions

This paper demonstrated a low-cost alternative
for the estimation of velocity and position of a
MAV in indoor flight. To develop this solution
it was used three main components a low-cost
Kinect sensor a MAV and a ground computer
equipped with MATLAB. First, from the sensor
data provided, the computer_vision methods were
used to identify and tracking a round red color
mark attached over the AR.Drone 2 quadrotor. To
find the round color mark and determine its centers the Hough transform (HT) was used. After
the centroid of the color mark be well detected, to
determine its position coordinates in SG from the
image coordinates SI , we used geometric transformation as detailed in section 3. In sequence, to
estimate the velocities, we aided a Kalman filter
as output of the system.
Finally, the proposed system was evaluated
trough a static experiment and by using a closedloop validation. In both, the experimental results

ISSN 2525-8311

showed a good performance of the estimation system, where the errors in the position estimation
oscillated within a range allowed for our application, which is intended to validate guidance and
navigation methods in the future.
Acknowledgments
We would like to thank Conselho Nacional de Desenvolvimento Cientfico e Tecnologico (CNPq)
(Grant 4752512013), Fundacao de Amparo
a Pesquisa do Estado de Sao Paulo (Grant
201504393-2) and Coordenacao de Aperfeicoamento de Pessoal de Nvel Superior for supporting this project. The authors are also grateful to
Elio Tecnologia.
References
Alvissalim, M. S., Zaman, B., Hafizh, Z. A.,
Masum, M. A., Jati, G., Jatmiko, W. and
Mursanto, P. (2012).
Swarm quadrotor
robots for telecommunication network coverage area expansion in disaster area, SICE
Annual Conference (SICE), 2012 Proceedings
of, IEEE, pp. 22562261.
Bar-Shalom, Y., Li, X. R. and Kirubarajan, T.
(2004). Estimation with applications to tracking and navigation theory algorithms and
software, John Wiley  Sons.
Bristeau, P.-J., Callou, F., Vissiere, D. and Petit, N. (2011). The Navigation and Control technology inside the AR . Drone micro
UAV, Proceedings of the 18th IFAC World
Congress, 2011 18 14771484.
Bulgakov, A., Emelianov, S., Bock, T. and Sayfeddine, D. (2014). Control of hovering altitude
of a quadrotor with shifted center of gravity for inspection of high-rise structures, Proceedings of the 31st International Symposium
on Automation and Robotics in Construction
(ISARC), Sydney, Australia.
Campbell, J., Hamilton, J., Iskandarani, M. and
Givigi, S. (2012). A systems approach for
the development of a quadrotor aircraft, Systems Conference (SysCon), 2012 IEEE International, pp. 17.
Chow, J., Ang, K., Lichti, D. and Teskey, W.
(2012). Performance analysis of a low-cost
triangulation-based 3d camera Microsoft
kinect system, International Society for Photogrammetry and Remote Sensing Congress
(ISPRS), Vol. 39, pp. 175180.
Clark, R. A., Pua, Y.-H., Fortin, K., Ritchie, C.,
Webster, K. E., Denehy, L. and Bryant, A. L.

2675

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

(2012). Validity of the microsoft_kinect for assessment of postural control, Gait  posture
36(3) 372377.
Crowther, B., Lanzon, A., Maya-Gonzalez, M.
and Langkamp, D. (2011). Kinematic analysis and control design for a nonplanar multirotor vehicle, Journal of Guidance, Control,
and Dynamics 34(4) 11571171.
dos Santos, D. A., Saotome, O. and Cela,
A. (2013).
Trajectory control of multirotor helicopters with thrust vector constraints, Control  Automation (MED), 2013
21st Mediterranean Conference on, IEEE,
pp. 375379.
Ducard, G. and DAndrea, R. (2009).
Autonomous quadrotor flight using a vision system and accommodating frames misalignment, Industrial Embedded Systems, 2009.
SIES 09. IEEE International Symposium
on, pp. 261264.
El-laithy, R. A., Huang, J. and Yeh, M.
(2012). Study on the use of microsoft_kinect
for robotics applications, Position Location
and Navigation Symposium (PLANS), 2012
IEEEION, pp. 12801288.
Emelianov, S., Bulgakow, A. and Sayfeddine, D.
(2014). Aerial laser inspection of buildings facades using quadrotor, Procedia Engineering
85 140146.
Ganganath, N. and Leung, H. (2012). Mobile
robot localization using odometry and kinect
sensor, Emerging Signal Processing Applications (ESPA), 2012 IEEE International Conference on, pp. 9194.
Gonzalez, R. C., Eddins, S. L. and Woods, R. E.
(2009). Digital image processing using MATLAB, Gatesmark Publishing.
Grover, M. (2015). International journal of engineering sciences  research technology low
cost flying bot used for aerial photography
and face detection.
Hartley, R. and Zisserman, A. (2003). Multiple view geometry in computer_vision, Cambridge university press.
Hsu, H.-m. J. (2011). The potential of kinect in
education, International Journal of Information and Education Technology 1(5) 365.
Luque-Vega,
L. F.,
Castillo-Toledo,
B.,
Loukianov, A. and Gonzalez-Jimenez,
L. E. (2014). Power line inspection via
an unmanned aerial system based on the
quadrotor helicopter, Mediterranean Electrotechnical Conference (MELECON), 2014
17th IEEE, pp. 393397.

ISSN 2525-8311

Mahony, R., Kumar, V. and Corke, P. (2012).
Multirotor aerial vehicles Modeling, estimation, and control of quadrotor, IEEE
Robotics Automation Magazine 19(3) 2032.
Naidoo, Y., Stopforth, R. and Bright, G. (2011).
Development of an uav for search  rescue
applications, AFRICON, 2011, IEEE, pp. 1
6.
Nakamura, T. (2011).
Real-time 3-d object
tracking using kinect sensor, Robotics and
Biomimetics (ROBIO), 2011 IEEE International Conference on, pp. 784788.
Prado, I. A. A. and dos Santos, D. A. (2014). A
safe position tracking strategy for multirotor
helicopters, 22nd Mediterranean Conference
on Control and Automation.
Siradjuddin, I., Behera, L., McGinnity, T. M. and
Coleman, S. (2012). A position based visual
tracking system for a 7 dof robot manipulator using a kinect camera, Neural Networks
(IJCNN), The 2012 International Joint Conference on, IEEE, pp. 17.
Viana, I. B., Prado, I. A. A., dos Santos, D. A.
and Goes, L. C. S. (2015a). Formation flight
control of multirotor helicopters with collision avoidance, Unmanned Aircraft Systems
(ICUAS), 2015 International Conference on,
IEEE, pp. 757764.
Viana, I. B., Prado, I. A. A., dos Santos, D. A. and
Goes, L. C. S. (2015b). Trajectory tracking
control of an aerial robot with obstacle avoidance, IFAC-PapersOnLine 48(19) 8186.
Widodo, N. S. and Sunardi, A. Y. (2014). Low
cost open source based uav for aerial photography.
Yan, J., dos Santos, D. A. and Bernstein,
D. S. (2013). Adaptive control with convex and saturation constraints, ASME 2013
Dynamic Systems and Control Conference,
American Society of Mechanical Engineers,
pp. V001T02A002V001T02A002.
Zhang, C. and Kovacs, J. M. (2012). The application of small unmanned aerial systems
for precision agriculture a review, Precision
agriculture 13(6) 693712.
Zhou, D. and Schwager, M. (2014).
Vector field following for quadrotors using differential flatness, Robotics and Automation
(ICRA), 2014 IEEE International Conference on, IEEE, pp. 65676572.

2676