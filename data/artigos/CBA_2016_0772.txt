XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

ROBOTS GROUP WITH LEADER APPLIED IN AUTONOMOUS NAVIGATION SYSTEM INSPIRED
BY SWARM ROBOTICS
MÁRCIO MENDONÇA, IVAN R. CHRUN, LÚCIA V. R. DE ARRUDA
Laboratório de Automação e Sistemas de Controle Avançado, CPGEI, Universidade Tecnológica Federal do
Paraná
Av. Sete de Setembro, 3165 - Rebouças CEP 80230-901  CuritibaPR
E-mails mendonca@utfpr.edu.br, ivanchrun@gmail.com, lvrarruda@utfpr.edu.br

MARELO C.G. REGATIERI
Universidade Tecnológica Federal do Paraná
Av. Alberto Carazai, 1640 - Centro CEP86300-000 - Cornélio ProcópioPR
E-mails marcelocgregatieri@gmail.com
Abstract This paper presents a navigation strategy group based on Collective Intelligence techniques for the control of autonomous robots using Simplified Dynamics Cognitive Networks (s-DCN), an evolution of Fuzzy Cognitive Maps (FCM), in a multiple objective group navigation environment with a navigation strategy to avoid from obstacles and conduct an object to a target
position. Constructive aspects of controllers and initial results will be presented. Finally, simulated results of the strategys first
part in two dimensions, using a graphical environment, are presented in four different scenarios, in order to initially suggest the
capability of group navigation, adaptability, hierarchical decision-making execution and autonomy of the agents.
Keywords Swarm robotics, fuzzy cognitive maps, dynamic cognitive networks, autonomous robotic navigation.
Resumo Este trabalho apresenta uma estratégia de navegação em grupo baseada em técnicas de Inteligência Coletiva para o
controle_de_robôs autônomos através de Redes Cognitivas Dinâmicas Simplificadas (s-DCN), uma evolução de Mapas Cognitivos Fuzzy (FCM), em um ambiente de navegação em grupo com multiobjectivos empregando uma estratégia de navegação para
desviar de obstáculos e conduzir um objetivo  uma posição alvo. Aspectos construtivos e resultados iniciais dos controladores
serão apresentados. Finalmente, resultados simulados, usando um ambiente gráfico, são apresentados em quatro diferentes cenários sugerem a capacidade de navegação em grupo, adaptabilidade, tomada de decisão hierárquica e autonomia dos agentes.
Palavras-chave .

1

Introduction

Fuzzy Cognitive Maps (FCM) is a modeling
methodology (Kosko, 1986) which extended the
Cognitive Maps for the inclusion of Fuzzy Logic, or
Fuzzy numbers in some cases, thus presenting a system with semantic features of Fuzzy systems and stability properties of Artificial Neural Network (Stylios
et al., 2008). Recently the FCMs have been conceptualized as a combination of Fuzzy Logic, Semantic
networks, Artificial Neural Networks, Expert Systems (Papageorgiou and Salmeron, 2013). A graphic
illustration of a FCM is represented by a cyclic or
acyclic graph, with it causal relationships are determined, in some cases, by Fuzzy numbers to quantify
the weights between the arches among the concepts.
The nodes (concepts) are used to describe the characteristic of the main system behavior and are connected to each other with a fixed weight value representing the relationship level of cause and effect between
concepts (in practice the concepts may be state variables of the problem) specifically, in this work, the
concepts are sensors and actuators of a robot or mobile agent. The FCM may not stabilize, and oscillate
in some cases, or even present a chaotic behavior. In
ISSN 2525-8311

normalized systems, with range -1, 1 (Papageorgiou, 2014).
The Dynamics Cognitive Networks emerged as
an evolution of Cognitive Maps and offers more possibilities in the management of causal structures and
the modeling of systems that does not presents strong
linearity and accentuated temporal phenomena (Mendonça and Arruda, 2015 Miao et al., 2001). The values of the weights associated to the arcs can vary
over time according to new types of causal relationship and concepts of the DCN, different from the
Cognitive maps and Fuzzy Cognitive maps, which
have their weights at fixed values thus, allowing the
construction of dynamic cognitive models that adapt
naturally. There is other DCN proposals in the literature, e.g., the work of Miao et al. (2010). The s-DCN
(simplified-DCN), proposal of this article, is a simplification of the original DCN in Mendonça and Arruda (2015).
The Dynamic Cognitive Networks, in which the
simplified model, used in this work, was been abstracted from, add new types of relationships to
FCMs classical cognitive model in summary, it allows the treatment of occurrence of events, the time
in an indirect way, and non-linearities in general.
Which are two major disadvantages of the classic

2707

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

models, as it does not address the time due to the
simultaneous occurrence of all causal relationships
and functions modeled by classical FCMs are only
monotonic, major construction details of the DCN
may be conferred on the doctoral thesis book of
Mendonça and Arruda (2015). The cognitive model
used in this research is a simplification of the original
version, because only applies relationships selection
that switches the operating states of the controllers
and have a dynamic tuning algorithm those are explained in the next section.
The term "autonomy" refers not only to the capacity for action and decision of an artificial control
system, but also the ability of adaptation of the decision-making mechanism (Mataric, 2007 Smithers,
1997 Russel and Norvig, 1995). A priori, one difficulty in the area of autonomous mobile robotics, is
the higher the navigation area, the variety of situations that will need decision-making, or control actions, from the agents will be proportionally higher
according to the increase of the environment dimensions (Cliff, 2003).
In this context, to validate the ability of the sDCN controllers autonomy, for the presented Group
Autonomous Navigation System, four simulations of
the first stage were performed using scenarios with
different situations. In general terms, an agent is autonomous if it can act without direct human intervention. In this context, an agent is proactive if it only
reacts to environmental stimuli, has own initiative to
take actions to achieve its objectives (Mataric, 2007).
This research proposes the construction of autonomous and pro-active agents, especially the leader
(this agent should take initiatives to meet their targets
or objectives), because the followers practically follow the leader. Section 2 will address the agents
navigation strategy for achieving the proposed goals
in more details. Moreover, intelligent agents can be
classified as one of the major areas of Computational
Intelligent Systems.
It is not scope of this work to develop the architecture of the controllers. However, it will be based
in behavior (BBC  Behavior Based Controllers), due
the following characteristics it is based by characteristics of Subsumption Architecture, purely reactive
however, the controllers go beyond that, e.g., by the
use of dynamic adaptation algorithms and complex
strategy navigation. The philosophy of behaviors
based systems requires the information be used as
non-centralized intern representation, or not manipulated in a centralized way it is suggested in Swarm
Robotics. In short, since the BBC are based in the
concepts of reactive systems (but not limited to it), it
also determines that behaviors should be incrementally added to the system, and that they can be executed
simultaneously, in parallel, and not sequentially, one
at a time. These suggestions are not definitive solutions (Mataric, 2007). The motivation for the development of the s-DCN controllers and for the navigation strategy is to use a future Behavior-Based Archi-

ISSN 2525-8311

tecture. Beside the concepts cited, for the control of
only one agent in complex task it is suggested the use
of hybrid architectures, differently, as the case of this
work, for the control of multiple robots in group.
Other motivation and inspirations of this article is
based by the paper of Ghaffari and Esfahanian
(2013).
The objective of this work is a manipulation of
the object in group, using cooperation and autonomy
of agents following a leader. There are studies about
object manipulation in the literature, e.g., ParraGonzalez et al. (2009), in which compares different
algorithms for object manipulation problem but their
purposes were the optimization of number of changes
in direction of object along the path.
The proposed controller provides tuning and adaptation capacity, task management, and finally, ability of interaction between the robots by the use of an
algorithm inspired by collective intelligence. Researches using intelligent computer systems and
Swarm Robotics have been applied in the construction of autonomous navigation systems for one or
group of robots, demonstrating an ability to execute
complex tasks, especially in applications with little or
no knowledge of the environment (Costa and Gouvea, 2010 Ghaffari and Esfahanian, 2013 Russel
and Norvig, 1995 Sahin and Spears, 2005).
The modeling of the navigation system used in
the robots is based on simplified-Cognitive Networks
Dynamic (s-DCN). The original DCN, for being an
evolved technique of Cognitive maps, consists in a
portable algorithm with low computational complexity, with the possibility of being embedded in different
types of microcontrollers Mendonça and Arruda
(2015). Its final cognitive model has similarities with
Fuzzy Cognitive Map (FCM) models, with the inclusion of other types of relationships and concepts, in
which can be implemented adaptive tuning of the
weights in real time, between the causal relationships
of the concepts. In this work, it is used a Reinforcement Learning Algorithm with tuning heuristics rules.
The s-DCN will be addressed in developing section
of this article.
Specifically, the objective is to develop navigation logic to control robots in a group using the simplified-Dynamic Cognitive Networks. The environment is partially known, i.e., the position of the piece
upper vertex (triangle) and the target (X) are previously known, in particular by the leader. This navigation strategy is based on following an established
leader, with the leader in the superior vertex, navigating in a triangle formation. Another possible strategy is making the leader virtual and in the triangles
center of gravity, e.g., the work of Aso et al. (2008),
that uses this principle to control and stability a group
of robots.
In the field of multi-robot systems consisting of
many autonomous robots, the research area that deals
with problems such that each robot has insufficiency
to solve a given task is called Swarm Robotics (Sa-

2708

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

hin, 2005). It usually assumes that the robots or
agents are homogeneous, i.e., they have the same
specifications, using individual controllers. Generally, to control a robotic swarm without using a global
controller, each robot needs to have sufcient capability for autonomous behavior acquisition. However,
to our knowledge, there are no methods satisfying
this requirement at the present stage (Ohkura et al.,
2010).
Similar concepts have been proposed so far, such
as cellular robotics (Xiao et al., 2014), collective
robotics (Kube and Zhang, 1997), distributed autonomous robotic systems (Asama et al., 1995), and aerial robotic swarms (Dono and Chung, 2013). However, Beni (2005) clarifies the position of Swarm Robotics by giving importance to the emergent behavioral pattern in a swarm robotic than o other approaches. This paper is organized. Section 2 presents
the background and development of the proposed
strategy for group navigation and the proposed objectives. Section 3, presents and discuss the initial results and finally Section 4 concludes and suggest
future works.
2 Background and Development of the Navigation
Strategy
The task proposed in this work task is inspired
by the work of Ghaffari and Esfahanian (2013). In a
similar way, it is proposed a group of three robots
with a triangle formation however, with three distinct
stages, as shown in the finite state machine at figure
1 of which, only the first was simulated for different
scenarios, i.e., step 1.

Figure 1. Finite State Machine

The Finite State Machine vocabulary is a) Initial
navigation state b) Avoid obstacles and go towards
the object (triangle) c) Pick up the object and move,
in formation, to the target (X), avoiding obstacles
along the way d) Return to the initial state if there is
another goaltarget or if it have completed the strategy.
In short, the aim of the robot group will have
three distinct states, deviate from the initial obstacles,
when they reach the object the group will get in formation, because of its distributed representation of
the map, each of the reference points discovered by
the agents are stored in its own behavior. And finally,
lead it to the goal location, avoiding an obstacle between triangle formation and the goal, "X" point,
figure 2 illustrates the steps with a state machine.
The autonomous agents use decentralized control, i.e., each agent will have its own s-DCN with
ISSN 2525-8311

decision-making, with the functionality of follow the
leader to the two followers robots, and move towards the object and lead it to the final position while
in formation. In particular, the first step, this is simulated in this work.

Figure 2. Overview of the environment and the stages progression

As for the leader, its features are similar to the
followers, avoid obstacles, and go towards to the top
corner of the object (triangle) to get in formation, for
steps  states 1-2. After getting the object "triangle" in
formation, the robot group has reduced its hierarchical features, to simply avoid obstacles (for both
leader and followers), follow the leader (for followers) and the task of achieving the target X (for the
leader). Figure 3 shows actions of the follower
agents models within the hierarchical layers in states
1 and 2, similar to subsumption architecture, bottomup (Brooks, 1986). In other words, the priorities of
this architecture are 1 - avoid obstacles 2 - follow
the leader 3  driving formation. As for stage 2 and
3, its priority is to avoid obstacle and follow the
leader while in formation. The last strategy step,
stage 4 would be arc d of state machine.
Similarly, to followers hierarchical layers, the leader
agents hierarchy prioritizes the obstacle deviation,
search for the object and driving formation, for states
1 and 2 and, obstacle deviation and guide object to
target (X) while in formation, for states 2 and 3.
Observe that is not scope of this paper discuss
the dynamics needed to perform tasks, it is restricted
the necessary decision-making and behaviors, and the
agents are considered as points in sequence with
movements of translation and rotation.

Figure 3. Features of the Followers hierarchy (states 1 and 2)

As for the causal relationships, they are the connections between the concepts, in order to identify
the cause and effect between the concepts. Firstly,
these cause-effect relationships must be analyzed to
determine whether they have a positive or negative

2709

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

causality, and manually or by means of an optimization technique, setting their values and weights.
The manual mode, as used in this work, initially
set the weighs of the causal relationships by observing the dynamic behavior of mobile agents. The next
step, after the concepts and causal relationships are
identified, is to add them to the cognitive model, the
inclusion of new types of relationships and concepts
that characterize a DCN, more details about the development of the DCN is presented in Mendonça and
Arruda (2015). For simplicity and necessity of controlling, the model used in this work was called sDCN (simplified-DCN), because it partially uses the
available resources of its development. More constructive details can be found in the work of Mendonça and Arruda (2015).
The structure of the developed s-DCN (Figure 4)
for group autonomous navigation consists of five
inputs and three outputs. The input concepts are L.S.
(left sensor), R.S. (right sensor), F.S. (front sensor),
DX.L. (leader detection by the left side for followers)
and DX.R. (leader detection by the right side for followers). Output concepts are T.L. (turn left), T.R.
(turn right) and A.D. (accelerationdeceleration) to
the actuators.
Bio-inspired algorithms will consequently improve the routing performance in self-organized networks (Zhang, et al, 2013). In this way, we intend to
the development of the s-DCN cognitive model the
following step will add the ability to adapt essential
to bio-inspired models (Ohkura et al., 2010).
The Ws1 and Ws2 selection relationship switches the inputs of the s-DCN controllers according the
current behavior of the agents. Switching between
avoid obstacles and the positions predetermined of
the targets (according navigation strategy).
The next step is to develop a model for tuning
the dynamic response controller. Thus, the controller
will be able to adapt through a Reinforcement Learning algorithm based on heuristic rules and oriented by
events, during navigation.
The algorithm used for the online adjustment of
the causal relations weights is inspired by Sutton and
Barto (1998).

Figure 4. Group Navigation s-DCN

However, the algorithm is similar to the one used
in Mendonça and Arruda (2015), which presents a
more details on how to develop the RA algorithm
with rules.

ISSN 2525-8311

3 Initial Simulated Results
In the scenarios, the objective of the robots is to
explore the surroundings with the leader agent (robot), according to the proposed navigation strategy if
the agents (robots) are close to each other they will
prioritize the avoidance of obstacles in its path. Thus,
depending on the necessary control actions in different situations, the mobile agents can ungroup from
initial formation.
The simulation environment adopted for the experiments simulation of the first stage of this work,
consists of a 2-D animation developed in MATLAB,
represented by a XY plane. The dimensions of the Xaxis are within the range of 0 to 100, while the Y-axis
within the ranges of -10 to 270. The vehicles (agents)
are symbolized as "*", and represented by different
colors. The speed of the animation is determined by
the number of iterations the distance of the obstacle
avoidance sensors are 11 units and, the detection of
the leader for the followers are30 units. The trails of
the three colors are the trajectory, or navigation
memory, covered by the three agents, in whom the
blue identifies the leading vehicle, and red and green
are followers vehicles. A suggested scale for real
reproduction of simulation scenarios is (1 1) and the
distances measures cited in centimeters.
It is emphasized that in the simulations, the goal
of mobile vehicles (agents) is to seek a formation in
triangle after deviating the obstacles, distributed in
the scenarios, in which are identified by the Black
dots "".
3.1 First scenarios simulation

Figure 5. s-DCN on the first scenario

In the first scenario, figure 5, the three robots
start next to each other. In terms of initial positions,
XY coordinates, the red starts at the point 41, -3,
the blue in the point 57, 5 and the green at the point
64, -3. The robots deviate from obstacles and maintain the triangle formation at the end of the route, but
it is noted that green robot is positioned in an asymmetric way with red. This is due to both positioning
algorithm has a degree of randomness at the time of
navigation, as the sensors for the deviation, showing
very close trajectories between agents.
3.2 Second scenarios simulation
The vehicles (agents) start far from each other,
Figure 6 the red in the point 4, -5, the blue in 50,

2710

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

5 and the green in 100, -5. This scenario was designed to induce that the robots find each other while
navigating, thus allowing an analysis of their response for the case in which robots start distant to the
leader. Figure 6a shows the obtained result of the
navigation.
It is possible to visualize the dynamic behavior
for prioritizing the decision-making of the red robot,
the obstacle deviation, in this case, causing certain
deviation of its trajectory to the leader. Figure 6b
points this time, through a break in the animation.
This is due to the fact that if the robots front sensor
accuses an obstacle, and left sensor dont, the robot
will give preference to turn to the left.

Figure 6. s-DCN on the second scenario, showing details for path
taken by the agent

3.3 Third scenarios simulation
The vehicles start next to each other in third scenario, figure 7, where the red starts about at 46, -3,
the blue in 52, 5 and the green in 58, -3. In this
drastic scenario, figure 8, the capability to adapt and
to group of the controllers was tested with a distribution of obstacles that tends to ungroup, due necessary
avoidance maneuvers.
This actions occurs due the initial positions of
the robots Blue 33, 5, leading robot or agent, and
red 18, -5, follower robot or agent, that direct the
navigation of two agents to the same path.

Figure 7 s-DCN on the third scenario

3.4 Fourth scenarios simulation
The performance of s-DCN controllers reached
the main goal of not colliding with obstacles, or even
another robot of the group, taking right decisions, as
shown in figure 8. It is emphasized that the leader
(blue) begins in a position above the follower (red),
and even with the interposition of the paths, there was
no collision between them.

ISSN 2525-8311

Figure 8. s-DCN on the fourth scenario (drastic scenario)

According to the results obtained from the
agents, or robots, dynamic behavior (kinematic) controlled by s-DCNs navigating the four stated scenarios, it was observed that the group driving worked
properly most of the time in the simulations however, in certain times, it is observed that the movement
group maneuver takes place only when there is an
obstacle deviation by both the leader and the other
members of the group, in addition to being in a distance of 30 units from leader (value adopted previously). This suggests future improvements or adjustments to the sensors in the simulator. In most of the
scenarios, it is possible to observe the capacity of
separation and regrouping (group and ungroup), relevant to Swarm Robotics (La and Sheng, 2012).
4 Conclusion and future works
With the simulation results, although early, we
obtained an Autonomous Navigation System in group
capable to avoid obstacles and achieve the goals set
out in step 1. However, the system still needs some
improvements, some due to the problems presented
by the kinematic model simulation of robots used to
obtain greater realism and accuracy in the movements
of robots or agents. As suggestion, a kinematic model
with pulses on two wheels should solve the problem,
giving more realistic and accurate movements.
The results showed the initial objectives, essential to a Swarm Navigation System, for example each
agent interacts locally with each other and the environment. Emergence of coherent global standard that
optimizes a problem. The system is decentralized, the
actions were guided by the individual actions of the
leader however, each agent or robot take decisions
according to the proposed strategy, suggesting heterarchy in the controllers.
A variety of scenarios, even if it is initial, suggest that the system response is robust and adaptive
with according to changes in the environment (resilience). Finally, each agent using Reinforcement
Learning algorithms demonstrated self-organization
capability.
Future work aims to address the implementation
of steps 2, 3 and 4 of the proposed strategy. Compare
the proposed controllers with other similar controllers
developed using current techniques, for example,
Adaptive Fuzzy Logic. Inclusion of white noise on
inputs from the sensors to evaluate the ability of controllers developed for dealing with uncertainties, and

2711

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

the quantification of the computational complexity of
the s-DCN. And, finally after these possible advances, embed the system in real mobile platforms.
References
Asama H., Fukuda T. and Arai, I. E. (1995).
Distributed Autonomous Robotic Systems,
Springer-Verlag.
Aso, S., Yokota, S., Hashimoto, H., Ohyama, Y.,
Sasaki, A. and Kobayashi, H. (2008). Control
and stability for robotic swarm based on center
of gravity of local swarm. In Industrial
Electronics, 2008. ISIE 2008. IEEE International
Symposium on, pp.1341-1346, June 30 2008July.
Beni, G. (2005). From Swarm Intelligence to Swarm
Robotics,
Swarm
Robotics.
SAB2004
International Workshop, Santa Monica, CA,
USA, July 2004, Revised Selected Papers.
Brooks, R. A. (1986). A robust layered control
system for a mobile robot. IEEE Journal of
Robotics and Automation, v. 2, n. 1, p. 14-23.
Cliff, D. (2003). Biological inspired computing
approaches to cognitive systems a partial tour of
the literature. Technical Report HPL-2003-11,
Hewlett Packard Laboratories.
Costa, E. D. S. and Gouvea, M. M. (2010)
Autonomous
navigation
in
dynamic
environments with reinforcement learning and
heuristic, Ninth International Conference on
Machine Learning and Applications, pp. 37-42.
Dono, T.F. and Chung, T.H. (2013). Optimized
transit planning and landing of aerial robotic
swarms. In Robotics and Automation (ICRA),
2013 IEEE International Conference on,
pp.1843-1850.
Ghaffari, A. and Esfahanian, M.R. (2013). Using
swarm robots based on leader-followers method
for spherical object manipulation. In Robotics
and Mechatronics (ICRoM), 2013 First RSIISM
International Conference on, pp.413-418, 13-15
Feb.
Kosko, B. (1986). Fuzzy cognitive maps.
International Journal Man-Machine Studies, vol.
24, no. 1, pp. 65-75.
Kube, C. R. and Zhang, H. (1997). Task Modelling in
Collective Robotics. Autonomous Robots, vol.4
no.1, Kluwer Academic.
La, H. M. and Sheng, W. (2012). Dynamic target
tracking and observing in a mobile sensor
network. Robotics and Autonomous Systems, vo.
60, no. 7, pp. 9961009, June.
Mataric, M. J. (2007). The Robotics Primer. MIT
Press, Cambridge.
Mendonça, M. and Arruda, L. V. R. (2015). A
Contribution to the Intelligent Systems
Development Using DCN. OmniScriptum GmbH
 Co. KG, 2015

ISSN 2525-8311

Miao, Y., Liu, Z.Q., Siew, C.K. and Miao, C.Y.
(2001). Dynamical cognitive network  an
extension of fuzzy cognitive. IEEE Trans. on
Fuzzy Systems, vo. 9, no. 5, pp. 760-770.
Miao, Y., Miao, C., Tao, X-H., Shen, Z. and Liu, ZQ. (2010). Transformation of Cognitive Maps. In
Fuzzy Systems, IEEE Transactions on, vol.18,
no.1, pp.114-124, Feb.
Ohkura, K., Yasuda, T. and Matsumura, Y. (2010).
Coordinating the adaptive behavior for swarm
robotic systems by using topology and weight
evolving artificial neural networks. In
Evolutionary Computation (CEC), 2010 IEEE
Congress on, pp.1-8, 18-23 July.
Papageorgiou E.I. and Salmeron J.L. (2013). A
Review of Fuzzy Cognitive Maps Research
During the Last Decade. Fuzzy Systems, IEEE
Transactions on, vol.21, no.1, pp.6679,
Papageorgiou, E.I. (2014). Fuzzy Cognitive Maps for
Applied Sciences and Engineering From
Fundamentals to Extensions and Learning
Algorithms. Springer-Verlag Berlin Heidelberg.
Parra-Gonzalez, E.F., Ramirez-Torres, J.G. and
Toscano-Pulido, G. (2009). A New Object Path
Planner for the Box Pushing Problem.
Proceeding from Electronics, Robotics and
Automotive Mechanics Conference, Cuernavaca,
2009, pp. 11 9-124, 22-25 Sept.
Russel, S. J. and Norvig, P. (1995). Artificial
intelligence a modern approach. Englewood
Cliffs Prentice Hall.
Sahin, E. (2005). Swarm Robotics From Sources of
Inspiration to Domain of Applications, Swarm
Robotics. SAB2004 International Workshop,
Santa Monica, CA, USA.
Sahin E. and Spears, W.M. (2005). Swarm Robotics.
SpringerVerlag, Germany, 2005.
Smithers, M. (1997). Autonomy in robots and others
agents. Brains and Cognition, vol. 34, pp. 88106.
Stylios, C. D., Georgopoulos, V. C., Malandraki, G.
A. and Chouliara, S. (2008) Fuzzy cognitive
map architectures for medical decision support
systems, Applied Soft Computing, vo. 8, no. 3,
pp. 1243-1251.
Sutton, R. and Barto, A. (1998). Reinforcement
learning an introduction. Cambridge MIT
Press.
Xiao, R., Wang, Y. and Tao, Z. (2014). Research on
structure emergence based on cellular automata.
Int. J. of Bio-Inspired Computation, vo. 6, no. 2,
pp. 126-139.
Zhang, X., Zhang, Y., Li, Y., Zhang, Z. and Long,
K. (2013). Bio-inspired adaptive routing in selforganized
networks
A
survey.
In
Communications and Networking in China
(CHINACOM), 2013 8th International ICST
Conference on, pp.505-510, 14-16 Aug.

2712