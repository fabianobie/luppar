Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

ON-LINE IDENTIFICATION OF A CHAOTIC FINANCIAL SYSTEM BASED ON NEURAL NETWORKS

JOSÉ A. R. VARGAS1, KEVIN H. M. GULARTE2, ELDER M. HEMERLY3
1,2

Universidade de Brasília
Departamento de Engenharia Elétrica, Caixa postal 4386
70910-900 Campus Universitário Darcy Ribeiro, Brasília, DF, Brasil
E-mails vargas@unb.br, kevinhmg@gmail.com
3

Instituto Tecnológico de Aeronáutica
Divisão de Engenharia Eletrônica
Praça Mal. Eduardo Gomes, 50 - Vila das Acácias
12228-900 São José dos Campos, São Paulo, Brasil
E-mail hemerly@ita.br
Abstract
 This paper focuses on the identification problem of uncertain systems. Based on a neural identification model with
feedback, scaling and Lyapunov based weight adjustment law, an identification algorithm is proposed to make ultimately bounded the on-line state error. The relevance of this work is also the formalization of the fact that the scaling of unknown nonlinearities, previous to the neural approximation, and the introduction of an explicit feedback in the neural model have a positive impact
on performance and application of the algorithm. To validate the theoretical results, the identification of a chaotic financial system is performed.
Keywords
 Identification, Lyapunov methods, neural networks.
Resumo
 Neste trabalho é proposto um algoritmo para identificação on-line de sistemas_dinâmicos incertos. Com base em um
modelo neural, com realimentação, escalonamento e um algoritmo de aprendizado projetado usando a teoria de estabilidade de
Lyapunov é provado que o erro residual de estado é limitado e relacionado, principalmente, com matrizes de projeto. A relevância do trabalho está também na formalização do fato que um escalonamento das não-linearidades a serem aproximadas pela rede
neural ou a introdução de uma realimentação explicita no modelo neural têm um impacto positivo no desempenho e aplicação do
algoritmo. Objetivando-se validar os resultados teóricos foi realizada a identificação de um sistema caótico financeiro.
Palavras-chave
 .

1 Introduction
System neuro-identification is important not only to predict the behavior of the system, but also for
providing an appealing system parameterization,
which can later be used in the synthesis of control
algorithms, since mathematical characterization is
often a prerequisite to observer and controller design.
Neural identification models usually employed
are the dynamic ones, being their weights mainly
adjusted using gradient and backpropagation algorithms or their robust modifications (Kosmatopoulos
et al., 1995 Selmic and Lewis, 2001 Abdollahi et
al., 2006 Bazaei and Moallem, 2007 Chairez et al.,
2009 Alanis et al., 2010). Most used robust modifications in neuro-identification are the , switching- ,
, parameter projection, and dead zone (Kosmatopoulos et al., 1995 Selmic and Lewis, 2001 Abdollahi et al., 2006 Bazaei and Moallem, 2007 Chairez
et al., 2009 Alanis et al.,2010) which avoid the parameter drift.
For instance in Kosmatopoulos et al., (1995), the
identification of a general class of uncertain continuous-time dynamical systems was proposed, and modification adaptive law for the weights of recurrent high-order neural networks (RHONNs) was
chosen to ensure that the state error converges to the
neighborhood of the origin. In Selmic and Lewis,
(2001), dynamic NNs with a gradient descent algo-

ISBN 978-85-8001-069-5

rithm for weights adjustment were used to identify a
general class of uncertain nonlinear_systems. A crucial assumption was required the unknown system
can be exactly modeled by a NN model, that is, the
disturbance and approximation errors are identically
null. On the other hand, others relevant works, such
as Abdollahi et al., (2006), Bazaei and Moallem,
(2007), Chairez et al., (2009), Alanis et al., (2010),
showed that the dead zone, modified -rule, and modification and others robust modifications can be
used in weight adjustment law to make the entire
identification process stable in the presence of approximation error and disturbances.
However, in these works the dependence between the design parameters and the residual state
error is, in general, not straightforward. Hence, arbitrary small residual state error cannot be achieved.
For instance in Abdollahi et al., (2006), the neural
identification of a class of uncertain nonlinear system
is proposed. It was showed that the state and weight
errors are bounded. However, the upper bound for
the norm of the residual state error, and the design
parameters, on the identification scheme, are unrelated. Therefore, it may not be possible to obtain small
residual state errors.
Motivated by the previous facts, in this paper we
propose an algorithm for on-line identification,
where the dependence between the residual state
error and a design feedback matrix is straightforward. Consequently, in contrast to Abdollahi et al.,
1820

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

(2006), the residual state error can, easily, be arbitrarily reduced. Basically, this is achieved by scaling
of unknown nonlinearities, previous to the neural
approximation, and by selecting a neural identification model with a feedback term, which aims at correlating the state error with the estimated weights. To
ensure stability, the weights adaptation law is based
on Lyapunov stability theory.
2

Linearly Parameterized Neural Networks

Linearly parameterized neural networks
(LPNNs) can be expressed mathematically as

 nn (W ,  )  W ( )
nL

(1)

,    ,    a  is the
where W  
so-called basis function vector, which can be considered as a nonlinear vector function whose arguments
are preprocessed by a scalar function s () , and
L

L

L

n, L , L are integers strictly positive. Commonly

used scalar functions s () include sigmoid, tanh,
gaussian, Hardys, inverse Hardys multiquadratic,
etc (Kosmatopoulos et al., 1995 Ge et al., 2002).
However, here we are only interested in the class of
LPNNs for which  () is bounded, since in this case
we have,
 ( )   0
(2)
being  0 a strictly positive constant.
The class of LPNNs considered in this work includes HONN (Kosmatopoulos et al., 1995), RBF
networks (Ge et al., 2002), wavelet networks (Zhang
and Benveniste, 1992), and also others linearly parameterized approximators as Takagi-Sugeno fuzzy
systems (Wang, 1994). Universal approximation
results in (Kosmatopoulos et al., 1995 Ge et al.,
2002 Zhang and Benveniste, 1992 Wang, 1994)
indicate that
Property 1 Given a constant  0 > 0 and a continuous function f   a  n , where   

L

is a

compact set, there exists a weight matrix W  W 
such that the output of the neural network architecture (where L may depend on  0 and f ) satisfies

sup   f ( )  W  ( )   0

(3)

where  denotes the absolute value if the argument
is a scalar. If the argument is a vector function in  n
then  denotes any norm in  n .

3 Problem Formulation
Consider the following nonlinear differential
equation

x  F (x, u, v, t ) , x(0 )  x 0

where x  X is the n-dimensional state vector,
u  U is a m-dimensional admissible input vector,

v  V   q is a vector of time varying uncertain
variables and F  X  U  V  0,  ) a  n is a continuous map. In order to have a well-posed problem,
we assume that X , U , V are compact sets and F is
locally Lipschitzian with respect to x in
X  U  V  0,  ) , such that (4) has a unique solution.
We assume that the following can be established
Assumption 1 On a region X  U  V  0,  )

h(x, u, v, t )  h0

(5)

where

h( x, u, v, t )  F (x, u, v, t )  f ( x, u )

(6)

f is an unknown map, h are internal or external
disturbances, and h0 , such that h0 > h0  0 , is a
unknown constant. Note that (5) is verified when x e
u evolved on compact sets and the temporal disturbances are bounded.
Hence, except for the Assumption 1, we say
that F (x, u, v, t ) is an unknown map and our aim is to
design a NNs-based identifier for (4) to ensure the
state error convergence, which will be accomplished
despite the presence of approximation error and disturbances.
4

Identification Model and State Estimate Error
Equation

We start by presenting the identification model
and the definition of the relevant errors associated
with the problem.
Let f be the best known approximation of f,

P   nn a scaling matrix defined as P  P T > 0 ,
g  P 1 g , and g ( x, u )  f (x, u )  f (x, u ) . Then, by

adding and subtracting f (x, u ) , (4) can be rewritten
as

x  f ( x, u ) + Pg (x, u ) + h(x, u, v, t )

ISBN 978-85-8001-069-5

(4)

(7)

1821

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

Remark 1 It should be noted that if the designer has
no previous knowledge of f, then f is simply assumed as being the zero vector.
From (3), by using LPNNs, the nonlinear mapping g (x, u ) can be replaced by W  (x, u ) plus an

approximation error term  (x, u ) . More exactly, (7)
becomes

x  f (x, u ) + PW  ( x, u ) + P (x, u ) + h( x, u, v, t ) (8)
where W    nxL is an optimal or ideal matrix,
which can be defined as




W   arg min  sup g (x, u )  W  (x, u ) 

x

X
,
W  

uU




with   W

(9)



W   W ,  W is a strictly positive

constant, W is an estimate of W  , and  (x, u ) is an
approximation error term, corresponding to
which can be defined as

 ( x, u )  g ( x, u )  W  ( x, u )

W,
(10)

The approximation, reconstruction, or modeling
error  in (10) is a quantity that arises due to the
incapacity of LPNNs to match the unknown map
g (x, u ) . Since X, U are compact sets and from (2),
the following can be established
Assumption 2 On a region X  U , the approximation error is upper bounded by

 ( x, u )   0
where

0 ,

such that

(11)

 0 >  0  0 , is an unknown

constant.
Remark 2 Assumption 1 is usual in identification or
robust control literature. Assumption 2 is quite natural since g is continuous and their arguments evolve
on compact sets.

Remark 3 Note that any  0 >  0 , h0 > h0 , and

 0 >  0 also satisfy (2), (5), and (11). Hence, to
avoid confusion, we define  0 , h0 , and  0 to be the
smallest constants such that (2), (5), and (11) are
satisfied.

ISBN 978-85-8001-069-5

Remark 4 It should be noted that W  and  (x, u )
might be nonunique. However, the uniqueness of
 (x, u ) is ensured by (9).
Remark 5 It should be noted that W  was defined
as being the value of W that minimizes the L norm difference between g (x, u ) and W  (x, u ) . The
scaling matrix P from (7) is introduced to manipulate
the magnitude of uncertainties and hence the magnitude of the approximation error. This procedure improves the performance of the identification process.
Remark 6 Notice that the proposed neuroidentification scheme is a black-box methodology,
hence the external disturbances and approximation
error are related. Based on the system input and state
measurements, the uncertain system (including the
disturbances) is parameterized by a neural network
model plus an approximation error term. However,
the parameterization (8) is motivated by the fact that
neural networks are not adequate for approximating
external disturbances, since the basis function depends on the input and states, whereas the disturbances depend on the time and external variables. The
aim for presenting the uncertain system in the form
(8), where the disturbance h is explicitly considered,
is also to highlight that the proposed scheme is in
addition valid in the presence of unexpected changes
in the systems dynamics that can emerge, for instance, due to environment change, aging of equipment or faults.
The structure (8) suggests an identification
model of the form

x  f (x, u ) + PW  (x, u )  L(x  x )

(12)

where x is the estimated state, L   nn is a positive definite feedback gain matrix introduced to attenuate the effect of the uncertainties and disturbances. It will be demonstrated that the identification
model (12) used in conjunction with a convenient
adjustment law for W , to be proposed in the next
section, ensures the convergence of the state error to
a neighborhood of the origin, even in the presence of
the approximation error and disturbances, whose
radius depends on the design parameters.
Remark 7 It should be noted that in our formulation,
the LPNN is only required to approximate





P 1 f ( x, u )  f (x, u )

(whose magnitude is often

small) instead of the entire function P 1  f (x, u ) .
Hence, standard identification methods (to obtain
some previous f ) can be used together with the
proposed algorithm to improve performance.

1822

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

By defining the state estimation error as 
x  x  x ,

(

)



tr W T 
x T  
x T W

5

(

)

V   
xTQ 
x  2
x T  + P 1 h

   
x  trW T (W  W )
0

(19)

0

Furthermore, by using the fact 1, equation (19) implies

Adaptive Law and Stability Analysis

Before presenting the main theorem, we state a
fact, which will be used in the stability analysis.


nL
Fact 1 Let W  ,W0 ,W ,W    . Then, with the

definition of W  W  W  , the following equalities
are true

 (

)



2tr W T W  W0  W

(

+ W  W0



 0 x
2

)

2
F

(



 W  W0

)

2

LT P 1 + P 1 L  Q

(15)

(16)

where L > 0 and Q > 0 . Then, the signal errors


x ,W are uniformly bounded.

Proof Consider the Lyapunov function candidate

(

)



V 
x T P 1 
x + tr W T  W1W 2

(17)

By evaluating (17) along the trajectories of (13) and
(15), we obtain

)


V   
x T LT P 1 + P 1 L 
x + 2
x T W


 2
x T  + P 1 h + tr (W T  W1W )

ISBN 978-85-8001-069-5

2

+ W  W0

F

2
F

 W *  W0

2
F

(20)
)

Further rearranging terms, and considering that
 <  0 and h < h0 , (20) implies

(14)

 W > 0,  0 > 0 ,
is a constant matrix, P is the
solution of the equation

(16)

+2 
x . +2 
x . P 1 . h

)

and

the

+ 2h0 P 1 +

0

F


W   W  0 (W  W0 ) 
x + 2
x  T (x, u )

(
(


(W

2

V  
x . min (Q). 
x + 2 0

F

Theorem 5.1 Consider the class of general nonlinear
systems described by (4), which satisfies Assumptions 1-2. Let the weight law be given by

using

V   min (Q) 
x

2

We now state and prove the main theorem of
the paper.

By

the Lyapunov derivative can

be written as

from (8) and (12), we obtain the state estimation
error equation


x   L
x + PW (x, u )  P ( x, u )  h(x, u, v, t ) (13)


where W  W  W  .

,

(18)

representation

2

W *  W0

2
F

(21)



Hence, V < 0 as long as


x >

2 0 + 2h0 P 1 +

0
2

 min (Q )

W *  W0

2
F

 

(22)

Thus, since is constant, by using Lyapunov ar
guments (Khalil, 2001), we concluded that W and 
x
are uniformly ultimately bounded, with ultimate
x  escapes of
bound . Note that if, by any reason,  
the residual set , where   
x   
x    , V
becomes negative definite again, and force the convergence of the state error to the ball of radius  .

Remark 8 It should be noted that the scaling of
unknown nonlinearities has a positive impact on the
identification performance. The scaling matrix P is
introduced to attenuate the effect of approximation
error and disturbances, as can be seen in (22).
Remark 9 Note that the performance, as far as the
residual state error is considered, of the proposed
algorithm is directly proportional to the ultimate
bound , which is controlled, see (22), by the choice
of the matrix Q.
Remark 10 It is not difficult to see, from (16) and
(22), that the residual state error is of order
1  min (Q ) , where the eigenvalues of Q can be arbitrarily enlarged by increasing the diagonal elements

1823

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

of the feedback matrix L. Consequently, the proposed
algorithm easily allows the achievement of small
residual state error by adjusting the matrix L, or, in a
less conservative form, by adjusting the matrices P
and L.

6

Simulation

To illustrate the application of the proposed
scheme, we consider a chaotic finance system describe by (Zhao et al., 2011)
x  z + ( y  a ) x

y  1  by  x 2

(23)

z   x  cz

where x denotes the interest rate, y denotes the investment demand and z denotes the price index. The
parameter a denotes the savings, b denotes the investment cost and c denotes the commodities demand
elasticity. It was considered that a0.9, b0.2 and
c1.2. Notice that system (23) satisfies assumption 1,
since the state variables evolved on compact sets.
To identify the uncertain system (23) the proposed identification model (12) and the adaptive law
(15) were implemented. The initial conditions for the
chaotic system and identification model were
x(0)2, y(0)1, z(0)2, x  0, W  0 , in order to
evaluate the performance of the proposed algorithm
under adverse initial conditions.
The others design parameter were chosen as
 W  1,  0  10 , s()  10 1 + exp 0.5() , PI, LI,





  s ( x ), s ( y ), s (z ), s 2 ( x ), s 2 ( y ), s 2 ( z )

T

and

1 0 0 0 0 0 
W0  0 1 0 0 0 0 .
0 0 1 0 0 0
The performances in the estimation of the interest rate, investment demand and price index are
shown in figures 1-3. We can see that the simulations
confirm the theoretical results, that is, the algorithm
is stable and the residual state error is small.
The Frobenius norm associated to the estimated
weights is shown in figure 4. After a transient, due to
the large initial uncertainty, this norms seems to
converge, indicating that most of the state estimation
error has been removed.
An additional remark is necessary about figure
4 by looking at figure 1, it can be seen that after
t8.5s there is a slight dynamic variation. As expected, this forces updates in the estimated weights,
hence also in their Frobenius norm, as indicated in
figure 4.

ISBN 978-85-8001-069-5

7 Conclusions
In this paper, by using neural networks and
Lyapunov methods, we have proposed a scheme for
identification of uncertain nonlinear_systems. The
proposed scheme is based on uncertainty scaling and
explicit feedback to relate the performance with two
design matrices. It is shown that the performance of
the identification, as far the residual state error is
considered, is directly proportional to the eigenvalues
of the scaling and feedback matrices. Simulation
results demonstrate the effectiveness of the proposed
algorithm.

References
Abdollahi, F., Talebi, H.A. and Patel, R.V.(2006)
Stable identification of nonlinear_systems using
neural networks Theory and experiments,
IEEEASME Trans. on Mechatronics, Vol. 11,
No. 4, pp. 488-495.
Alanis, A. Y., Sanchez, E. N., Loukianov, A. G. and
Hernandez, E. A.(2010). Discrete-time recurrent
high order neural networks for nonlinear
identification, Journal of the Franklin Institute,
Vol. 347, pp. 1253-1265.
Bazae, A. and Moallem, M. (2007). Online neural
identification of multi-input multi-output
systems, IET Control Theory Appl., Vol.1, No 1,
pp. 44-50.
Chairez, I., Poznyak, A. and Poznyak, T.(2006).
Stable weights dynamics for a class of
differential neural network observer, IEE Proc.Control Theory Appl., Vol. 3, No. 10, pp. 14371447.
Ge, S. S., Hang, C. C., Lee, T. H. and Zhang, T.,
(2002). Stable adaptive neural network control,
Kluwer academic publishers.
Khalil, H. (2001). Nonlinear Systems (3rd Edition),
Prentice-Hall, Inc., Englewood Cliffs, New
Jersey.
Kosmatopoulos, E. B., Polycarpou, M.M.,
Christodoulou, M.A. and Ioannou, P.A. (1995).
High-order neural network structures for
identification of dynamical systems. IEEE Trans.
Neural Networks, Vol. 6, No. 2, 422-431.
Selmic, R. R. and Lewis, F.L.(2001). Multimodel
neural networks identification and failure
detection of nonlinear_systems, Proc. 2001 CDC,
Orlando, Florida USA, 3128-3133.
Wang, L. X.(1994). Adaptive fuzzy system and
control design and stability analysis, PrenticeHall, Inc., Englewood Cliffs, New Jersey.
Zhang, Q. and Benveniste, A. (1992). Wavelet
networks, IEEE Trans. Neural Networks, Vol. 3,
No. 6, pp. 889-898.
Zhao, X., Li, Z. and Li, S.(2011). Synchronization of
a chaotic finance system, Elsevier, Applied
Mathematics and Computation, Vol.217, No. 13,
pp. 6031-6039.

1824

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

Figure 1. Performance in the estimation of x.

Figure 2. . Performance in the estimation of y.

Figure 3. . Performance in the estimation of z.

Figure 4. Frobenius norm of the estimated weights.

ISBN 978-85-8001-069-5

1825