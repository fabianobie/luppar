Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

CONSTRUCAO DE UMA GRADE DE
OCUPACAO PARA NAVEGACAO AUTONOMA
UTILIZANDO CAMERA ESTEREOSCOPICA
ATIVA
Andre de Oliveira Palmerim Barcelos Fabio Silveira Vidal* Paulo Fernando Ferreira
Rosa


Instituto Militar de Engenharia
Praca General Tiburcio, 80 - Urca
Rio de Janeiro, RJ, Brasil


Instituto Federal do Tocantins
BR-153 KM 480
Paraso do Tocantins, TO, Brasil
Email aopbarcelos@gmail.comfabio.vidal.br@ieee.orgrpauloime@gmail.com
Abstract By using a SLAM technique, based on Rao-Blackwellized particle filter (RBPF), this paper proposes a modification on sensoring, aiming at utilizing an active stereoscopic camera for mapping, parallel localization, the construction of an occupancy grid, without the need for sensor arrangement or high financial
expenses. To validate the method, comparisons of both real and simulated experiments have been made, using
a rangefinder laser, as already done in previous works. It is also proposed a future work to solve the problems
observed in this paper.
Resumo Utilizando uma tecnica de SLAM, baseada no Filtro de Partculas Rao-Blackwellized (RBPF),
esse trabalho propoe uma modificacao no sensoriamento, visando utilizar uma camera estereoscopica ativa para
mapeamento, localizacao e em paralelo, a construcao de uma grade_de_ocupacao, sem a necessidade de um
arranjo de sensores ou de um elevado custo financeiro. Para validacao do metodo, foram feitas comparacoes
de experimentos (simulado e real) utilizando um laser rangefinder, ja consolidado na literatura por trabalhos
anteriores. Tambem foi proposto um trabalho futuro para resolucao dos problemas observados neste trabalho.
Palavras-chave

.
Um exemplo pode ser visto em (A. A. Makarenko,
2002), em que considera uma area limitada de exploracao. Sistemas de localizacao e mapeamento
simultaneos, sao, em geral, implementados para
hardware embarcado, os quais possuem limitacoes
de carga paga e processamento. Os exemplos mais
comuns sao veculos_aereos_nao_tripulados, assistentes pessoais roboticos e veculos_autonomos.
Ainda neste ambito, o algoritmo a ser processado pelo hardware embarcado do robo, precisa
ser computacionalmente compatvel para execucao em tempo habil.
As solucoes de SLAM, sao baseadas na relacao
entre as medicoes realizadas pelos sensores embarcados (cameras, lasers, Inertial measurement
unit (IMU)), e tambem pelo comando de controle
dado para os respectivos atuadores do robo. Se
os comandos nos atuadores ou as medicoes realizadas pelos sensores fossem extremamente precisas, isto e, sem erros, o problema de SLAM sequer existiria. Porem, as medicoes realizadas pelos sensores, sofrem interferencias do meio_ambiente, assim como os erros de odometria, que possuem um comportamento cumulativo. Uma alternativa para corrigir esses erros e a utilizacao de
sensores que possuam um comportamento de erro

INTRODUCAO

O campo da robotica_movel possui muitos desafios, dentre eles, o mapeamento e a estimacao
da pose do robo em um ambiente desconhecido
(SLAM), seja para definir qual e o melhor caminho para uma possvel navegacao, ou para exploracao de um ambiente totalmente ou parcialmente
desconhecido. Para estes casos, se faz necessario
um sistema capaz de mapear, estimar a pose do
robo neste mapa e construir, de forma paralela,
uma grade_de_ocupacao, a qual sera utilizada no
reconhecimento de obstaculos no ambiente explorado. A complexidade do sistema tambem deve
ser levada em consideracao, pois, devemos obedecer parametros de carga paga, custo e energia
disponveis para o projeto.
Este trabalho utiliza uma tecnica de Localizacao e Mapeamento Simultaneos (Simultaneous Localization and Mapping SLAM) baseada no RaoBlackwellized particle filter (RBPF) (K. P. Murphy, 2000). Um algoritmo SLAM e utilizado
para mapear e determinar a pose do robo, enquanto uma grade_de_ocupacao e gerada de
forma simultanea e esta grade_de_ocupacao se faz
necessaria para o reconhecimento de obstaculos
no ambiente mapeado, a qual auxilia no plane-

71

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

gaussiano, ou seja, tende a zero em combinacao
com tecnicas probabilsticas de estimativa de estado. Temos como alguns exemplos de sensores
com comportamento gaussiano lasers, cameras e
sonares.
Neste trabalho defendida a modificacao no
sensoriamento de um metodo SLAM ja consolidado utilizando laser rangefinder, para utilizar-se
somente uma camera estereoscopica ativa (sensor
de imagem estereoscopicas). Assim, proporcionando uma reducao do custo e a carga paga do sistema robotico. Para validacao do metodo modificado, realizamos experimentos em duas situacoes
(a) utilizando o laser rangefinder (funcionamento
detalhado na secao 4), como no metodo original,
e (b) utilizando uma camera estereoscopica ativa,
sendo esta a modificacao proposta e a contribuicao
deste trabalho. Foram considerados o custo do sistema (valor financeiro dos sensores e carga paga).
A secao 2 discute alguns trabalhos relacionados ao SLAM. Na secao 3, apresentamos a tecnica
de SLAM utilizada para uma melhor compreensao da modelagem matematica da solucao implementada para o problema. Na secao 4 uma breve
explanacao da organizacao do sistema, a modificacao proposta pelo trabalho e demonstracao dos
resultados obtidos. Na secao 5 sao apresentadas
propostas futuras para solucionar problemas observados neste trabalho.
2

mento de trajetoria eficiente, sem o risco de colisao
com obstaculos no ambiente.
Uma dessas solucoes de SLAM, e descrita
no trabalho (Neto, 2012). Nele, a probabilidade do robo estar numa pose e calculada com
EKF(Extended Kalman Filter ) integrando um filtro de partculas. Hipoteses aleatorias sao geradas
para uma pose correspondente do robo, baseada
nas visualizacoes dos marcos. Os marcos no ambiente sao extrados atraves de uma camera estereoscopica, utilizando o algoritmo SIFT(ScaleInvariant Feature Transform) (Lowe, 1999). Existem outros tipos de algoritmos de visao_computacional, que podem ser aplicados para esse
proposito de deteccao de pixels com destaque na
cena, dentre eles, pode-se citar (a) SURF(Speeded
Up Robust Features) (H. Bay, 404-417), que utiliza um vetor de 128 componentes para cada pixel
destacado na cena observada. (b) ORB(Oriented
Fast and Rotated Brief ) este algoritmo se destaca
pela robustez semelhante a encontrada no SURF,
porem, com velocidade de deteccao muito superior, o mesmo utiliza um vetor de 16 componentes
para descrever o pixel em destaque na cena observada.
No trabalho apresentado por (A. M. Neto,
2012), (A. M. Neto, 2011b), (A. M. Neto, 2011c),
(A. M. Neto, 2011a) e (A. M. Neto, 2011d)
e demonstrado uma exploracao integrada com
multiplos robos. Neste trabalho, e gerado um
mapa comum a partir da contribuicao dos N
robos. Esta tecnica reduz o tempo de exploracao de um abiente, visto que multiplos robos
realizando a exploracao de forma integrada, realizam o mapeamento de um ambiente de forma
distribuda. Utilizando a aproximacao dada na
tecnica de FastSLAM, os robos que reobservam os
marcos ja mapeados por outro(s) robos conseguem
um aumento na precisao da determinacao das
poses de cada robo, visto que nesta segunda etapa,
entra-se em modo de reobservacao (fechamento de
loop).
Nas solucoes apresentadas anteriormente, se
faz necessaria a construcao de uma grade_de_ocupacao, para que os robos possam navegar e planejar a sua trajetoria. Para isso, e utilizado alem da
camera estereoscopica, um sensor Laser LiDAR
(Light Detection And Ranging). Neste trabalho
e proposto a utilizacao da combinacao da tecnica
de Filtro de Partculas Rao-Blackwellized (RBPF)
(G. Grisetti, 2005) com a extracao dos marcos no
ambiente, utilizando uma camera estereoscopica
ativa, para construir uma grade_de_ocupacao e
em paralelo, a construcao de um mapa de caractersticas. A partir deste mapa de caractersticas
(marcos) e possvel estimar a pose do robo no ambiente. A contribuicao principal deste trabalho e
utilizar somente uma camera estereoscopica como
sensor. Assim, descarta-se a necessidade de utilizacao de dois sensores, a camera para associacao

Trabalhos Relacionados

As tecnicas de SLAM, como o PoseSLAM
(R. Valencia, 2011), EKF-SLAM (M. W. M.
G. Dissanayake and Csorba, 2001), CurveSLAM
(D. Rao, 2012) e FastSLAM (Montemerlo and
Thrun, 2003) que necessitam extrair marcos do
ambiente utilizando os sensores embarcados no sistema, esses sensores podem ser, cameras, lasers,
sonares ou uma combinacao deles (C. Fulgenzi,
2009). PoseSLAM e uma tecnica que consiste
em priorizar o caminho com o menor erro. Um
trabalho apresentado por (R. Valencia, 18851891) utiliza esta tecnica para realizar a exploracao de um ambiente e minimizar a entropia da
trajetoria do robo. Uma combinacao do FastSLAM e Filtros de Partculas, e apresentado em
(K. Matsuo, 2012). A tecnica chamada de FastSLAMPSOM (FastSLAM with Particle Swarm
Optimization Based Mapping), sugere uma utilizacao de computacao paralela para a reducao
do tempo de processamento. No CurveSLAM
(D. Rao, 2012) e apresentada uma tecnica de localizacao e mapeamento, utilizando-se as linhas de
contornos observadas no ambiente. As tecnicas de
SLAM, sao utilizadas para corrigir o erro acumulado pela odometria do robo. Para caso de veculos_autonomos utilizando tecnicas de SLAM, se faz
necessario uma grade_de_ocupacao para reconhecimento dos obstaculos para realizar um planeja-

72

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

de marcos e mais um laser para construcao da
grade_de_ocupacao. Utilizando somente a camera
para associacao de marcos e construcao da grade
de ocupacao, reduzindo assim o numero de sensores necessarios para a realizacao da tarefa de
mapeamento, localizacao e planejamento_de_trajetoria de um veculo_autonomo.
Foram realizados quatro experimentos, para
a construcao da grade_de_ocupacao utilizando a
tecnica de RBPF, como descrito a seguir (a)
no primeiro experimento, foi utilizado um laser
LIDAR, num ambiente real, com uma trajetoria
pre definida (b) no segundo experimento, foi utilizado uma camera estereoscopica ativa, filtrando
a leitura dos pixels horizontais centrais da camera
de profundidade, com a mesma trajetoria planejada do primeiro experimento (c) no terceiro experimento, foi utilizado um laser LIDAR num
ambiente simulado, com trajetoria planejada diferente da utilizada no primeiro e segundo experimentos (d) no quarto e ultimo experimento, foi
utilizada a camera estereoscopica ativa, num ambiente simulado, com a mesma trajetoria utilizada
no terceiro experimento.

partcula, corresponde a uma possvel pose, dada
as observacoes dos sensores 1t e do comando de
controle u1t1 , que vem da odometria. Para cada
instancia de partcula, e associado um mapa local, que corresponde ao mapeamento dos marcos,
dada a provavel pose. Uma caracterstica importante num filtro de partculas, e a Importancia
de Reamostragem Sequencial (SIR), ou seja, como
devem se comportar a distribuicao probabilstica
para uma reamostragem das partculas, num segundo passo. A SIR do RBPF, e baseada nas observacoes eou no comando de controle, quando
disponveis. Assim, ha uma reducao significativa
em relacao ao problema de deplecao de partculas,
que geram amostras com peso muito reduzido. O
peso das partculas e uma caracterstica associada
a cada instancia. Este peso, significa o quanto
aquela partcula e probabilisticamente fiel a pose
real do robo. O calculo do peso de cada partcula
e dado pela relacao entre observacoes dos sensores
1t , comando de controle anterior u1t1 e pode
ser calculada por
(i)

t 
3

Mapeamento com Filtro de Partculas
Rao-blackwellised

(i)

(x1t 1t , u1t1 )

(2)

.
Em que a funcao , que contem o historico de
observacoes do robo, e dada por

No trabalho apresentado por (K. P. Murphy, 2000)
foi introduzido o conceito principal do Filtro de
Partculas Rao-Blackwellized para o SLAM, que
e estimar a pose posterior p(x1t 1t , u0t ) num
mapa  atraves de uma trajetoria dada por x1t 
x1 , . . . , xt . A estimativa da pose, e feita a partir das observacoes feitas pelos sensores e por comandos de controle obtidos a partir da odometria do robo (encoders), onde 1t  1 , . . . , t e
u1t1  u1 , . . . , ut1 sao as observacoes e o comando de controle, respectivamente. O modelo
matematico do RBPF e dado por
p(x1t , 1t , u1t1 ) 
p(x1t , 1t ).p(x1t 1t , u1t1 )

p(xi1t 1t , u1t1 )

(x1t 1t , u1t1 )  (xt x1t , 1t , u1t1 ).
(3)
(x1t1 1t1 , u1t2 )
O calculo do peso de cada partcula e de
suma importancia para permitir a diminuicao do
problema de deplecao. alguns melhoramentos
propostos nos trabalhos de (A. Doucet, 2001),
(R. Morales-Menendez, 2009) e (Pitt and Shephard, 1997) proporcionaram uma definicao recursiva em que foi obtido uma menor deplecao a
cada amostragem das partculas. No trabalho
de (G. Grisetti, 2005) chega-se a uma formulacao
baseada na reamostragem das partculas, levando
em consideracao a pose atual do robo e o historico
de observacoes, normalizada por uma constante 
e modelada na seguinte equacao.

(1)

Com esta fatoracao e possvel estimar a trajetoria do robo, assim, pode-se construir o mapa,
dada a trajetoria do robo. Sabe-se que o mapa
para ser construdo, depende da pose do robo
num dado momento. Dada esta transformacao, e
possvel estimar um mapa posterior p(x1t , 1t )
utilizando-se a fatoracao dada pela Eq. 1. Temos
como variaveis conhecidas, as poses da trajetoria
planejada para o robo, dada por x1t e as observacoes 1t . A demonstracao analtica detalhada pode ser vista em (Moravec, 1988). Para
se estimar a pose posterior p(x1t 1t , u1t1 ) do
robo atraves de uma trajetoria planejada, se faz
necessaria a utilizacao de um filtro de partculas. O filtro de partculas e uma distribuicao
probabilstica de possveis poses do robo. Cada

(i)

(i)

t 

(i)

(i)

p(t x1t 1t1 )p(xt xt1 , ut1 )
(i)

(i)

(xt xt1 , 1 , u1t1 )

(4)

Para uma melhor compreensao do funcionamento do metodo, apresentamos um resumo das
funcoes implementadas na qual pode-se ver na Fig.
1 o diagrama de fluxo.
4

Organizacao Sistemica e Resultados
Experimentais

Nesta secao, iremos mostrar como funciona a estruturacao de um sistema no Robotic Operating

73

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Figure 1 Diagrama de fluxo do mapeamento com
RBPF

Figure 2
Sensor Kinect (adaptado
(httpblogs.msdn.combkinectforwindows,
n.d.))

System (ROS), a configuracao de hardware embarcado e, por final, os resultados obtidos nos experimentos.
A estrutura de uma solucao baseada em ROS,
pode ser dividida basicamente em (a) pacotes, (b)
nos, (c) topicos, e (d) mensagems. Os pacotes sao
as estruturas gerais da solucao, uma visao macro
da mesma. No pacote, encontram-se todos os nos
que sao necessarios para o seu funcionamento. Os
nos sao, em analogia, os executaveis de cada pacote. Com cada no pode-se publicar nos topicos.
Os topicos sao o meio de troca de mensagem com
outros nos e, atraves dos topicos, um conjunto de
nos pode enviar ou receber mensagens entre si.
Para cada sensor existe, pelo menos um no e um
topico para realizar a comunicacao. No caso dos
sensores, existem nos especficos para ouvirem as
mensagens enviadas pelo sensor correspondente.
Para cada atuador (motores do robo) existe um
topico para publicacao da velocidade do mesmo.
Nos sistemas roboticos, por vezes sao
necessarios diversos sensores embarcados. Neste
caso, possumos cameras e odometria (encoders), e
os mesmos encontram-se em posicoes diferentes do
centro do robo, por isso, se faz necessario a utilizacao de sistemas de transformadas, para disposicao
espacial de cada sensor. Para solucionar este caso,
utilizamos um pacote de transformadas, conhecido
como TF, que sera detalhado a seguir. A estrutura de hardware ficou da seguinte maneira, um
laser (veja Fig. 4) e uma camera estereoscopica
ativa (veja Fig. 2). Estes sensores ficaram dispostos numa plataforma robotica_movel (veja Fig.
5).
A camera estereoscopica ativa utilizada neste
trabalho foi um modelo Kinect (veja Fig. 2) e
um dispositivo dotado de uma camera RGB, um
projetor infravermelho (IR), uma camera infravermelha e um arranjo de microfones. O sensoriamento do Kinect se da combinando imagens coloridas com as projecoes em IR. Para a reconstrucao
da dimensao de profundidade, o Kinect projeta
padroes em IR na cena, que sao observados pela

de

Figure 3 Relacao Trigonometrica da Camera

camera IR, relacionando trigonometricamente os
pontos (camera IR e projetor IR possuem uma
distancia conhecida entre eles) com o ponto observado Fig. 3. Com isso, a distorcao causada no
padrao projetado e suficiente para poder estimar a
profundidade de cada ponto na cena observada. A
camera RGB, pode ser utilizada juntamente com
um algoritmo de visao_computacional para detectar marcos no ambiente, baseados na intensidade
de pixel da cena, isto e comentado na Secao 5
como solucao para um problema observado neste
trabalho.
O sensor_laser utilizado neste trabalho (somente para comparacao), Fig. 4 funciona medindo
o tempo que o feixe IR necessita para colidir e retornar. O tempo que o feixe IR demora entre o
momento da transmissao e a recepcao, e proporcional a distancia que o sensore esta de um obstaculo. O laser utilizado e o modelo SICK-LMS,
fabricado pela SICK Sensor Intelligence.
A plataforma movel utilizada neste trabalho,
e de dinamica diferencial, possui dois motores e
duas rodas (19cm), cada motor e sensoriado por
um encoder de 500 marcacoes. A plataforma pode

74

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Figure 4 Diagrama Esquematico do Laser
Rangefinder

Figure 6 Diagrama das Tranformadas do Sistema
porciona uma possibilidade de implementacao
de mapa comum para multiplos robos (b) pioneer3dxodom frame Responsavel por dar a pose
origem do robo pela estimativa da odometria (c)
pioneer3dxbase frame Responsavel pela estimativa de pose atual do robo (d) camera frame Responsavel pela pose da camera RGB em relacao
a base da plataforma movel (e) camera depth
Responsavel pela pose da camera de profundidade em relacao a base da plataforma movel (f)
laser frame Responsavel pela pose do sensor de
laser em relacao a base da plataforma movel.
Com estas tranformadas e possivel sincronizar as
mensagens de um passo especfico no tempo, trocadas pelos sensores e os nos do pacote principal
(ime slam coreslam).
O sistema esta estruturado para que cada
funcao seja um no, assim, pode-se elencar nucleos especificos do procesador para executar cada
funcao do sistema, essa estrutura nos proporciona
um paralelismo na execucao. O sistema funciona
aguardando as mensagens e executa o processamento quando as mensagens sao entregues. A
seguir temos uma tabela de descricao da funcao
executada por cada no do sistema .

Figure 5 Hardware utilizado para experimentos
reais
se locomover ate 1.6ms e carregar uma carga
paga de ate 23kg. Esta plataforma e do modelo Pioneer-3DX (P3DX), fabricada pela Adept
MobileRobots, e muito utilizada em pesquisas de
robotica_movel.
A Fig. 5 mostra o hardware montado para
este trabalho, no detalhe, cada item embarcado
na plataforma movel. (a) CPU, (b) Camera
MS-Kinect, (c) Laser SICK-LMS, (d) Plataforma
Movel Pioneer-3DX.
O ROS possui o pacote TF que se tornou uma
solucao viavel para o nosso problema de transformadas, espacial e temporal. Este problema ja e
muito conhecido na robotica, principalmente em
manipuladores, por isso, praticamente todo sistema robotico necessita desta solucao. O pacote
TF, oferece ferramentas que nos auxiliam nestas
tranformadas, a estrutura de transformadas pode
ser vista na Fig. 6.
As transformadas sao estruturadas em arvore, cada uma e um topico, que publicam
mensagens para os nos do pacote principal
(ime slam core), que se divide da seguinte forma
(a) ime slam map Responsavel pela publicacao
do mapa global e permite relacionar a origem
do mapa com a pose atual do robo ou de qualquer um dos sensores embarcados. Este mapa
esta estruturado como um servidor, o que pro-

Table 1 Descricao
No
ime slam coreslam
ime vision
ime slam laser node
rosaria
ime slam rviz
gazebo ros

de Func. dos Nos
Funcao
Metodo SLAM
Sensoriamento Camera
Sensoriamento Laser
Atuadores PD3DX
Visualizacao
Ambiente Simulado

Foram feitos quatro experimentos dois em
ambiente real e dois em ambiente simulado(Fig.
7), usando uma trajetoria planejada. Para comparacao dos resultados, utilizamos um sensor de
alto custo, ja muito utilizado em trabalhos anteriores, o Laser SICK-LMS e a modificacao proposta
no trabalho, utilizando os dados de profundidade

75

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

do Kinect, utilizando uma varredura no centro da
matriz de profundidade gerada pela camera estereoscopica ativa. A CPU utilizada segue as seguintes configuracoes Intel Core I7 (2.10GHz), 16GB
de RAM DDR31600MHz.

Figure 8 Resultados das trajetorias planejadas(laranja), estimada com a camera(preta) e
com o laser(vermelha) em ambiente simulado
Figure 7 Ambiente Simulado (9m x 6m)

Table 2 Media e desvio padrao para cada experimento realizado com a camera e com o laser em um
ambiente simulado.

O primeiro experimento foi simulado no
Gazebo, definindo 8 passos para a trajetoria na
exploracao do ambiente. Para cada passo do robo,
pegamos dados de profundidade da camera estereoscopica ativa. Para um valor ser considerado
valido, devera estar dentro do intervalo de distancia entre 0.5 e 5 metros. Qualquer obstaculo detectado neste intervalo de distancia, sera mapeado
e colocado na grade_de_ocupacao que esta sendo
construda. As observacoes ficam armazenadas
num historico para que o algortmo de estimativa de pose, possa corrigir os valores quando houver uma re-observacao da mesma caracterstica
ja computada anteriormente, como explicado na
secao 3.
O segundo experimento, tambem simulado no
mesmo ambiente do primeiro, utiliza a mesma trajetoria, porem, o sensor utilizado e o laser SICKLMS, sendo um sensor de alto custo e ja consagrado em trabalhos anteriores, foi uma alternativa para comparacao da modificacao proposta.
Os criterios de deteccao, localizacao e execucao do
algortmo, sao os mesmo para o primeiro experimento.
Os resultados das trajetorias estimadas nos
dois experimentos, podem ser visualizadas na Fig.
8.
Na Tabela 2 pode-se observar a media (), assim como, o desvio padrao () encontrados para
cada eixo das posicoes do robo. Os erros encontrados para cada posicao do passo dado pelo
robo, pode ser visualizado na Figura 9 em que
foram obtidos na relacao da posicao planejada e a
posicao estimada pelo SLAM.
O terceiro e o quarto experimentos foram
feitos em ambiente real. Foram planejados 8 passos com poses especficas, neste experimento, o
mapa e a trajetoria do robo diferem da feita no

Var



Camerax
0.05077
0.10230

Cameray
0.10444
0.10634

LiDARx
0.15911
0.12022

LiDARy
0.09977
0.08212

Figure 9 Valores de erro no experimento em ambiente simulado
primeiro e segundo experimentos. Para criterio
de avaliacao, comparamos o devio padrao entre
as poses planejadas e com a utilizacao do sensor
laser, e outro com a camera.
Utilizando a comparacao entre a trajetoria
planejada e a trajetoria estimada, pode-se chegar
aos valores de media e desvio padrao para cada
sensor no experimento real, estes valores podem
ser observados na Tabela 3.
Uma melhor apresentacao dos erros acumulados pode ser observada no grafico dado pela
Figura 11.

76

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Algumas limitacoes foram observadas neste
trabalho. Dentre elas, a utilizacao do kinect em
ambientes abertos (com luz do sol), pois o sistema de projecao de padroes utilizado pelo kinect,
e ofuscado pela luz solar. Uma solucao proposta, dada a estruturacao do projeto, e utilizar
uma camera DepthSense, que possibilita a utilizacao em campo aberto. Foram observados problemas nas aquisicoes dos marcos quando o robo
esta muito proximo a um obstaculo. A abertura angular da camera se da pela lente. Quanto
mais perto de um objeto, essa abertura se torna
menor, o que proporciona um campo de varredura
menor da cena observada. Essa questao das observacoes pode ser resolvida modificando-se o metodo
das associacoes de marcos, utilizando-se um algoritmo de visao_computacional o qual trabalhara
com a descricao de intensidade dos pixels da imagem RGB. Assim, as modificacoes das caractersticas observadas na cena, nao se modificara bruscamente por conta da diminuicao do angulo de
varredura.

Figure 10 Resultados das trajetorias planejadas(laranja), estimada com a camera(preta) e
com o laser(vermelha) em ambiente real
Table 3 Media e desvio padrao para cada experimento realizado com a camera e com o laser em um
ambiente real

6
Var



Camerax
0.19444
0.16907

Cameray
0.028888
0.12045

LiDARx
0.13233
0.16565

LiDARy
0.08122
0.09190

Agradecimentos

Os autores agradecem o suporte financeiro oferecido pela Coordenacao de Aperfeicoamento de
Pessoal de Nvel Superior (CAPES)  Edital 2012
Pro-Estrategia, e Financiadora de Estudos e Projetos (FINEP)
Referencias
A. A. Makarenko, S. B. Willians, F. B. H. F.
D.-W. (2002). An experiment of integrated
exploration, Proceedings of the 2002 IEEERSJ. Intl Conference on Intelligent Robots
and Systems .
A. Doucet, J.F.G. de Freitas, K. M. (2001). Sequential monte-carlo methods in practice.,
Springer Verlag .
A. M. Neto, P. F. F. Rosa, P. C. P. (2011a). Integrated exploration of an indoor environment
with slam technique, Proceedings of the 15th
Portuguese Conference on Artificial Intelligence, 2011, Lisbon .

Figure 11 Valores de erro no experimento em ambiente real
5

Conclusao e Trabalhos Futuros

A. M. Neto, P. F. F. Rosa, T. E. A. O.-P. C. P.
(2011b). Environment exploration with multiple vehicles and fastslam technique, Proceedings of the IECON 2011 - 37th Annual Conference on IEEE Industrial Electronics Society, Melbourne .

Neste trabalho, foi demonstrada a possibilidade
de realizar a tarefa de mapeamento e estimativa de pose de um robo_movel, gerando em paralelo, uma grade_de_ocupacao para auxilio na
navegacao_autonoma. A utilizacao da tecnica de
SLAM, baseada no RBPF fazendo a reamostragem das partculas com base nas observacoes, demonstrou um resultado satisfatorio, pois, os erros
obtidos comparando-se a utilizacao da camera estereoscopica com o laser, foram bem proximos.

A. M. Neto, P. F. F. Rosa, T. E. A. O.-P. C. P.
(2011c). Exploration with fastslam technique, Proceedings of the 9th IEEE International Conference on Control and Automation
(ICCA), Santiago .

77

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

A. M. Neto, P. F. F. Rosa, T. E. A. O.-P. C. P.
(2011d). A slam approach for multiple homogeneous autonomous vehicles., Proceedings of
the 3rd Int. Congress on Ultra Modern Telecommunications and Control Systems, 2011,
Budapest .

Montemerlo, M. and Thrun, S. (2003). Simultaneous localization and mapping with unknown data association, Proceedings of the
IEEE, International Conference on Robotics
and Automation .
Moravec, H. (1988). Sensor fusion in certainty
grids for mobile robots, AI Magazine .

A. M. Neto, P. F. F. Rosa, T. E. A. O.-P. C. P.
(2012). Multiple robots in a cooperating
task Exploration and mapping, Proceedings
of the IROS12 4th International Workshop
on Planning, Perception and Navigation for
Intelligent Vehicles, Vilamoura .

Neto, A. M. (2012). Mapeamento de ambiente interno semi-estruturado com multiplos veculos utilizando sensor visual embarcado, PhD
Thesis, Military Institute of Engineering .
Pitt, M. and Shephard, N. (1997). Filtering via simulation auxilary particle filters, Technical
report, Department of Mathematics, Imperial
College, London .

Blackwell, D. (1947). Conditional expectation
and unbiased sequential estimation, Annals
of Mathematical Statistics .
C. Fulgenzi, G. Ippoliti, S. L. (2009). Experimental validation of fastslam algorithm integrated with a linear features based map, Elsevier Mechatronics .

R. Morales-Menendez, N. de Freitas, D. P. (2009).
Real-time monitoring of complex industrial
processes with particle filters, Proceedings of
the Conference on Neural Information Processing Systems (NIPS) .

D. Rao, C. Soon-Jo, S. H. (2012). Curveslam An
approach for vision-based navigation without
features, Proceedings of the IEEERSJ International Conference on Intelligent Robots
and Systems (IROS) .

R. Valencia, J. Andrade-Cetto, J. P. (2011). Path
planning in belief space with pose slam, Proceedings of the IEEE International Conference on Robotics and Automation .

G. Grisetti, C. Stachniss, W. B. (2005). Improving grid-based slam with rao-blackwellized
particle filters by adaptive proposals and selective resampling, International Conference
on Robotics and Automation (ICRA) .

R. Valencia, J. V. Miro, G. D. J. A.-C. (18851891). Active pose slam, Proceedings of the
IEEERSJ International Conference on Intelligent Robots and Systems (IROS) .

H. Bay, T. Tuytelaars, L. G. (404-417). Surf
Speed up robust features, In 9th European
Conference on Computer Vision .
httpblogs.msdn.combkinectforwindows (n.d.).
K. Matsuo, J. M. (2012). Outdoor visual localization with a hand-drawn line drawing map
using fastslam with pso-based mapping, Proceedings of the IEEERSJ International Conference on Intelligent Robots and Systems
(IROS) .
K. P. Murphy, S. A. Solla, T. K. L. K. R. M.
(2000). Bayesian map learning in dynamic
enviroments, Advances in Neural Information Processing Systems 12, MIT Press .
Lowe, D. G. (1999). Object recognition from local
scale-invariant features, In The Proceedings
of the 7th IEEE International Conference on
Computer Vision .
M. W. M. G. Dissanayake, P. Newman, S. C. H. F.
D.-W. and Csorba, M. (2001). A solution to
the simultaneous localization and map building (slam) problem, IEEE Transactions on
Robotics And Automation .

78