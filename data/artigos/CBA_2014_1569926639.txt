Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

DETECÇÃO DE INCÊNDIOS UTILIZANDO PERSISTÊNCIA ESPAÇO-TEMPORAL E
SEGMENTAÇÃO POR COR EM VÍDEO
DENER E. BORTOLINI*, ADRIANO L. SANTOS*, HERMES A. MAGALHÃES*, HANI C. YEHIA*, DOUGLAS A. G.
VIEIRA, CARLOS A. M. NASCIMENTO
* Programa de pós-graduação em Engenharia Elétrica
Universidade Federal de Minas Gerais
Av. Antônio Carlos 6627, Belo Horizonte, MG, Brasil
 Enacom
Parque Tecnológico de Belo Horizonte (BH-TEC)
Rua Professor José Vieira Mendonça, 770, sala 406, Belo Horizonte-MG, Brasil
 CEMIG - Companhia Energética de Minas Gerais
Avenida Barbacena, 1200, Belo Horizonte, MG, Brasil
E-MAILS GIGATONN@GMAIL.COM, ADRIANOCOMP@GMAIL.COM, HERMES@CPDEE.UFMG.BR,
DOUGLAS.VIEIRA@ENACOM.COM.BR, CAXANDRE@CEMIG.COM.BR

HANI@UFMG.BR,

Abstract Algorithms in fire detection through video has proven increasingly important, creating tools to monitor and protect
our increasingly scarce natural resources. Although several methods have been proposed, there is the existence of large number
of false alarms because of the interference of moving fire colored objects in outdoor environments. This paper proposes a method that will allow treat these situations. First, the pixels are selected by movement. So, these pixels are classified according to
their color. Finally, these pixels are grouped and the spatial and temporal information are extracted from these groups formed to
detect the fire. The contributions obtained in this work include the movement segmentation of the fire using colors, a committee
of classifiers to classify the pixels according to their color and spatial and temporal persistence partially based on the method of
ant colony. This approach makes it possible to significantly reduce the rate of false alarms obtained during fire detection.
Keywords fire detection, space temporal persistence, color segmentation
Resumo Algoritmos de detecção_de_incêndios por meio de vídeos têm se mostrado cada vez mais importantes, criando ferramentas para monitorar e proteger os cada vez mais escassos recursos naturais. Apesar de vários métodos terem sidos propostos
na literatura, esses métodos geram um grande número de alarmes falsos devido  interferência de vários objetos com cor de fogo,
principalmente em ambientes externos. Este artigo propõe um método que permite tratar essas situações. Primeiro, os pixels da
imagem capturada são selecionados segundo o movimento. Então, esses pixels são classificados segundo sua cor. Finalmente,
estes pixels são agrupados e as informações espaciais e temporais são extraídas desses grupos para a detecção das chamas. As
contribuições obtidas nesse trabalho incluem a segmentação por movimento do fogo utilizando cores, um comitê de classificadores na classificação dos pixels segundo sua cor e a persistência temporal e espacial baseada parcialmente no método de colônia
de formigas. Com isso é possível reduzir significativamente a taxa de alarmes falsos obtidos durante a detecção_de_incêndios.
Palavras-chave .

1

Introdução

do ao fato de tais linhas percorrerem grandes áreas
rurais e de cobertura florestal.
Com os avanços nas tecnologias de monitoração
e visão_computacional, algoritmos de detecção de
incêndios por imagem podem ser utilizados em conjunto com as câmeras instaladas nas torres de transmissão para diminuir os danos e os custos na monitoração de incêndios_florestais. No entanto, alguns desafios devem ser levados em conta. Um deles é a
limitação na avaliação e extração_de_características as
quais as máquinas estão sujeitas. As máquinas levam
em conta apenas alguns aspectos do contexto, baseando-se em características primitivas e interpretações
simples para a solução do problema.
Tendo em mente essas limitações, os trabalhos
encontrados na literatura se baseiam em construir
modelos que fazem uso de diversas características
visuais básicas, incluindo cores, movimento e geometria do fogo (Çelik, 2007 Toreyin et al., 2005 Toreyin et al., 2006 Wang et al., 2010). No entanto, esses
modelos acabam por gerar um grande número de
alarmes falsos devido  interferência de objetos com

Segundo estudos realizados pela World WildLife
Fund (WWF, 2012), a crescente demanda de recursos
naturais pela sociedade tem causado uma extensa
substituição das áreas florestais por áreas de plantio e
criação de gado. Geralmente no nosso país, o fogo é
usado como uma ferramenta eficiente e barata de
preparo do solo para estes fins (Motta, 2008). Isso
acaba gerando incêndios que causam prejuízos imensuráveis  fauna e flora quando estes atingem regiões
florestais não visadas para o plantio e pasto.
A monitoração por vídeo é uma alternativa bastante viável para tratar esses problemas, já que as
câmeras atualmente podem ser instaladas com relativa facilidade em praticamente qualquer lugar. Levando esta característica em consideração, as torres de
transmissão_de_energia_elétrica são um importante
recurso que pode ser utilizado para este fim. Tem-se
observado uma tendência mundial de instalação de
câmeras nas torres como meio de inspeção remota da
linha em manobras de religação após incidentes, alia157

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

por meio de imagens capturadas por câmeras instaladas nas torres de transmissão. O D383F usa 3 etapas,
onde em cada etapa foram adotadas estratégias que
permitem uma melhoria de desempenho com relação
a detecção das chamas, sendo elas
 Segmentação por movimento usando cores
 Classificação por cores usando um comitê
de classificadores heterogêneos
 Persistência espaço-temporal dos objetos
baseada parcialmente na técnica de colônia
de formigas.
Com essas etapas, o algoritmo pode facilmente
tratar alarmes falsos obtidos em ambientes externos,
melhorando a confiabilidade do mesmo sem sacrificar o desempenho de detecção e execução.
Os testes realizados neste trabalho utilizam uma
base de vídeos de âmbito florestal desafiadora que
possui diversas situações com objetos com cor de
fogo que apresentam características similares s encontradas em uma chama. Essa base, portanto, permite mostrar o desempenho de classificação, bem como
a robustez e confiabilidade obtida pelo algoritmo
D383F em relação  outros métodos.

cor de fogo que geralmente estão presentes na imagens do ambiente sendo monitorado (Wang et al.,
2010).
De maneira geral, tais algoritmos propostos possuem 3 etapas distintas, sendo elas segmentação por
movimento, classificação segundo sua cor e avaliação
do movimento do fogo.
A segmentação por movimento é uma etapa base
para o reconhecimento e classificação de objetos em
vídeo, diminuindo o custo_computacional exigido
pelas etapas subsequentes (Ko et al, 2010 Wang et
al., 2010). Para este fim, geralmente são usadas técnicas de subtração_de_fundo (Toreyin et al., 2006
Çelik et al., 2007 Wang et al., 2010).
Para a etapa de classificação por cor, cada autor
procura extrair as características que permitam separar de maneira eficiente as chamas de outros objetos.
Em (Chen et al., 2004), é mostrado que os pixels que
formam as chamas devem possuir saturação no canal
vermelho do espaço de cores RGB (vermelho, verde
e azul). Em (Çelik et al., 2009), os autores afirmam
que separar a luminância da crominância pode levar a
uma classificação mais eficiente, utilizando o espaço
de cores YCbCr para tratar o problema. Já (Toreyin et
al., 2006) geram um modelo próprio de classificação
por cor baseado em um modelo estatístico.
Após estas duas etapas, objetos que possuem cor
de fogo e movimento geralmente estão segmentadas.
No entanto alguns objetos que não são fogo podem
aparecer como falsos alarmes. Então, é necessária a
criação de modelos que permitam distinguir entre
esses objetos e chamas de maneira adequada. Em
(Chen et al,. 2004), o autor faz a contagem dos pixels
com cor de fogo para avaliar o movimento contínuo
do fogo. No entanto, em alguns casos como focos
distantes da câmera, as chamas podem não variar
suficientemente a quantidade de pixels na imagem
para avaliar de forma eficiente o movimento das
chamas.
Em (Toreyin et al., 2006), a característica de
flicker ou cintilância do fogo é analisada no domínio
da freqência espacial e temporal com a transformada_de_wavelet. Esta técnica geralmente é robusta, mas
em ambientes florestais, em que folhas ou outros objetos com cor de fogo ao vento podem se comportar
como chamas, é necessário utilizar outras metodologias para auxiliar na detecção correta das chamas (Ko
et al, 2010 Wang et al., 2010).
Em (Çelik et al. 2007), os autores criam uma
caixa de contenção em torno dos pixels com cor de
fogo, na qual a contração e expansão dessa caixa
permitem distinguir as chamas de outros objetos.
Novamente, os ambientes florestais geram problemas
em casos como folhas com cor de fogo balançando
ao vento e chamas não variando significativamente
suas dimensões.
Neste artigo, propomos um algoritmo que será
chamado D383F (F de fogo), referente ao projeto
CEMIG-ANEEL D383 que fazemos parte. Projeto
que tem como objetivo detectar incêndios_florestais

2 Algoritmo de detecção_de_incêndios
2.1 Segmentação por movimento
Os pixels em movimento na imagem de vídeo
são determinados através da técnica de subtração de
fundo estimada por médias adaptativas proposta por
(Donohoe et al., 1988). A técnica possui baixo_custo
computacional e usa imagens de vídeo obtidas por
câmeras fixas (Piccardi, 2004). Ela consiste basicamente de duas etapas a adaptação da imagem de
fundo (um filtro auto regressivo) e o cálculo do alvo
por meio do limiar.
No D383F, a subtração_de_fundo é realizada usando cores (espaço de cores RGB) para maximizar o
desempenho da captura das chamas nos ambientes
externos. Assim, a primeira etapa da técnica referente
 adaptação da imagem de fundo é calculada  R, G,
B) segundo
I n 1 (x , y),

se n  2
bg n ( x , y)  
(1  )bg n 1 (x , y) +  I n 1 (x , y),


caso contrário

(1)

onde bgn-1(x, y) e In-1(x, y) se referem, respectivamente, ao valor de intensidade do pixel na posição (x, y)
da imagem de fundo e no quadro anterior da sequência de vídeo (n-1). Com   (0, 1), assumindo um
valor constante (  0.0075, definido experimentalmente) que determina o tempo necessário para que a
influência de quadros antigos diminua na imagem de
fundo (Bradski et al., 2008).
A segunda etapa referente ao cálculo alvo por
meio do limiar irá identificar os objetos que não per158

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

informação referente  segmentação das chamas. Para
mostrar com mais clareza esta diferença, foi realizada
a subtração pixel a pixel dessas imagens, gerando
uma máscara binária dos pixels não nulos que pode
ser vista na Figura 3A. Nela é possível ver que a informação ignorada ao se utilizar escala de cinza para
a subtração_de_fundo corresponde exatamente  área
das chamas na imagem original colorida.

tencem ao fundo através de um parâmetro de limiar
Ts. Primeiro é realizada em cores a subtração pixel a
pixel do quadro atual da sequência de vídeo (In) da
imagem de fundo (bgn) segundo

sub( x, y)  I n ( x, y)  bg n ( x, y) ,

(2)

onde o resultado da operação contido em sub(x, y) é
convertido para a escala de cinza (sub(x,y)) por
sub  (x, y)  0.299R(x, y) + 0.587G(x, y) + 0.114B(x, y)

(3)

e submetido ao limiar Ts para identificar os pixels
que não pertencem  imagem de fundo. Logo, a regra
de segmentação dos pixels segundo o movimento é
1, se sub  ( x , y) > Ts
x , y  img F0 ( x , y)  
0, caso contrário ,

(4)

onde F0(x, y) para x e y varrendo toda a imagem é
uma máscara do objeto a ser identificado como um
conjunto de pixels em movimento. Com Ts (0, 255),
definido experimentalmente com o valor Ts  25.
Assim como relatado em (Toreyin et al., 2006), a
detecção do movimento tem como alvo capturar os
objetos em movimento através de um modelo bem
simples. Isso permite que a detecção do fogo possa
ser realizada em tempo_real pelo algoritmo. As etapas
posteriores são as responsáveis pela classificação
destes pixels como chamas verdadeiras ou não. A
Figura 1 mostra o resultado obtido da segmentação
por movimento de uma chama utilizando a técnica
citada.

Figura 2. Experimento de subtração_de_fundo em escala de cinza e
cores. (A e C) Em escala de cinza as chamas se confundem com a
fumaça, que são facilmente distinguíveis nas imagens coloridas (B
e D). (E e F) Resultados da segmentação da subtração_de_fundo.

Figura 3. (A) Resultado da diferença obtida entre as imagens E e F
da Figura 2. A diferença de informação na segmentação está exatamente na área que corresponde s chamas da cena, conforme
pode ser visto na imagem colorida (B).

2.2 Classificação dos pixels com cor de fogo
Segundo (Çelik et al., 2009), essa é a etapa mais
importante de um algoritmo de detecção_de_incêndios. Sendo fundamental selecionar um espaço de
cores que permita extrair as informações de cores das
chamas de maneira eficiente. Segundo os mesmos
autores, a separação da informação de luminância da
crominância é de extrema importância para uma melhor distinção das chamas de outros objetos. E, para
este fim, utilizam o espaço de cores YCbCr. Devido
aos resultados mostrados em seu trabalho, decidimos
usar (Çelik et al., 2009) como ponto de partida para a
classificação dos pixels segundo sua cor. Onde 4 de
suas 5 regras propostas são usadas, sendo elas

Figura 1. Resultado da segmentação dos pixels pelo movimento.
(A) Quadro atual do vídeo (B) Imagem de fundo (C) Resultado
da subtração_de_fundo.

Para mostrar o ganho de desempenho ao se utilizar as 3 dimensões de cores para a detecção das chamas em ambientes externos, foi feito um pequeno
experimento com um vídeo que possui fogo e fumaça
na mesma cena. Nesse vídeo a fumaça adquire tons
de cinza que se confundem com os tons de cinza gerados pelas chamas na imagem em escala de cinza.
A Figura 2 mostra os resultados obtidos da subtração_de_fundo em um quadro desse vídeo. Na primeira coluna temos a subtração com as imagens em
escala de cinza e na segunda coluna a subtração em
cores. Percebe-se que é praticamente impossível discernir as chamas da fumaça nas imagens em escala de
cinza.
As imagens resultantes da subtração_de_fundo em
escala de cinza e da subtração_de_fundo em cores (E e
F respectivamente) possuem uma diferença crítica na

1,
F1 ( x , y)  
0,
1,
F2 ( x , y)  
0,

se Y ( x , y) > Cb( x , y)
caso contrário
se Cr ( x , y) > Cb ( x , y)
caso contrário.

1, se Y ( x , y ) > Ymédio

C b ( x , y ) < C b médio

F3 ( x , y )  
C r ( x , y ) > C r médio

0 , caso contrário

159

(5)

(6)

e
e

(7)

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

1, se Cb( x , y)  Cr ( x , y) > 
F4 ( x, y)  
0, caso contrário.

ram usadas 50 imagens com fogo. Para cada imagem
foi calculado o valor de intensidade máxima obtida
por cada canal (Vmax) e a diferença entre este valor e
a média ( V ) obtida para todos os pixels da imagem
no canal. Esta estratégia permite avaliar o quanto as
cores das chamas próximo ao vermelho puro se destacam do resto da imagem (contraste ou Vc). Além
disso, o tempo médio para transformação do espaço
de cores RGB para cada um dos espaços citados
também foi calculado. Já que buscamos o tempo de
processamento menor possível para o novo classificador gerado. As informações sobre o hardware usado para este teste poderá ser visto com maior detalhes
posteriormente na seção 3.
A média do canal que representa a crominância
vermelha do espaço de cores ( V ), o valor máximo
(Vmax) e o contraste (Vc) são obtidos respectivamente
segundo

(8)

As regras F1 e F2 procuram separar os pixels referentes as chamas pela baixa saturação da cor azul.
A regra F3 analisa a característica de maior brilho do
fogo tendo em mente o valor de crominância azul
baixo em relação aos outros objetos na cena. E finalmente, a regra F4 utiliza a característica do espaço
de cor YCbCr de mostrar uma chama com valor de
intensidade alto no canal de crominância vermelho
(Cr) e um valor de intensidade baixo no canal de
crominância azul (Cb). Essa diferença entre Cr e Cb é
controlada por um limiar , definido através da técnica de curva ROC (Receiver Operating Characteristics). Para utilizar esta técnica, criamos uma base de
dados com 100 imagens de amostras (50 com fogo e
50 sem fogo) como indicado pelos autores, que nos
levou ao valor de 80. Este valor aproximou-se bastante dos resultados obtidos por (Çelik et al., 2009)
em seus experimentos (> 90 de acertos positivos e
< 40 de alarmes falsos).
A quinta regra utilizada em nosso trabalho é baseada nas informações de outro classificador, gerando um comitê de classificadores heterogêneos (Guyon et al., 2006).
Esse classificador obedece a certos critérios para
ser considerado heterogêneo e permitir uma melhor
separação das chamas usando as cores, sendo eles
 C1 - O espaço de cores utilizado por esse
classificador deve ser diferente do espaço de
cores YCbCr.
 C2 - Esse novo espaço de cores escolhido
deve permitir uma melhor separação das
chamas em seu canal com a informação de
crominância vermelha que a obtida usando o
canal Cr do YCbCr.
 C3 - O tempo gasto na transformação do espaço de cores RGB para o novo espaço de
cor escolhido deve ser baixo, já que um dos
objetivos desse trabalho é a detecção em
tempo_real.
Com relação a C1 e C2, é preciso levar em conta
os espaços de cores que separam a luminância da
crominância e os canais que representam a informação da cor vermelha em cada espaço de cores. Assim,
o experimento para a escolha do espaço de cores do
novo classificador foi feito com
 Canal V do YUV.
 Canal "u" do CIE Luv.
 Canal "a" do CIE Lab.
cujas transformações do RGB para cada respectivo
espaço de cor (inclusive o YCbCr) podem ser vistas
em (Intel, 2014 OpenCV, 2014 Bradski et al.,
2008). Nesse trabalho, foi usado a biblioteca livre
OpenCV para executar todas as transformações.
Para definir um modelo de avaliação da informação contida em cada canal de crominância vermelha e
compará-lo ao canal Cr do espaço de cor YCbCr, fo-

img img

V

w
h
1
V ( x , y)


img w img h x 1 y 1
Vmax  max V(x, y)

(9)
(10)

Vc  Vmax  V

(11)

onde V(x,y) é o valor de intensidade do pixel (x,y) no
respectivo canal de crominância vermelha.
A Tabela 1 mostra na quarta coluna a média dos
resultados obtidos para o teste de quantificação do
contraste da cor vermelha e na quinta coluna o tempo
gasto para a transformação do RGB para cada espaço
de cor (tendo como base as funções do OpenCV).
Tabela 1. Resultados obtidos para o teste de quantificação de
contraste da cor vermelha.

Médias de valores obtidos para
as 50 imagens com fogo
Canal V
YUV
Canal u
CIE Luv
Canal a
CIE Lab
Canal Cr
YCbCr

Vmax

V

Vc

Tempo gasto
(ms)

227.66

155.06

72.59

2.26

186.5

118.55

67.94

27.6

184.02

141.31

42.70

4.7

209.28

149.52

59.75

2.34

Pela Tabela 1 podemos ver que o canal V do espaço de cores YUV apresenta a maior diferença de
contraste e o melhor tempo na transformação da imagem do espaço de cores RGB, sendo este o canal
escolhido para o novo classificador proposto.
Usando as equações de 9 a 11, uma nova equação foi proposta para calcular um limiar de segmentação (TSV) baseado nas informações do canal V do
espaço de cores YUV. Essa equação se fundamenta
no fato que os pixels que compõem o fogo geralmente estão mais próximos ao valor de saturação que o
restante dos objetos na cena. Ou seja, os pixels possuem uma intensidade na crominância vermelha superior  média da cena.
160

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Desta forma, o limiar TSV consiste na média da
cena capturada ( V ) deslocada em função da diferença
entre ela e o valor máximo de intensidade da cena
(Vc) dividida por um valor de sensibilidade  que
controla o deslocamento, conforme mostrado a seguir

TSV  V +

Vc


(12)

onde o valor de  foi definido experimentalmente
como 1.8, obtendo bons resultados para os diversos
vídeos e imagens estáticas utilizadas.
A grande vantagem da equação (12) é permitir
que o limiar se altere dinamicamente de acordo com
a cena capturada. O que gera uma segmentação dos
pixels com cores que geralmente variam de amareloalaranjado até o vermelho. A segmentação dos pixels
através desse limiar fornece a informação de áreas
com maior probabilidade de ser um foco de incêndio
a partir das cores presentes na cena. Assim, a quinta
regra de classificação do pixel segundo sua cor referente ao uso do classificador baseado canal V do espaço de cores YUV é

1, se V ( x , y) > TSV
F5 ( x , y )  
0, caso contrário

Figura 4. Exemplo do funcionamento da regra F5 e da regra geral
de classificação do pixel segundo seu movimento e a cor. (A)
Quadro original de um vídeo de incêndio. (B) Segmentação dos
pixels segundo a regra F5, referente ao novo classificador proposto. (C) Em verde temos possíveis falsos positivos detectados
quando apenas as regras F0 a F4 são usadas. Em azul temos o
resultado obtido pelo comitê de classificadores (regra Fp), detectando apenas áreas de chamas na imagem.

(13)

Dentro das características que distinguem as
chamas de um incêndio de outros objetos com cor de
fogo em um vídeo (ex. roupas de pessoas ou pinturas
de carros), as mais importantes são o movimento
contínuo das chamas em torno do material combustível e o tempo de duração da chama. No geral, as
chamas ficam restritas a uma área da imagem levando
vários minutos para consumir o material combustível.
Já os falsos positivos geralmente apresentam uma
trajetória linear na imagem com um tempo de duração menor que a do fogo.
Para a utilização dessas características, uma nova
metodologia foi criada. Primeiramente os pixels classificados como parte de uma chama pela regra Fp são
agrupados através da técnica de agrupamento chamada florestas de conjuntos disjuntos (Cormen et al.,
2009). Esta técnica permite o agrupamento dinâmico
dos pixels através de um limiar de distância espacial
(TdG) entre os pixels. Isso elimina a necessidade de
determinar um número de grupos a priori, já que
estes podem variar constantemente em um vídeo.
Cada grupo (Ga) gerado é validado pelo seu número
de elementos ou pixels (TGmin) conforme (Çelik et al.,
2007). O que permite eliminar grupos que sejam pequenos e oriundos de ruído ou de uma parametrização pobre da segmentação por movimento. Logo

Finalmente, levando em conta a regra de segmentação por movimento (F0), as 4 regras (F1-F4)
propostas por (Çelik et al., 2009) e a regra do novo
classificador proposto (F5), a regra geral de classificação de um pixel pelo movimento e cor é
5

1, se
i0 Fi ( x , y)  6
Fp ( x , y )  
0, caso contrário

(14)

onde Fp(x, y) representa a classificação do pixel como sendo parte de uma chama ou não.
A Figura 4 mostra o funcionamento da regra F5 e
da classificação realizada pela regra geral. O ganho
de desempenho obtido com o comitê de classificadores pode ser visto na Figura 4C. Em cor verde temos
pixels pertencentes a fumaça, classificados erroneamente como fogo ao se utilizar apenas as regras de F0
a F4 (movimento + Çelik). Na cor azul estão os pixels
classificados como fogo ao adicionar a regra F5 s
demais regras. Ou seja, ao usar a totalidade das regras simbolizada por Fp, observamos que apenas áreas mais ativas das chamas são selecionadas, aumentando a confiabilidade do algoritmo D383F.

G a  G se a quantidade

2.3 Persistência espacial e temporal

de elementos de G a  TG min

Mesmo após as duas etapas anteriores, objetos
com cor de fogo e em movimento podem ser confundidos com chamas verdadeiras. Sendo necessária
outra etapa que permita eliminar o máximo possível
de alarmes falsos gerados pelo algoritmo.

(15)

onde G é resultado do agrupamento dos pixels pela
técnica de florestas de conjuntos disjuntos no quadro
de vídeo atual.

161

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

atual constatada dentro de uma área determinada pelo
parâmetro de limiar TmG. Este parâmetro controla a
quantidade de movimento que cada grupo tem a partir de seu Cg. E funciona como uma caixa de contenção imaginária para cada objeto detectado, avaliando
a característica do fogo de estar preso  fonte de
combustível. O parâmetro TmG foi definido experimentalmente como duas vezes e meia o valor de
TGmin.
Portanto, cada grupo gerado pela técnica de agrupamento no quadro atual (Ga) tem a distância de
seu centro de gravidade (Cga) medida em relação aos
demais I centros de gravidade anteriores (Cgi) contidos em MG. Se esta distância indicar que o grupo
atual Ga está dentro da área de alcance de algum dos
grupos de MG, ou seja, Cga - Cgi < TmG, Cgi é atualizado para o novo valor contido em Cga, EXi incrementado e ATi zerado. Caso não exista nenhum grupo Cgi próximo de Ga, uma nova entrada MGI+1 é
criada na estrutura de dados. Com CG I+1 recebendo o
valor de Cga, EX I+1  1 e AT I+1  0, onde I é o número total de entradas de MG antes do acréscimo
corrente.
Evidentemente, para que um grupo seja classificado como uma chama, ele deve ter seu valor de existência EX comparado a um limiar de persistência
espacial e temporal (Te). Este parâmetro é escolhido
de tal forma que galhos e folhas balançando ou pessoas e carros passando pela cena sejam ignorados
pelo tempo de existência em quadros de vídeo.
Quando um grupo ultrapassa esse limiar, esse
grupo é persistido espacialmente e temporalmente, ou
seja, o grupo é um foco de incêndio. Sendo esta a
regra final de classificação do algoritmo

Figura 5. Resultado do agrupamento dos pixels em movimento e
com de fogo com TdG e TGmin igual a 10 pixels.

A Figura 5 mostra o resultado do agrupamento
dos pixels em um quadro de vídeo de incêndio florestal. Foi utilizado TdG e TGmin igual a 10 pixels para a
resolução de 320 x 240 pixels, sendo identificados 4
grupos distintos.
Uma vez com os pixels agrupados, pode-se então
extrair as características espaciais e temporais de
cada grupo e realizar a persistência. Para isso, um
modelo baseado parcialmente na técnica de colônias
de formigas (Dorigo et al., 1999) foi criado. Em que
a ideia de depósito e evaporação de feromônios das
formigas é utilizada para persistir os grupos e eliminar possíveis falsos positivos.
A ideia é baseada no fato que a chama ao se
manter dentro da área em torno do combustível causa
um depósito constante de feromônios ao longo do
tempo em uma área. Ao contrário de outros objetos
que se movimentam menos como galhos e folhas em
determinadas condições ou objetos que apresentam
uma trajetória linear como pessoas ou carros. Estes
falsos positivos, embora depositem feromônios, não
conseguem superar a taxa de evaporação por depositar pouco ou de maneira espaçada.
De forma a implementar estas ideias propostas
acima no algoritmo D383F, foi criada uma estrutura
de dados simples (MG). Esta estrutura é similar a
uma tabela que guarda as informações espaciais e
temporais relevantes dos grupos detectados no vídeo
ao longo do tempo. Cada elemento dessa estrutura
corresponde a um grupo de pixels Ga detectado anteriormente no vídeo e possui as seguintes informações centro de gravidade do grupo (Cg), os feromônios (que chamaremos de existência ou EX) e a taxa
de atualização (AT) representando a informação de
evaporação dos feromônios. Então, cada linha da
estrutura de dados é representada como

1, se EX > Te
FGi  
0, caso contrário

No caso de utilização real do algoritmo, esperase que quanto maior o tempo de persistência (incêndios geralmente têm uma duração extensa), menor
será a incidência de alarmes falsos detectados pelo
algoritmo. Aumentando a confiabilidade da classificaçãodetecção_de_incêndios.
Ao final do processamento de cada quadro, o parâmetro ATi de cada elemento de MG recebe um
incremento de valor 1. Após o incremento, é calculada a evaporação dos feromônios ou o decremento de
EXi. Que ocorre quando um grupo deixa de ser atualizado por algum tempo (definido experimentalmente
como ATi > Te3). Por último, um grupo MGi é apagado da estrutura de dados se o mesmo não for atualizado pelo tempo estipulado por Te (ATi > Te). Isso
evita que MG cresça de maneira desordenada e que
grupos formados por objetos muito antigos continuem fazendo parte do modelo de detecção.
A Figura 6 mostra o resultado final obtido com a
união das 3 etapas referente ao mesmo vídeo ilustrado na Figura 5. Podemos ver que 3 focos de incêndios persistidos (caixas retangulares azuis) e um de-

MG i   Cg i , EX i , ATi 
para o i - ésimo grupo  i de 1 até I

(17)

(16)

O Cgi representa a característica espacial de cada
grupo de pixels, sendo o ponto médio calculado do
grupo. EXi contém a informação do tempo em quadros que MGi está sendo capturado e persistido segundo suas características espaciais e temporais. ATi
informa há quantos quadros MGi não recebe uma
atualização.
Para que a EXi seja incrementada, simulando o
depósito de feromônios, é necessário que o grupo
detectado no quadro atual do vídeo tenha a existência

162

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

com o D383F foram usados com os mesmos valores
citados ao longo do texto. TOR foi utilizado como
descrito pelo seu autor, de forma a ignorar os falsos
positivos dessa base. A Tabela 3 mostra os resultados
obtidos para cada um dos métodos testados nessa
base de dados. A acurácia informa a porcentagem de
acertos (verdadeiros positivos e verdadeiros negativos) obtidos por cada método na base de vídeos. E a
coluna de tempo gasto informa o tempo médio de
processamento gasto em segundos para cada vídeo da
base.
É importante salientar que todos os métodos foram capazes de detectar as chamas em cada um dos
vídeos com incêndio dessa base. Assim, o segundo
critério de avaliação se baseia no número de alarmes
falsos gerados por cada método, ou seja, a confiabilidade do método. Pelos resultados mostrados vemos
que o método CLKP se comportou como o esperado.
Reproduzindo os resultados mostrados em (Çelik et
al., 2009) com uma taxa de verdadeiros positivos
superior a 99 e uma taxa de alarmes falsos próxima
a 35. Mas devido ao fato de processar todos os
pixels indiscriminadamente, o método acaba possuindo o segundo maior tempo de processamento.

les em estado de observação (caixa retangular amarela). O ponto na cor ciano mostra o centro de gravidade do grupo naquele instante.

Figura 6. Resultado final obtido com as 3 etapas, 3 focos de incêndios persistidos temporalmente (caixas vermelhas) e 1 foco em
observação (caixa amarela).

3 Resultados
Para avaliar os resultados obtidos pelo algoritmo
D383F, um experimento simples foi realizado, usando uma base de dados de 10 vídeos florestais na resolução de 320 x 240 pixels. Nesta base temos 5 vídeos
que apresentam incêndios (VR1-VR5) e 5 que não
possuem chamas (controle), mas possuem objetos
com características em comum com fogo que podem
confundir os métodos (VR6-VR10). Cada vídeo está
a uma taxa de 10 quadros por segundo e possui um
total de 100 quadros, somando 1000 quadros para
toda a base. As informações de cada vídeo podem ser
vistas na Tabela 2.

Tabela 3. Resultados do teste na base de dados.
Método
CLKP
CLKS
TOR
Algoritmo
D383F

Tabela 2. Base de vídeos utilizada para o teste.
Vídeo
VR1
VR2
VR3
VR4
VR5
VR6
VR7
VR8
VR9
VR10

Descrição
Incêndio florestal com chamas laranja e fumaça
Incêndio florestal com chamas laranja e fumaça
Incêndio em uma montanha (longa distância)
Incêndio florestal  noite (longa distância)
Incêndio florestal  noite
Incidência de luz solar na grama (amarelo)
Árvores com folhas cor laranja ao vento (distante)
Galhos em frente ao pôr do sol (perto)
Leito de um rio com objetos de cor vermelha
Galho de cor vermelho escuro ao vento (perto)

Taxa de
verdadeiros
positivos
100.0
94.4
65.0

Taxa de
falsos
positivos
40.0
16.6
0.0

82.2

0.0

80.0
88.9
82.5

Tempo
gasto
(seg.)
4.0
1.7
4.7

91.1

1.9

Acurácia

Ao adicionarmos a etapa de segmentação por
movimento em CLKS, vemos que o desempenho de
classificação do algoritmo melhorou consideravelmente. Ocorrendo uma diminuição do número de
alarmes falsos e aumentando a confiabilidade do método, bem como conseguindo a menor média de tempo de processamento entre os métodos testados. Isso
se deve ao fato dos objetos estáticos agora serem
ignorados pelo método. Mas é preciso observar que,
mesmo que o resultado obtido seja melhor em relação
 CLKP, ainda há o problema de um número considerável de falsos positivos sendo detectados pelo método nessa base.
O método TOR é bastante citado na literatura pela sua robustez. Ele consegue eliminar grande parte
dos falsos positivos, mesmo quando estes objetos
estão em movimento. No caso dessa base de vídeos
desafiadora, TOR tratou todos os casos de alarmes
falsos encontrados por CLKP e CLKS nos vídeos de
controle, mantendo um bom desempenho com alta
confiabilidade. Por ser mais restritivo, o número de
quadros detectados nos vídeos com incêndios é menor, levando a uma acurácia menor que CLKS. É
importante ressaltar que nesta base, as chamas, na sua
maioria, estão distantes da câmera e em uma resolução baixa, interferindo com a etapa de avaliação da
cintilância do fogo. Essa avaliação de cintilância

Para comparação foram usados na mesma base
os métodos propostos por (Toreyin et al., 2006) e
(Çelik et al., 2009). Ainda, uma versão modificada
do trabalho de Çelik foi criada usando a etapa de
segmentação por movimento descrita nesse trabalho
para diminuir a taxa de falsos positivos, permitindo
avaliar o ganho com esta etapa. Os métodos vão ser
chamados respectivamente de TOR, CLKP (Çelik
puro) e CLKS (Çelik com subtração_de_fundo). Todos os algoritmos foram testados no mesmo computador com um processador AMD FX-8320 de 8 núcleos de 3.5 GHz e 8Gb de memória RAM. No caso
dos métodos CLKP e CLKS, os parâmetros comuns

163

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Agradecimentos

também leva a um custo_computacional maior, sendo
o método com a maior média de tempo de processamento por vídeo. Outro fator a ser considerado são os
vídeos VR1 e VR2, que apresentam chamas que se
confundem com a fumaça gerada pelo incêndio em
escala de cinza, usada na etapa de segmentação por
movimento do método.
O D383F também tratou todos os falsos positivos da base, mas sem sacrificar o desempenho de
classificação, mantendo uma taxa de verdadeiros
positivos relativamente alta. Consequentemente, obteve a melhor acurácia entre todos os métodos testados. O tempo de processamento foi um pouco superior ao CLKS, mostrando que as melhorias propostas
são simples e têm pouco impacto na complexidade do
algoritmo com a resolução usada de 320 x 240 pixels.
Em suma, os resultados mostram a robustez e confiabilidade do algoritmo D383F em relação ao outros
métodos testados. Sobretudo quando este é comparado a TOR, considerado estado da arte nesta área e
que faz parte de uma solução comercial atualmente.

O presente trabalho foi feito com o apoio financeiro
da CEMIG, ANEEL, CAPES, CNPq e FAPEMIG.

Referências Bibliográficas
Bradski, G. R. e Kaehler, A. (2008). Learning OpenCV.
Sebastopol, CA OReilly.
Chen, T. H., Wu, P. H., e Chiou, Y. C. (2004). An early
fire-detection method based on image processing.
International Conference on Image Processing 2004,
Vol.3, pp. 17071710.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., e Stein, C.
(2009). Introduction to Algorithms. The MIT Press,
3rd edition.
Çelik, T., Demirel, H., Ozkaramanli, H., e Uyguroglu, M.
(2007). Fire detection using statistical color model in
video sequences. IEEE Acoustics, Speech and Signal
Processing 2006, Vol. 2, pp.176185.
Çelik, T. e Demirel, H. (2009). Fire detection in video
sequences using a generic color model. Fire Safety
Journal, Vol. 44, pp. 147158.
Bortolini, D. E. (2013). Detecção de incêndios ambientais
utilizando persistência_espaço-temporal, segmentação
por cor e sub-amostragem de vídeo. Dissertação de
mestrado. Universidade Federal de Minas Gerais.
Donohoe, G., Hush, D. R., e Ahmed, N. (1988). Change
detection for target detection and classification in
video sequences. IEEE Acoustics, Speech and Signal
Processing 1988, Vol.2, pp. 184187.
Dorigo, M., Caro, G. D., e Gambardella, L. M. (1999). Ant
algorithms for discrete optimization. Artificial Life,
Vol. 5, pp. 137172.
Guyon, I., Gunn, S., Nikravesh, M., e Zadeh, L. A. (2006).
Feature Extractions Foundations and Applications.
Berlin, Springer-Verlag.
Intel
(2014).
Color
Models.
Disponível
em
httpintel.lyUMurvt Accessado em 12 Fev 2014.
Ko, B., Cheong, K. H., e Nam, J. Y. (2010). Early fire
detection algorithm based on irregular patterns of
flames and hierarchical bayesian networks. Fire
Safety Journal, Vol.45, pp. 262 270.
Motta, D. S. (2008). Identificação dos fatores que
influenciam no comportamento do fogo em incêndios
florestais. Tese de mestrado, Universidade Federal
Rural do Rio de Janeiro.
OpenCV (2014). Miscellaneous Image Transformation.
Disponível
em
httpdocs.opencv.orgmodules
imgprocdocmiscellaneoustransformations.html
Accessado em 16 Jun 2014.
Piccardi, M. (2004). Background subtraction techniques a
review. IEEE International Conference on Systems,
Man and Cybernetics, Vol. 4, pp. 30993104.
Toreyin, B. U. e Çetin, A. E. (2005). Flame detection in
video using hidden markov models. IEEE
International Conference on Image Processing 2005,
Vol.2, pp. 12301233.
Toreyin, B. U., Dedeoglu, Y., U., G., e Çetin, A. E. (2006).
Computer vision based method for real-time fire and
flame detection. Pattern Recognition Letters, Vol. 27,
pp. 49  58.
Wang, L., Ye, M., e Zhu, Y. (2010). Hybrid fire detection
using hidden markov model and luminance map.
Medical Image Analysis and Clinical Applications
2010. Vol 1, pp. 112 - 118.

4 Conclusão
O objetivo desse trabalho foi apresentar os resultados de um novo detectorclassificador de focos de
incêndio ambientais por meio de vídeo que permita
um alto nível de confiabilidade na execução da sua
tarefa sem sacrificar significativamente seu desempenho. De forma geral, as técnicas citadas na literatura
para a detecção_de_incêndios em ambientes externos
são eficientes, mas quando usados em um ambiente
florestal, podem produzir um grande número de alarmes falsos. Foi mostrado que utilizando ideias
simples e melhorias baseadas em outros estudos e
experimentação, o algoritmo D383F obteve um resultado satisfatório. Conseguindo tratar todos os alarmes
falsos em uma base desafiadora e mantendo um desempenho de classificação superior aos métodos previamente existentes. Isso se deve principalmente s
ideias propostas em cada etapa descrita do algoritmo.
Em que foram usadas as cores para a segmentação do
movimento, um comitê de classificadores por cor e a
persistência espacial e temporal dos objetos detectados. Cada uma dessas ideias propostas procura filtrar
as diferentes características intrínsecas do objeto de
interesse fogo, sem aumentar de forma significativa o
custo_computacional do algoritmo.
Pode-se concluir que o D383F se mostra ideal
para a monitoração de ambientes florestais em que a
intervenção humana deva ser mínima, como no caso
da proposta de instalação das câmeras de monitoramento nas torres de transmissão_de_energia_elétrica.
Experimentos realizados em (Bortolini, 2013)
com uma base de vídeos mais ampla e em resoluções
mais altas permitem mostrar de forma clara a robustez e simplicidade alcançadas do algoritmo D383F.
Bem como o uso deste no contexto de ambientes urbanos com chamas geradas a partir de outros materiais combustíveis não florestais, sem grandes alterações nos parâmetros citados neste trabalho.
164