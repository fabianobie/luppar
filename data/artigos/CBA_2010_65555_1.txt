RECONHECIMENTO DE PADRÕES UTILIZANDO O TEOREMA DO EIXO DE SEPARAÇÃO E
REDES NEURAIS ARTIFICIAIS
RODRIGO M. A. ALMEIDA, LEONARDO M. HONÓRIO
1. CRTI, IESTI, UNIVERSIDADE FEDERAL DE ITAJUBÁ(UNIFEI)
AV BPS 1303, BAIRRO PINHEIRINHO, 37500-903, ITAJUBÁ, MG, BRASIL
2. INCT, INERGE, UNIVERSIDADE FEDERAL DE JUIZ DE FORA (UFJF)
DEP. ENGENHARIA ELÉTRICA, GALPÃO 3PPEE, SALA 217 - CAMPUS UNIVERSITÁRIO
E-MAILS RODRIGOMAX@UNIFEI.EDU.BR, LEONARDO.HONORIO@UFJF.EDU.BR
Abstract This work presents a new technique of artificial neural networks training based on geometric techniques. It is
capable of generating the network topography without the necessity of parameters specification. Similar approaches, based on
geometric factors, are being developed with high hit rate and generalization capacity. In this work the axis separation theorem is
adapted for n-dimensional spaces, expanding the concept of OBB-trees to OBHB-trees. The algorithm is composed of four steps
OBHBs construction, search for the separation hiperplanes using axis separation theorem, select the best hiperplanes set and
neural net specification. Experimental results show that this technique could be successful used in classification problems
Keywords Artificial neural nets, axis separation theorem, patterns classification.
Resumo Este trabalho apresenta uma nova técnica de treinamento de redes_neurais artificiais baseado em técnicas geométricas. Este método tem a capacidade de gerar a topografia da rede sem necessidade de especificação de parâmetros. Técnicas simi lares, baseadas em fatores geométricos, vêm sendo desenvolvidas com altas taxas de acerto e boa capacidade de generalização.
Neste trabalho o teorema_de_eixos_de_separação foi adaptado para espaços n-dimensionais, expandindo o conceito de OBB-trees
para OBHB-trees. O algoritmo é composto de quatro etapas construção das OBHBs, busca dos hiperplanos de separação usan do o teorema dos eixos de separação, seleção do melhor conjunto de hiperplanos e especificação da rede_neural. Resultados ex perimentais demonstram que esta técnica pode ser utilizada com sucesso em problemas de classificação.
Palavras-chave 

1

Introdução

Este trabalho visa apresentar uma técnica para
determinação de uma rede_neural utilizando técnicas
de segmentação geométrica de maneira automática.
Para isto foi realizada uma adaptação do teorema de
eixos de separação, já utilizado para detecção de colisões em espaços bi e tridimensionais(S Gosttchalk,
1996) (Gottschalk, 2000), para espaços N-dimensionais.
Para realização desta proposta dividimos o procedimento em quatro etapas. A primeira é responsável pela construção dos objetos virtuais que representarão as classes. Estes objetos foram definidos
como hipercaixas pelas semelhanças que trazem
com as caixas tridimensionais.
A segunda etapa consiste na busca dos hiperplanos de segmentação. Utilizando o teorema dos eixos
de separação é possível encontrar o hiperplano, ou
conjunto de hiperplanos que separem corretamente
as classes.
Na terceira etapa realizou-se uma redução no
conjunto de hiperplanos encontrados. Pelos experimentos realizados é possível ver que para realizar a
correta classificação das classes geralmente não são
necessários todos os planos que foram encontrados.
A quarta etapa engloba a especificação e geração da rede_neural que agrega todas as características encontradas nas etapas anteriores. Sua estrutura
é definida apenas pelos hiperplanos encontrados,
não exigindo a especificação de nenhum parâmetro.

O processo de classificação de objetos é uma necessidade real presente em diversas áreas (Brudzewski,
et al., 2003) (Ding, et al., 2001) (Gentile, et al.,
2001) (Lippmann, 1989). Ao longo da história diversas técnicas surgiram, mas a maior dificuldade
era garantir uma taxa de acerto aceitável quando
considerados os erros advindos dos dados utilizados.
Esse problema foi em parte solucionado pelas técnicas de inteligência_artificial, por heurísticas específicas para cada caso, abordagens para melhoria das
capacidades de generalização e tratamento dos dados de entrada.
Duas abordagens são muito utilizadas atualmente uma baseada em técnicas de classificação
geométrica, como support_vector_machines ou SVM
(Chih, et al., 2002) (Fung, et al., 2005) (Gentile, et
al., 2001), e a segunda em teorias de inteligência_artificial, como as redes_neurais artificiais (Lippmann,
1989) (Chen, et al., 1997) (Bose, et al., 1993).
Ambas abordagens possuem vantagens e desvantagens. SVM consegue altas taxas de acerto e
tem uma boa fundamentação matemática, mas pode
não ser adequada para problemas multi classe. As
redes_neurais artificiais podem ser aplicadas em praticamente todos os problemas de classificação, sendo mais adequadas para sistemas multi classes, mas
possuem diversos parâmetros que precisam ser especificados a priori, principalmente a topologia da
rede(Mukkamala, et al., 2002) (Beale, et al., 1990).
1302

Para verificar se existe colisão é necessário testar se existe algum ponto pertencente a um objeto
que se encontra dentro do espaço delimitado pelo
outro. Este é um procedimento computacionalmente
caro e na maioria dos casos não pode ser realizado
no espaço de tempo exigido pela aplicação.
Uma alternativa para realizar esse procedimento é a utilização de volumes envolventes. Esta é
uma técnica amplamente utilizada por reduzir a
quantidade de cálculos utilizando o teorema do eixo
de separação conforme afirma Gottschalk (2000).
Gottschalk (2000) afirma ainda que entre os
modelos existentes para a geração dos volumes envolventes, o que apresenta melhores resultados é o
OBB-trees (Oriented bounding boxes), ou caixas envolventes orientadas.
O teste de colisão é composto de 3 etapas
 Geração das caixas envolventes
 Busca por planos de separação
 Divisão das caixas originais se necessário.

1.1 Treinamento de redes_neurais artificiais
Para se treinar uma rede_neural artificial é necessário, na maioria dos algoritmos disponíveis, definir 
priori a topologia a ser utilizada. Por topologia entenda-se quantidade de camadas, quantidade de
neurônios em cada camada, existência ou não de realimentação e as funções de ativação dos neurônios.
Para o caso das redes feed-forward, é possível
demonstrar que são necessárias no máximo 3 camadas de neurônios (entrada, intermediária e saída)
para que a rede consiga aproximar qualquer tipo de
função, isto é conhecido como teorema de Kolmogorov (Beale, et al., 1990). Apesar disto, não existe
maneira determinística para definir a quantidade ótima de neurônios necessários na camada intermediária para garantir o bom funcionamento da rede. Algumas abordagens foram desenvolvidas com este intuito, obtendo apenas sucessos parciais (Mirchandani, 1989).
1.2 Interpretação geométrica de um neurônio

2

Os neurônios de uma rede_neural possuem uma interpretação geométrica. Dado um espaço n-dimensional, onde n é o numero de entradas da rede_neural,
cada conjunto de entradas representa um ponto neste
espaço.
Neste espaço, o neurônio pode ser representado
por um plano. Se a função de ativação do neurônio
for binária, para uma entrada X, que representa um
ponto no espaço, sua saída indicará qual lado do
plano este ponto se encontra, conforme a Figura 1.

Metodologia proposta OBHB

Neste trabalho foi proposto o treinamento de redes_neurais a partir de uma abordagem geométrica
dos pontos, mas de maneira diferente das literaturas
estudadas (Mangasarian, 1968), (Gentile, et al.,
2001) e (Chen, et al., 1997). Através das técnicas de
verificação de colisão, utilizando a teoria dos eixos
de separação, temos uma maneira rápida e computacionalmente eficiente (S Gosttchalk, 1996) de calcular os planos de segmentação. Neste trabalho foi feita a expansão do conceito de OBB para N-dimensões, criando então uma hipercaixa envolvente
e orientada, ou OBHB  Oriented Bounding Hiperbox.
Através do teste de colisão modificado encontra-se os planos de separação entre os sólidos, que
representam agora o conjunto de dados de entrada
da rede_neural. De posse destes planos é gerada uma
rede_neural já treinada e apta a realizar a diferenciação dos dados.
A metodologia é dividida em duas partes o teste de colisão modificado e a geração da rede_neural.

Figura 1  Neurônio e respectiva representação gráfica

Conforme afirma Bose, et al., (1993), dois conjuntos de pontos podem ser separados por um conjunto de planos. Se for possível então agrupar os dados de entrada em conjuntos e encontrar esses planos de maneira geométrica é possível criar uma rede
neural que classifique os corretamente, como demonstrado em Gentile, et al., (2001) e Chen, et al.,
(1997).

2.1 Teste de colisão modificado
As mudanças realizadas no teste original se encontram resumidas na Tabela 1.
Tabela 1  Diferenças entre OBB-Tree e OBHB-Tree

1.3 Testes para colisão de objetos
Em algumas operações computacionais, principalmente jogos e simulações de ambientes reais
(Bourg, 2002), necessita-se de um sistema que detecte com precisão e velocidade adequadas as colisões entre os objetos.
A colisão entre dois objetos acontece quando
alguma região do primeiro se encontra dentro do espaço delimitado pelo segundo.

1303

O algoritmo de detecção_de_colisão foi divido
em quatro partes criação da hipercaixa envolvente,
busca por hiperplanos de segmentação, teste de colisão e seleção de hiperplanos. A estrutura de busca
em árvore é implementada na terceira parte enquanto o algoritmo para divisão dos pontos se encontra
na primeira.
Nos itens que se seguem é feita uma exemplificação do funcionamento dos algoritmos baseados
em um exemplo bidimensional com duas classes losangos(números) e círculos(letras). Tais pontos foram escolhidos arbitrariamente e podem ser visualizados na Figura 2.

caixas estão separadas os objetos não colidem.
Gottschalk (2000) afirma que basta analisar os eixos
paralelos aos vértices das caixas e as combinações
lineares destes para garantir a não colisão. Isto gera
(2N+N) testes para cada par de caixas, onde N é a
dimensão do sistema. Para o objetivo deste trabalho
iremos desconsiderar as combinações lineares das
faces, reduzindo a quantidade de testes para (2N).
Com isso a possibilidade de falsos positivos aumenta consideravelmente. Este aumento é compensado
pela estrutura de testes em árvores que terá que descer um nível a mais que na situação anterior. Como
vantagem tem-se a complexidade do algoritmo reduzida em uma ordem.
O teste de colisão é realizado projetando-se ambas as caixas nos sistemas de coordenadas locais de
cada uma. Este sistema é o mesmo que foi utilizado
para a geração da caixa (Figura 3). O teste pode ser
visualizado na figura 4. O procedimento é repetido
para todos os eixos do sistema de coordenadas local
de cada uma das caixas.

Figura 2  Pontos das classes usadas como exemplo

2.1.1 Construção da hipercaixa envolvente
Para encontrar os eixos sobre os quais repousa a
hipercaixa que melhor se ajusta aos dados de entrada são calculados os autovetores da matriz de covariância dos pontos. Os autovetores representam as
direções no espaço N-dimensional que indicam a
maior taxa de variação dos dados, onde N é a quantidade de atributos analisados. Esta é a abordagem
clássica para a formação dos volumes envolventes
(Gottschalk, 2000).
De posse destes vetores formamos um sistema
de coordenadas local (x,y) e realizamos a projeção
de cada um dos pontos nestes vetores. As projeções
nos retornam o tamanho da caixa em cada dimensão
conforme pode ser visto na Figura 3.

Figura 4  Teste de eixo na procura de plano de separação

Para um determinado eixo, o hiperplano, que
separa as hipercaixas, pode ser definido através de
um vetor normal e um ponto. O vetor normal é qualquer vetor paralelo ao eixo de análise. O ponto que
o plano corta o eixo foi definido para o escopo deste
trabalho como o ponto médio do espaço gerado entre as projeções das duas hipercaixas no eixo.
2.1.3 Teste de colisão
O algoritmo de teste de colisão verifica se
existe algum plano de segmentação entre as duas hipercaixas, através do algoritmo de busca por hiperplanos. Caso não exista nenhum hiperplano, ele divide uma das caixas e refaz o teste para cada um dos
filhos da caixa segmentada com a segunda caixa.
Este procedimento é repetido até que nenhum
dos objetos gerados colidam entre si, ou até não ser
possível mais dividir os objetos e mesmo assim haver colisão. Neste último caso não é possível separar
totalmente os objetos, pois existe um ponto que pertence a ambas as classes.
Este teste é feito numa estrutura de árvore. Deste modo existem diversas técnicas de busca que podem ser aplicadas para decisão de qual objeto será
dividido, quantas vezes será dividido e qual caminho seguir. Se a divisão for realizada sempre no
mesmo objeto, estaremos realizando uma busca em

Figura 3  Encontrando os limites de um volume envolvente

2.1.2 Busca por hiperplanos de segmentação
Após encontrar as hipercaixas para ambas as
classes de pontos verificamos todos os eixos do sistema. Segundo o teorema dos eixos de separação se
existir pelo menos um eixo no qual as projeções das
1304

profundidade pela árvore. Isto não é interessante,
pois deste modo o esforço computacional é concentrado, delineando em demasia o primeiro objeto.
Pela Figura 5 percebemos a estrutura de divisão em
árvore.

uma etapa de seleção de planos é realizada com o
intuito de reduzir a quantidade de planos a uma
quantidade mínima que ainda consiga dividir os
pontos adequadamente. Para realizar esta seleção
definimos um vetor binário para cada plano de forma a identificar a posição do ponto no espaço. O vetor possui dimensão igual  quantidade de planos
encontrados. Se o ponto 1 se encontra no semiplano
positivo, aquele apontado pelo vetor normal, do plano Pi este é rotulado com 1 na posição i do vetor de
classificação. Caso contrário o valor será 0. Para os
pontos da Figura 6, a classificação será dada de
acordo com a Tabela 2.
Tabela 2  Classificação dos pontos

Para garantir a separação dos grupos, todos os
vetores de classificação para o primeiro grupo devem ser diferentes dos vetores de classificação do
segundo grupo.
Para efetuar tal seleção inicia-se com o primeiro ponto da classe circulo (ponto A) e o primeiro da
classe losango (ponto 1). Procura-se o primeiro hiperplano que o classifique de maneira diferente. O
hiperplano P1 não satisfaz essa afirmação, pois classifica o ponto A e o ponto 1 como positivos. Isto
pode ser visualizado na primeira posição do vetor
classificação na Tabela 2, onde ambos estão definidos com o valor 1. O plano P2 também não pode ser
selecionado, pois ambos os pontos são classificados
como negativos. O primeiro hiperplano que efetivamente separa os dois é P3.
Assim que o primeiro ponto for separado, incrementamos a posição passando para o segundo ponto,
nesse caso o ponto 2. Neste momento é verificado
se eles (A e 2) já não estão separados pelos hiperplanos selecionados anteriormente. Por já estarem
separados prosseguimos comparando o ponto A com
os demais 3, 4, ... 10. Ao chegar no décimo ponto,
é possível perceber que eles (A e 10) estão classificados da mesma maneira (positivos). Procura-se então um hiperplano que os separe. Selecionamos, por
causa da ordem crescente, o plano P1. Agora o ponto A é classificado como (1,1) e o ponto 10 como
(1,0).
Quando o primeiro ponto do primeiro grupo estiver completamente separado do segundo grupo, o
procedimento é refeito para o segundo ponto. Neste
exemplo, apenas estes dois hiperplanos, P3 e P1, são
necessários para separar todos os pontos, conforme
podemos visualizar na Figura 7.

Figura 5  Opções para divisão

2.1.4 Seleção de hiperplanos
Com o prosseguimento do algoritmo de busca
chega-se  um ponto onde as caixas, já segmentadas
em caixas filhas, apresentam separação umas das
outras. Neste ponto é possível encontrar todos os
possíveis planos de segmentação, conforme são
apresentados na Figura 6, para o exemplo apresentado.

Figura 6  Hiperplanos encontrados para o exemplo

Após encontrar todos os hiperplanos, é necessário realizar uma seleção com a finalidade de reduzir
este número a uma quantidade que seja suficiente
para separar os pontos utilizados para treinamento.
A partir da Figura 6 pode-se notar que os hiperplanos dividem o espaço em diversas regiões. Para
que os hiperplanos consigam separar as classes corretamente, não pode haver pontos de classes distintas numa mesma região.
É possível observar também que nem todos os
planos encontrados são necessários. Deste modo

1305

tura (Chih, et al., 2002) (Ding, et al., 2001), entre
elas uma parece ser apropriada e facilmente implementada one-against-all. Uma representação gráfica desta técnica está apresentada na Figura 9.

Figura 7  Pontos do exemplo corretamente separados

2.2 Geração da rede_neural
A rede_neural a ser gerada é constituída de 2 camadas. A primeira camada representa os hiperplanos encontrados. A segunda camada identifica as regiões que possuem pontos. Em problemas de ordens
superiores é possível que algumas regiões do espaço, na divisão final dos hiperplanos, não possuam
pontos internos. Estas regiões são eliminadas e apenas as demais são utilizadas na formulação da rede
neural. A etapa anterior, o teste de colisão, garante
que não existe nenhuma região com pontos internos
pertencentes a classes diferentes. Deste modo, cada
neurônio da segunda camada será responsável por
uma região do espaço.
Com esta formulação garante-se que, quando
um ponto cair em uma região completamente conhecida, o neurônio responsável por aquela região
indicará 1 em sua saída. Caso o ponto recaia numa
região não identificada, o neurônio que possuir o
maior valor indicará a região mais próxima daquela,
caracterizando assim a generalização do conhecimento.
Através dos hiperplanos e regiões apresentados
na Figura 7 pode-se montar a rede_neural apresentada na Figura 8.

Figura 9  Técnica de classificação multi-classe one-against-all

Nesta técnica são gerados N problemas, onde N
é o número de classes que desejamos separar. Em
cada subproblema elege-se uma classe principal diferente. As outras classes serão agrupadas sob um
único rótulo e o problema toma novamente uma forma binária. Ao fim do procedimento serão geradas
N redes_neurais, cada qual especializada para uma
determinada classe.
3

Resultados

3.1 Banco de dados utilizados
Para validação da técnica desenvolvida é necessário testar o modelo com bancos de dados conhecidos. Neste estudo foram utilizados seis bancos de
dados obtidos do repertório disponibilizado pela
UCI (Asuncion, et al., 2007), sendo que dois destes
são de autoria da Statlog. Estes bancos foram escolhidos por serem utilizados na literatura pesquisada
(Chih, et al., 2002) e (Fung, et al., 2005). Na Tabela
3 são apresentadas algumas informações destes bancos de dados.
Tabela 3  Banco de dados utilizados no teste

Figura 8  Rede neural gerada para o exemplo apresentado

3.2 Testes
Foram testados todos os bancos de dados utilizando tenfold. Na Tabela 4, é apresentado um resumo dos resultados obtidos para todos os bancos de
dados utilizando a técnica proposta OBHB. Em todos os testes a taxa de acerto para os dados utilizados no treinamento foi de 100. O valor representa

2.3 Modificações para problemas com mais de uma
classe
O algoritmo apresentado foi desenvolvido para
utilização com duas classes apenas. Para adaptar
classificadores binários para sistemas multi-classes,
existem algumas maneiras apresentadas pela litera-

1306

a taxa média de acerto nas 10 rodadas. O melhor resultado é apresentado em negrito.

Theory and Applications. Julho de 1997, Vol.
44, 7.
Chih, Wei H. e Chih, Jen. L. 2002. A Comparison
of Methods for Multiclass Support Vector
Machines. IEEE Transactions on Neural
Networks. Março de 2002, Vol. 13, 2, pp. 41525.
Ding, Chris H Q e Dubchack, Inna. 2001. Multiclass protein fold recognization using support
vetor machines and neural networks.
Bioinformatics. Abril de 2001, Vol. 17, 4, pp.
349-358.
Fung, Glenn M e Mangasarian, O L. 2005.
Multicategory Proximal Support Vector
Machine Classifiers. ed. Shai Ben David.
Machine Learning. 59, 2005, pp. 77-97.
Gentile, C e Sznaier, M. 2001. An Improved
Voronoi-Diagram-Based Neural Net for Pattern
Classification. IEEE Transactions on Neural
Networks. Setembro de 2001, Vol. 12, 5, pp.
1227-1234.
Gottschalk, S. 2000. Collision Queries using
Oriented Bounding Boxes. Departamento de
Ciência da Computação, Universidade da
Carolina do Norte. Chappel Hill, 2000. Tese de
Doutorado.
Lippmann, R.P. 1989. Pattern classification using
neural networks. Communications Magazine,
IEEE. Novembro de 1989, Vol. 27, 11, pp. 4750, 59-64.
Mangasarian, O L. 1968. Multisurface Method of
Pattern Separation. IEEE Transactions on
Information Theory. Novembro de 1968, Vol.
14, 6, pp. 801-807.
Mirchandani, G. 1989. On Hidden Nodes for Neural
Nets. IEEE Transactions on Circuits and
Systems. Maio de 1989, Vol. 36, 5, pp. 661664.
Mukkamala, Srnivas, Janoski, Guadalupe e Sung,
Andrew. 2002. Intrusion Detection Using
Neural Networks and Support Vector Machines.
Proceedings of IEEE International Joint
Conference on Neural. 2002, pp. 1702-1707.
S Gosttchalk, M C Lin, D Manocha. 1996. OBBTreeA Hierarchical Structure for Rapid
Interference Detection. ACM Siggraph96.
1996, pp. 171-180.

Tabela 4  Resultados de OBHB versus literatura

4

Conclusão

Este trabalho apresentou uma nova técnica de
treinamento de redes_neurais, OBHB-Tree, baseada
na teoria dos eixos de segmentação. Ela é capaz de
definir a estrutura, tamanho e pesos das conexões de
uma rede_neural de forma analítica, baseado apenas
nos dados de entrada, sem nenhum outro conhecimento  priori.
Com base nos resultados demonstrados, conclui-se que a técnica de especificação e treinamento
de uma rede_neural baseada em segmentação de elementos apresenta valores de acertos comparáveis
com os apresentados pela literatura.
A técnica utilizada para resolver problemas
multi-classes (one-against-all) se mostrou satisfatória.
Agradecimentos
Os autores gostariam de agradecer  CAPES e 
FAPEMIG pelo apoio financeiro.
Referências Bibliográficas
Asuncion, A e Newman, D J. 2007. UCI Machine
Learning Repository. Online University of
California, School of Information and
Computer Science., 2007. Citado em 23 de 10
de
2008.
httpwww.ics.uci.edumlearnMLRepository.
html. Irvine, CA.
Beale, R e Jackson, T. 1990. Neural computing an
introduction. s.l.  Hilger, 1990. p. 240.
Bose, N K e Garga, A K. 1993. Neural Network
Desing Using Voronoi Diagrams. IEEE
Trasactions on Neural Networks. Setembro de
1993, Vol. 4, 5, pp. 778-787.
Bourg, D M. 2002. Physics for Game Developers.
Sebstopol  OReilly, 2002. p. 326.
Brudzewski, K., Osowski, S. e Markiewicz, T.
2003. Classification of milk by means of an
electronic nose and SVM neural network.
Sensors and Actuators B Chemical. 2003, Vol.
98, pp. 291-298.
Chen, Y Q, Damper, R I e Nixon, M S. 1997. On
Neural-Network Implementations of k-Nearest
Neighbor Pattern Classifiers. IEEE Transactions
on Circuits and SystemsI Fundamental

1307