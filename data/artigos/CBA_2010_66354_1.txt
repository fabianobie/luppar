XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

DESENVOLVIMENTO DE UM SISTEMA DE APRENDIZADO PARA O CONTROLE
DO CAMINHAR DE UM ROBO UTILIZANDO APRENDIZADO POR REFORCO
Jeeves Lopes dos Santos, Cairo Lucio Nascimento Jr., Luis F. W. Barbosa


Laboratorio de Maquinas Inteligentes - LMI
Divisao de Engenharia Eletronica
Instituto Tecnologico de Aeronautica - ITA
Sao Jose dos Campos, Sao Paulo, Brasil

Emails jeeves@ita.br, cairo@ita.br, wiltgen@ita.br
Abstract This article describes a learning methodology in Walking Machine to determine the coordination of
the robot actuators in order to allow a fast and stable forward movement. The symmetry of the robot is considered
in order to speed up learning. The behavior of actuators is described by functions which are characterized by
linearly interpolated points. The value of these points is accomplished using a reinforcement learning algorithm
known as Bootstrap Learning. During learning, a simulated environment (MatLabSimulink) is used. In this
environment, the SimMechanics toolbox is used to represent the physical model of the robot which was built
with four legs and three actuators in each leg. The evaluation of this topology is done by generating 30 sets of
functions that are apllied to the 12 actuators. As result, the algorithm converge in all cases and a fast and stable
movement was obtained in the simulated environment.
Keywords
of learning.

Artificial Intelligence, Walking Machine, Reinforcement Learning, Bootstrap Learning, Topology

Resumo Este artigo apresenta uma topologia_de_aprendizado capaz de gerar uma coordenacao eficiente entre
os atuadores de um robo quadrupede (com tres atuadores por perna) construdo com o BIOLOID Comprehensive
Kit da ROBOTIS levando-o a se locomover para frente de uma forma rapida e estavel. O aprendizado leva em
consideracao as simetrias existentes no robo visando simplificar o problema a ser resolvido e, consequentemente,
aumentar a velocidade de convergencia do aprendizado. Para tal, o comportamento dos atuadores e descrito
atraves das defasagens entre as pernas existentes e por funcoes que descrevem a posicao_angular de cada atuador
ao longo do tempo. O ajuste dos pontos das referidas funcoes e realizado atraves de um algoritmo de aprendizado
por reforco conhecido como Bootstrap Learning. Durante a fase de aprendizado o toolbox SimMechanics do
software MatLabSimulink e utilizado na simulacao da dinamica do robo e do ambiente de navegacao. Para
avaliar a abordagem proposta, 30 experimentos de aprendizado foram simulados, gerando 30 conjuntos de funcoes
para serem aplicadas nos atuadores. Obteve-se a convergencia do algoritmo de aprendizado em todos os casos
simulados e a melhor solucao foi aplicada no robo real.
Palavras-chave .

1

Introducao

Scheier, 1999).
Para viabilizar o deslocamento de um Walking
Machine e necessario definir o comportamento dos
seus atuadores (por exemplo, motores em suas
juntas). Assim, considerando um controle_em_malha_aberta, os referidos comportamentos podem
ser representados por funcoes cclicas de perodo
T que identifiquem as posicoes angulares de cada
um desses elementos do robo.
No trabalho aqui apresentado, cada funcao
f (t) e representada por um conjunto de pontos
interpolados linearmente entre si como ilustrado
na Figura 1, onde N E corresponde ao numero de
pontos que definem a funcao periodica e T N E e
o tempo de transicao entre cada ponto da curva e
o seu sucessor.
Assim, para realizar o deslocamento do robo,
inicialmente todos os atuadores sao colocados nas
suas respectivas posicoes iniciais e um determinado tempo e aguardado para que o robo estabilize. Apos esse perodo, as funcoes cclicas sao
aplicadas em cada perna levando-o a realizar um
passo completo a cada perodo de tempo T .
Utilizando essa estrategia, um sistema de

A robotica_movel constitui-se como uma vertente
no ambito da robotica que almeja aumentar a versatilidade de diversos tipos de equipamentos com
o advento da locomocao. Neste contexto, a utilizacao de rodas corresponde a configuracao mais
comum para os robos que se locomovem em terra
devido a sua facilidade de uso e seu desempenho
em terrenos regulares. Porem, sua performance
e comprometida ou a sua utilizacao inviabilizada
em ambientes acidentados. Assim, neste tipo de
ambiente, os robos com pernas, tambem conhecidos como walking_machines, constituem-se uma
promissora opcao.
As pesquisas desenvolvidas em walking_machines tambem podem ser utilizadas para testar
ideias de como funciona o sistema de locomocao
dos seres vivos (Ijspeert, 2008) e ajudar pessoas
com problemas motores atraves da aplicacao dos
avancos obtidos em equipamentos que auxiliem na
locomocao do ser humano. Alem disso, as pernas
podem proporcionar um maior grau de identificacao entre o homem e o robo facilitando a insercao
desses equipamentos em seu cotidiano (Pfeifer and

5028

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

funcoes que regem o comportamento dos atuadores, a secao 3 apresenta os resultados experimentais obtidos e a secao 4 apresenta as conclusoes e
os trabalhos futuros.
2

O aprendizado_por_reforco se baseia na relacao
causa-efeito, onde uma determinada entrada r e
aplicada no sistema e, a partir da qualificacao da
resposta gerada pela sada y atraves da funcao objetivo J, e realizado o ajuste dos parametros envolvidos.
No problema em questao, a referida entrada r
e formada por um vetor contendo os pontos e as
velocidades angulares utilizadas como referencia
para os controladores locais. Estes controladores
estao embarcados em cada atuador do robo. Ja
a sada y apresenta algumas informacoes obtidas
atraves dos sensores sobre a interacao do robo com
o ambiente, tal como posicoes e velocidades angulares e a distancia total percorrida.
Partindo dessa premissa, a topologia adotada
neste trabalho pode ser dividida em quatro blocos como ilustrado na Figura 2, onde o gerador
de funcoes, o algoritmo de aprendizado, a funcao
objetivo e o robo interagem de forma cclica, onde
cada iteracao segue os seguintes passos

Figura 1 Representacao das funcoes aplicadas nos
atuadores do robo.
aprendizado para um robo com tres atuadores por
perna, quatro pernas e N E  4, necessitaria ajustar 48 pontos para definir as 12 funcoes necessarias. Como em um sistema de aprendizado a velocidade de convergencia esta associada a quantidade de informacao que deve ser adquirida, e
interessante utilizar artifcios para minimizar o
numero de funcoes a serem determinadas. Para
tal, pode-se levar em consideracao as simetrias
existentes no robo, ou seja, todas as pernas que
possuem uma mesma configuracao podem utilizar
uma mesma funcao com uma determinada defasagem.
Dessa forma, considerando que no exemplo
dado todas as pernas sejam fisicamente identicas,
e necessario ajustar os 12 pontos que descrevem
as tres funcoes dos atuadores de uma das pernas,
bem como as tres defasagens referentes as outras.
Em suma, na abordagem utilizada, deve-se
ajustar os pontos das funcoes e as defasagens apresentadas na Equacao (1), onde N A equivale ao numero de atuadores de cada perna, N P e o numero
de pernas e i refere-se a defasagem da perna i.
 1
1
1
f (t)  f01 , f11 , ..., fN

E2 , fN E1 


2
2
2
2
2

f (t)  f0 , f1 , ..., fN E2 , fN E1 



 ..
..
.
.
NA
NA
NA
NA
NA

f
(t)

f
,
f
, ...fN

0
1
E2 , fN E1 






  1 , 2 , ..., N P , 1  0

Metodologia do aprendizado

1. Baseado no conhecimento existente, o algoritmo de aprendizado gera um conjunto de
funcoes f 1 (t), ..., f N A e o vetor  e repassaos para o gerador de funcoes
2. O gerador de funcoes utiliza essas informacoes para originar o vetor r
3. O vetor r e utilizado pelos controladores locais do sistema para executar um passo completo
4. A qualidade da resposta obtida pelo sistema
e quantificada atraves da sada y e da funcao
J

(1)

5. O algoritmo de aprendizado utiliza o valor de
J para aprimorar o conhecimento existente
6. O algoritmo verifica se o desempenho do robo
ja e considerado adequado. No caso afirmativo, a fase de aprendizado e finalizada, caso
contrario o algoritmo retorna ao passo 1.

Neste contexto, este artigo apresenta o desenvolvimento de um sistema de aprendizado capaz de determinar as referidas funcoes com uma
defasagem fixa fornecida pelo projetista. Para
tal, uma tecnica de aprendizado com supervisao
fraca e utilizada. Nesta, o supervisor apenas fornece informacoes de sucesso ou fracasso durante
a fase de treinamento (Nascimento Jr. and Yoneyama, 2000). A referida tecnica consiste em um
aprendizado_por_reforco conhecido como Bootstrap
Learning (Widrow et al., 1973).
Assim, neste artigo a secao 2 apresenta a metodologia adotada no processo de aprendizado das

2.1

Robo - Mundo Fsico  Simulado

No processo de aprendizado aqui descrito foi utilizado um Walking Machine com as caractersticas
apresentadas na Tabela 1 em dois ambientes distintos no mundo fsico e em um ambiente simulado.
No mundo fsico, o referido robo (Fig. 3) foi
montado utilizando o BIOLOID Comprehensive

5029

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Como neste momento os sensores disponveis
ainda nao tem a capacidade de fornecer informacao a respeito da instabilidade do robo durante
o processo de aprendizado, o robo do mundo fsico apenas e empregado na avaliacao das funcoes
obtidas com o robo no ambiente simulado.
Neste ambiente, o robo corresponde ao modelo extrado do mundo fsico no intuito de obter
o comportamento de uma forma simulada, permitindo assim, extrair as informacoes necessarias
para o processo de aprendizado.
A utilizacao de simulacoes consiste em uma
ferramenta largamente utilizada nos processos de
aprendizado da coordenacao dos atuadores de walking_machines. Isso ocorre devido ao fato de que,
apesar das simulacoes descreverem uma aproximacao do comportamento real do robo, elas possuem
algumas vantagens (Law and Kelton, 1999)

Figura 2 Topologia adotada para o processo de
aprendizado

1. Nao existe o risco de danificar o robo

Tabela 1 Caractersticas do robo quadrupede.
Peso Dimensoes (cm)
N P N A (kg) X
Y
Z
4
3
1, 54 30 19, 5
11

2. Nao ha necessidade de recarga da bateria
3. O reposicionamento do robo pode ser feito
sem a intervencao humana

Kit que corresponde a um conjunto de componentes que podem ser dispostos de diversas formas, desde pequenos robos com rodas ou garras,
ate humanoides. Os referidos componentes correspondem a

4. Existe a possibilidade de se acelerar a simulacao, reduzindo o tempo de aprendizado

1. Uma unidade de processamento microcontrolada conhecida como CM-5 que e responsavel
por gerenciar os elementos existentes no robo
atraves de uma comunicacao serial

O modelo simulado (Fig. 4) foi implementado atraves da utilizacao de um toolbox do
MatlabSimulinkT M chamado SimMechanicsT M .
Essa ferramenta consiste em um diagrama_de_blocos capaz de descrever e simular complexos equipamentos mecanicos com a combinacao de corpos
rgidos. Esses corpos sao conectados atraves de
juntas simuladas que determinam quais tipos de
movimento (translacao eou rotacao) podem ser
realizados.
Para complementar o modelo, deve-se simular as principais forcas que incidem nos referidos
corpos que, para o trabalho em questao, podem
ser resumidos pelas forcas de reacao de contato e
forcas de atrito entre os pes do robo e o solo. Para
ambas as forcas existem diversos modelos como os
utilizados em (Gonthier et al., 2004), (Marhefla
and Orin, 1996), (Juhasz and Rusin, 2007) e
(Lunzman et al., 2008).
Para este trabalho modelou-se a forca de reacao de contato (fN ) atraves da equacao (2), onde
K e a constante elastica, B a constante de amortecimento e x e a distancia de penetracao no solo.

5. Varias morfologias de robos podem ser testadas antes da construcao do robo real.

2. Sensores de distancia e deteccao de som que
fornecem informacoes do ambiente para o
CM-5 quando solicitado
3. Um conjunto de servomotores com microcontroladores dedicados que agem como um controlador local em cada junta do robo. Dessa
forma, o CM-5 pode informar o angulo e a
velocidade desejada que o sistema_embarcado
gera os sinais necessarios para que o atuador
tenha o comportamento desejado
4. Diversos tipos de armacoes para conectar os
componentes permitindo compor o robo desejado


fN 

0
se xn < 0
Kx + B x se xn > 0

(2)

Ja a forca de atrito (fA ) e representada pela
equacao (3) onde  e o coeficiente de atrito que e

Figura 3 Robo quadrupede utilizado nos testes

5030

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Para implementar o GF, inspirado no mecanismo de geracao_de_padroes rtmicos existente nos
seres vivos (o CPG ou Central Pattern Generator
(Ijspeert, 2008)), subdividiu-se a sua topologia de
tal forma a gerar um controle distribudo, onde
os Nucleos Geradores de Padroes (NGP) correspondem as entidades independentes que originam
as funcoes para os atuadores de uma perna especfica.
Assim, como ilustrado na Figura 6, o Gerador
de Funcoes e composto por
1. Uma quantidade de NGPs equivalente ao numero de pernas (N P )
2. Pelo conjunto de parametros utilizados por
esses NGPs na determinacao das funcoes aplicadas nos atuadores de cada perna
3. Pelo conjunto de defasagens especficas (do
N GP2 ao N GPN P ).

Figura 4 Modelo utilizado no processo de aprendizado e a representacao grafica gerada pelo SimMechanics
subdividido em dinamico (K ou M U K) e estatico (S ou MUS). Porem, para evitar uma descontinuidade na transicao da aplicacao do coeficiente de atrito estatico e dinamico, o  se comporta de acordo com o grafico da Fig. 5, onde
VT H e a velocidade determinada pelo projetista
para delimitar a regiao de transicao entre os tipos
de coeficiente de atrito.
fA  fN  

(3)

Figura 6 Subdivisao do bloco gerador de funcoes.
Assim, cada Nucleo Gerador de Padroes utiliza os parametros e as defasagens para compor o
vetor r com os pontos correspondentes as posicoes
e velocidades angulares almejadas para os atuadores. Assim, o comportamento entre o ponto atual
e o seguinte e regido pelo controlador local.

Figura 5 Coeficiente de Atrito X Velocidade.
Para os testes realizados neste artigo, os valores de K, B, K , S e VT H foram determinados
de forma emprica visando representar o comportamento do robo real. Assim, os seus valores foram
N
N
fixados respectivamente em 1500 m
, 25 ms
, 0, 85,
1 e 0, 01s.
2.2

2.3

Algoritmo de aprendizado

O Gerador de Funcoes e o robo atuam como um
sistema_de_controle de malha_aberta viabilizando
a locomocao do equipamento. Porem, a coordenacao eficiente dos atuadores depende dos parametros e das defasagens entre as pernas. Logo, ha a
necessidade de uma fase na qual esses dados sejam
ajustados em busca de um objetivo. Esta etapa
pode ser denominada de treinamento ou fase de
aprendizado.

Gerador de Funcoes

O Gerador de Funcoes (GF) corresponde ao bloco
onde as informacoes necessarias para a execucao
do movimento sao armazenadas e utilizadas para
originar as funcoes que descrevem o comportamento almejado para os atuadores.

5031

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

O algoritmo de aprendizado e o responsavel
por realizar esse ajustes. O mesmo utiliza tecnicas
para otimizar as variaveis envolvidas de tal forma
a maximizar a funcao que descreve o objetivo almejado, em outras palavras, maximizar a funcao
J. Neste trabalho, o algoritmo em questao e implementado utilizando um tipo de aprendizado por
reforco conhecido como Bootstrap Learning.
O aprendizado_por_reforco e uma tecnica que
se baseia na tentativa e erro, onde pode-se atribuir uma gratificacao para cada resultado considerado bom e uma penalidade para o considerado ruim. Esse conceito de qualidade do resultado e proveniente do valor de J. Ja o Bootstrap
Learning corresponde a um aprendizado_por_reforco onde o conhecimento atual e utilizado para
atualizar o conhecimento subsequente (Sutton and
Barto, 1998).
Neste trabalho, para implementar a referida
tecnica, primeiramente sao definidos os possveis
valores que podem ser utilizados como parametros. Esses valores correspondem ao conjunto de
possveis pontos que podem compor a funcao que
descreve o comportamento de cada atuador. Para
definir esse conjunto de pontos, primeiramente
o projetista deve ajustar o Numero de Possveis
Pontos (N P P ) que devem existir. Assim, dentro da regiao de atuacao de cada atuador havera
N P P posicoes angulares equidistantes entre si.
Cada ponto da funcao de um mesmo atuador
pode admitir qualquer elemento desse conjunto de
valores, sendo atribudo a cada um deles uma probabilidade de sucesso. Essa informacao e entao
organizada na forma de uma matriz de tres dimensoes como se segue

Figura 7 Organizacao da matriz que armazena
o conhecimento adquirido pelo aprendizado por
reforco.
Inicialmente, como ainda nao foi adquirido
nenhum conhecimento a respeito dos pontos que
irao compor cada funcao, todas as probabilidades PP P xExA assumem o mesmo valor que corresponde a PP P xExA  1N P P .
Baseado nessas probabilidades, a cada iteracao de aprendizado, o algoritmo escolhe quais os
proximos parametros a serem testados levando em
consideracao as probabilidades de sucesso, ou seja,
um parametro que tenha uma probabilidade de sucesso de 25, tem 25 de chance de fazer parte
da funcao a ser testada na proxima iteracao.
Ja o ajuste das referidas probabilidades e baseado no valor obtido de J que, para a aplicacao
em questao, varia entre 1 e 1. Esses dois extremos correspondem a penalidade maxima (P ) e
a gratificacao maxima (G ), ambos definidos pelo
projetista. Assim, o reforco  e obtido atraves da
Equacao (4).


Linhas  Cada linha representa um possvel parametro utilizado como ponto para as funcoes

J

G  P
2


+

G + P
2

(4)

Assim, a probabilidade (PK ) de cada valor
utilizado como ponto em cada uma das funcoes e
calculada atraves da Equacao (5), onde fp e dado
pela Equacao (6) e PK1 e a probabilidade previa
do mesmo valor utilizado.

Colunas  Cada coluna representa um ponto
que compoe a funcao que descreve o comportamento de cada atuador
Profundidade  Cada profundidade representa
um dos atuadores que compoem uma perna.



se fp > 0
se fp  0

(5)


 
fp  PK1 1 +
100

(6)

PK 

Com essa representacao, a probabilidade que
esta contida em cada celula da matriz (PP P xExA )
representa a chance de sucesso quando o parametro P P compoe o ponto E da funcao para o atuador A. Dessa forma, a soma das probabilidades em
uma mesma coluna sempre deve resultar no valor
1, uma vez que ha 100 de chance do angulo a ser
utilizado como ponto da funcao em questao esta
representado por uma das linhas existentes. Por
outro lado, nao ha uma relacao de dependencia direta entre as probabilidades em diferentes colunas
ou diferentes profundidades.
A Figura 7 ilustra a organizacao da referida
matriz.

fp
0

Depois de ajustar as probabilidades dos parametros testados, todas as probabilidades de cada
coluna sao normalizadas fazendo que a sua soma
resulte em 1.
Por fim, a etapa de treinamento e encerrada
apos realizar a quantidade maxima de iteracoes
informada pelo projetista ou quando e constatada
a convergencia do aprendizado. Essa convergencia
e identificada quando todas as colunas das matrizes possuem um elemento com uma probabilidade

5032

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

superior a 95, ou quando a funcao J retorna apenas valores entre 0, 02 e 0, 02 nos ultimos 2 das
iteracoes realizadas.
2.4

Funcao objetivo

3

Como explicitado anteriormente, a funcao objetivo J mensura a qualidade do resultado obtido
com a execucao do caminhar do robo. Para o trabalho em questao, almeja-se que J favoreca um
movimento rapido e estavel. Para tal, a composicao de J levou em consideracao as seguintes caractersticas desejadas

2. J deve decair com o aumento da taxa de instabilidade observada ao longo da execucao do
passo
3. J deve favorecer uma evolucao do desempenho obtido, ou seja, o valor de J sera positivo
se o desempenho observado na iteracao atual
for superior a uma determinada media obtida
pelo historico de iteracoes realizadas

Alem disso, os processos de aprendizado, utilizaram os coeficientes apresentados na Tabela 2.
Tabela 2 Valores utilizados em todos os processos
de aprendizado.
T
N P P N E N c G
P
3, 75s
20
4
20 30 30

2. V corresponde ao vetor coluna que contem as
medias das velocidades angulares nos eixos x,
y, e z, respectivamente

Neste contexto, a Figura 8 ilustra o progresso
do aprendizado ao longo de um dos treinamento
atraves de cinco graficos, onde

3. N e o numero de amostras coletadas.

G

j1 (Vi,j

 V )2 )

N


Vx,1
V   Vy,1
Vz,1

Vx,2
Vy,2
Vz,2


... Vx,N
... Vy,N 
... Vz,N

Resultados obtidos

3. As pernas traseiras estao com uma defasagem
de 180o entre si.

1. A matriz Vi,j (Equacao 8) contem as velocidades nos eixos x, y, e z no instante de amostragem j

PN

(10)

2. A perna traseira do lado esquerdo (perna 2)
esta em fase com a dianteira do lado direito
(perna 3)

Para compor a funcao com todas as caractersticas almejadas, primeiramente e necessario
mensurar a taxa de instabilidade (G) do robo ao
executar um passo. G pode ser quantificada atraves da Equacao 7 (Golubovic and Hu, 2003), onde

i1 (

1

1. A perna traseira do lado direito (perna 1)
esta em fase com a dianteira do lado esquerdo
(perna 4)

4. J deve gerar resultados dentro do intervalo
de 1 a 1.

P3

1

Para avaliar o desempenho da estrategia adotada
neste trabalho, foram realizados 30 processos de
aprendizado, obtendo assim 30 conjuntos de funcoes a serem aplicadas nos atuadores do robo.
Durante os processos de aprendizado foi utilizado um vetor de defasagens  fixado em 0 2 2 0,
ou seja, quando f 1 (t), f 2 (t) e f 3 (t) das pernas 1 e
4 estao nos pontos f 1 (0), f 2 (0) e f 3 (0), as funcoes
das pernas 2 e 3 estao nos pontos f 1 (2), f 2 (2) e
f 3 (2). Dessa forma o robo desempenha um tipo
de caminhar conhecido como Trotting (Quadruped
Locomotion - Musings About Running Dogs and
Other 4-Legged Creatures, 2006), onde

1. J deve crescer com o aumento da distancia
percorrida em um passo do robo

s

D
M edia(kDk,N c)
G
+ M edia(G,N
c)

1+
fJ 

1. O historico da distancia percorrida esta representado no primeiro grafico

(7)

2. O historico dos valores de G esta no segundo
(8)

3. O terceiro grafico apresenta os valores de J
ao longo do aprendizado

Assim, a funcao escolhida para mensurar
a qualidade da resposta obtida e representada
pela Equacao 9, onde fJ e dada pela Equacao 10, D e a distancia percorrida pelo robo e
M edia(Dados, N c) e a media dos Dados nas ultimas N c iteracoes.

1 se fJ  1



fJ se 1 > f > 1
J
(9)
1 se fJ  1



1 se o robo cair.

4. A representacao do grau de convergencia e
apresentada no quarto grafico atraves da media das maximas probabilidades de cada coluna
5. A evolucao da porcentagem de quedas a cada
50 iteracoes e apresentada no quinto grafico.
Atraves desses graficos observa-se que, neste
processo de aprendizado, o progresso da convergencia (grafico 3) se da de forma lenta ate em

5033

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

instabilidade G e a distancia D estao intimamente
ligadas uma vez que, na maioria dos casos, um
deslocamento D acima da media originava um G
tambem acima da media, ou seja, quanto maior a
velocidade do robo, maior a sua taxa de instabilidade.
Dentre os conjuntos de funcoes obtidos, foi selecionado um dos que apresentou melhor resultado
simulado. Essas funcoes foram entao aplicadas no
robo real para verificar o seu desempenho. Assim,
obteve-se o comportamento ilustrado na figura 9.

Figura 8 Progresso de um dos aprendizados.
torno da iteracao de numero 500. Ate esse momento a distancia percorrida em um passo (grafico
1) e a instabilidade G (grafico 2) apresentam valores aparentemente randomicos, enquanto que o valor de J (grafico 4) apresenta uma grande variacao
ocorrendo mais valores negativos do que positivos,
em outras palavras, ocorrendo mais desempenhos
ruins do que bons. Ja a porcentagem de quedas a cada 50 iteracoes (grafico 5) fica um pouco
a baixo dos 50.
Apos a 500a iteracao a velocidade de convergencia do aprendizado se acentua, ha um aumento
gradativo da media da distancia percorrida por
um passo, ha uma diminuicao da media das taxas
de instabilidade G e a porcentagem de quedas comeca a cair gradativamente. Esse comportamento
ilustra que o robo esta aprendendo a se locomover
com os aspectos almejados grande deslocamento
e baixa taxa de instabilidade.
A verificacao do aprendizado no grafico do historico de J tambem e perceptvel uma vez que
observa-se um maior numero de de reforcos positivos seguido por uma diminuicao da sua amplitude,
comprovando a convergencia do aprendizado.
Em todos os treinamentos realizados
verificou-se que o robo aprendeu a se locomover dentro das caractersticas estipuladas. A
Tabela 3 representa os resultados obtidos com as
simulacoes atraves dos valores mnimos (Min),
das medias (Med), dos valores maximos (Max)
e os desvios padrao (DP) da instabilidade G, da
distancia percorrida em um passo D, e do numero
de iteracoes necessarios para a convergencia.

Figura 9 Comportamento verificado no quadrupede real com as funcoes obtidas no aprendizado.
O conjunto de funcoes selecionado apresentou, no ambiente simulado, um deslocamento de
30, 04cm com uma taxa de instabilidade G de 0, 49
ao realizar um passo. No robo real, apos realizar 10 passos, verificou-se um deslocamento medio
de 35, 79cm, enquanto que a taxa de instabilidade
nao pode ser mensurada devido a ausencia de sensores que fornecessem as informacoes necessarias
para esse calculo. Dessa forma, observou-se uma
boa coerencia entre o comportamento do robo real
e do simulado.

Tabela 3 Resultados estatsticos obtidos.
G
D
Numero de
cm
Iteracoes
Min 0, 15 10, 61
677
Med 0, 42 21, 38
1187
Max 0, 86 35, 17
4200
DP 0, 17 7, 20
651

4

Conclusoes e trabalhos futuros

Este artigo teve como objetivo apresentar uma
metodologia de aprendizado capaz de viabilizar a
locomocao de um robo com pernas de uma forma

Em linhas gerais, verificou-se que a taxa de

5034

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

estavel levando em consideracao as simetrias presentes para facilitar, e consequentemente agilizar,
o aprendizado atraves de um controle distribudo
do robo.
A utilizacao dessa estrategia permite que o
bloco gerador de funcoes seja facilmente adaptado
a diferentes numeros de pernas com um pequeno
custo na complexidade, tendo como restricao a
igualdade entre as caractersticas das pernas.
Os testes realizados comprovaram que a metodologia e a tecnica de aprendizado_por_reforco
utilizada (Bootstrap Learning) se mostraram eficientes ao desempenhar os seus papeis.
Para a estrategia aqui apresentada existe uma
relacao entre a complexidade das funcoes a serem
aplicadas nos atuadores e a velocidade de convergencia do aprendizado. Essa relacao deve ser equilibrada pelo projetista de acordo com as suas necessidades. Para tal, o projetista deve ajustar o
numero de pontos (N E) que caracterizam as funcoes aplicadas nos atuadores e o numero de possveis posicoes angulares (N P P ).
Por fim, dentre os trabalhos futuros que deverao ser realizados, pode-se destacar

Gonthier, Y., Lange, C., McPhee, J. and Piedboeuf, J.-C. (2004). Simulation of contact in
multibody synamics using simulink, 8th ESA
Workshop on Advanced Space Tecnologies for
Robotics and Automation - ASTRA 2004 ESTEC - Noordwijk, Nederlands, 2 a 4 de
Novembro de 2004.
Ijspeert, A. J. (2008). Central patter generator for
locomotion control inanimals and robots A
review, Neural Networks 21 442653.
Juhasz, K. and Rusin, S. (2007). Contact processing in the simulation of clawar, 10th International Conference (CLAWAR 2007) - Singapore - 16 - 18 de Julho de 2007, Cambrage,
Massachusetts.
Law, A. M. and Kelton, D. M. (1999). Simulation
Modeling and Analysis, McGraw-Hill Higher
Education.
Lunzman,
S.,
Caterpillar,
Kennedy,
D.
and Miller, S. (2008).
Phisical modeling of mechanical friction in simulink, Technical report, MATLAB Digest,
httpwww.mathworks.commatlabcentral
fileexchange19756
Visualizado
em
11032010.

1. A insercao de novos sensores no robo real
2. Permitir que o algoritmo de aprendizado determine o vetor de defasagem entre as pernas
()

Marhefla, D. W. and Orin, D. E. (1996). Simulation of contact using a nonlinear damping model, 1996 IEEE International Conference on Robotics and Automation Minneapolis, Minnesota.

3. A inclusao do robo fsico no loop de aprendizado
4. Realizar testes com outras funcoes objetivo
com o intuito de fazer uma analise comparativa dos seus desempenhos

Nascimento Jr., C. L. and Yoneyama, T. (2000).
Inteligencia Artificial em Controle e Automacao, Editora Edgard Blucher LTDA, Sao
Paulo.

5. Realizar uma avaliacao da influencia da variacao dos valores de N E e N P P no desempenho das funcoes obtidas com o aprendizado e
da velocidade de convergencia

Pfeifer, R. and Scheier, C. (1999). Understanding
Intelligence, MIT Press.
Quadruped Locomotion - Musings About Running
Dogs and Other 4-Legged Creatures (2006).
httpwww.oricomtech.comprojectslegs.htm.

6. Viabilizar que o algoritmo determine o tempo
de execucao de um passo de tal forma a nao
limitar a velocidade maxima na qual o robo
pode se locomover.
5

Sutton, R. S. and Barto, A. G. (1998). Reinforcement Learning - An Introduction, MIT Press,
Cambrage, Massachusetts,.

Agradecimentos

Widrow, B., Gupta, N. K. and Maitra, S. (1973).
Punishreward Learning with a critic in
adaptive threshold systems, IEEE Transactions on Systems, Man, and Cybernetics, Vol.
SMC-3 n. 5.

Este trabalho teve o apoio financeiro da CAPES
(projeto Pro-Engenharias PE-041-2007) e da FAPESP (Processo n. 200606005-0)
Referencias
Golubovic, D. and Hu, H. (2003). Ga-based gait
generation of sony quadruped robots, 3th
IASTED International Conference on Artificial Intelligence and Applications - Marina
del Rey, de 3 a 5 de Novembro de 2003.

5035