ON THE EVALUATION OF DIFFERENT METRICS FOR NON-TECHNICAL
LOSSES ESTIMATION THROUGH OPTIMUM-PATH FOREST
Caio C. O. Ramos, Andre N. Souza, Joao P. Papa


Av. Prof. Luciano Gualberto, Travessa 3, N 158, CEP 05508-900
Departamento de Engenharia de Energia e Automacao Eletrica-PEAEPUSP
Sao Paulo, Brasil

Av. Luiz E. C. Coube, SN, CEP 17033-360
Laboratorio de Sistemas de Potencia e Tecnicas Inteligentes-LSISPOTIDEEFEBUNESP
Bauru, Sao Paulo, Brasil


Av. Luiz E. C. Coube, SN, CEP 17033-360
Laboratorio de Computacao de Alto Desempenho-LCADDCoFCUNESP
Bauru, Sao Paulo, Brasil
Emails caioramos@gmail.com, andrejau@feb.unesp.br, papa@fc.unesp.br
Abstract Recently, the Optimum-Path Forest was successfully applied for non-technical losses estimation,
outperforming the results obtained by some state of the art classifiers, such as Support Vector Machines and
Artificial Neural Networks using Multilayer Perceptron. In this paper, we present new results using different
metrics to evaluate the connectivity power between samples in the feature space by OPF, which outperformed
the aforementioned results obtained.
Keywords

Non-Technical Losses, Pattern Recognition, Optimum-Path Forest.

Resumo Recentemente, o algoritmo Floresta de Caminhos Otimos foi aplicado com sucesso para a estimacao de perdas nao tecnicas, superando resultados obtidos por classificadores tradicionais, tais como Maquinas
de Vetores de Suporte, Redes Neurais Artificiais e utilizando Perceptron Multicamadas. Neste paper, apresentamos novos resultados utilizando diferentes metricas para avaliacao da forca de conectividade entre amostras no
espaco de caractersticas pelo classificador Floresta de Caminhos Otimos que melhoraram os resultados acima
mencionados.
Palavras-chave

.

also are defined as the difference between the total losses and the technical losses, been strongly
related to illegal connections in the distribution
system (de Oliveira et al., 2008).
Theft and problems with power meters, with
the purpose to modify the registration of electric power, are the main causes of commercial
losses in national and international electric power
companies, evidencing the energy frauds (Alves
et al., 2006). However, it is a hard task to calculate or measure the amount of the commercial
losses, because in most part of the cases it is almost impossible to know where they occur (Nizar
and Dong, 2009).
Although the advances in this area can be
evidenced in recent years, especially with several
techniques of electric energy measurement, it becomes more necessary to find alternative methods with flexibility and easy adaptation to the
context of the problem, as the models of the
computational techniques with intelligent algorithms. Nagi et al. (Nagi, Mohammad, Yap,
Tiong and Ahmed, 2008) used Support Vector
Machines - SVM (Boser et al., 1992) for detection of electricity theft, and Nizar et al. (Nizar
et al., 2007) applied data mining-based techniques for non-technical loss analysis. Monedero
et al. (Monederon et al., 2006) proposed to use

Introduction

A competitive environment in the national scene
has been introduced with the privatization of electric power companies. The investments made by
companies have as main objective a significant improvement of their financial and technical performance, seeking higher productivity, efficiency and
profitability. In order to get better management
with respect to the energy losses, one of the ways
to maximize the available energy for commercialization in the electric power companies is sto reduce the theft or fraud of energy (Davidson, 2002).
The losses of electric power are constituted
by the difference between the generatedbought
energy and the billed ones, and can be divided
into two distinct types (i) technical and (ii) nontechnical losses. The former are related with problems in the system through the physical characteristics of the equipment, that is, the technical losses
are the energy lost in the transport, the transformation and the equipment of measurement, becoming a very high cost to the electric power companies (Nizar et al., 2008). The commercial losses
or non-technical losses are those associated with
the commercialization of the supplied energy to
the user and refer to the delivered and not billed
energy, propitiating a loss in the profits. They

108

Artificial Neural Networks - ANN (Haykin, 1994)
together with statistical analysis for fraud detection in electrical consumption. A hybrid approach
between Genetic Algorithms - GA (Koza, 1992)
and SVM was also applied for non-technical losses
detection (Nagi, Yap, Tiong, Ahmed and Mohammad, 2008).
Despite the use of these artificial intelligence
techniques have been increasing, some flaws need
to be revisited. An ANN with multi-layer_perceptrons (ANN-MLP), for example, can address
linearly and non-linearly separable problems, but
not non-separable situations with maximum effectiveness (Haykin, 1994). As an unstable classifier, collections of ANN-MLP (Kuncheva, 2004)
can improve its performance up to some unknown
limit of classifiers (Reyzin and Schapire, 2006).
Support vector machines have been proposed to
overcome the problem, by assuming linearly separable classes in a higher-dimensional feature
space (Boser et al., 1992). Its computational cost
rapidly increases with the training set size and the
number of support vectors. As a binary classifier,
multiple SVMs are required to solve a multi-class
problem. Panda et al. (Panda et al., 2006) presented a method to reduce the training set size
before computing the SVM algorithm. Their approach aims to identify and remove samples likely
related to non-support vectors. However, in all
SVM approaches, the assumption of separability
may also not be valid in any space of finite dimension.
Recently, a novel framework for graph-based
classifiers that reduce the pattern recognition
problem as an optimum path forest computation
(OPF) in the feature space induced by a graph
were presented (Papa et al., 2009). These kind of
classifiers do not interpret the classification task
as a hyperplanes optimization problem, but as
a combinatorial optimum-path computation from
some key samples (prototypes) to the remaining nodes. Each prototype becomes a root from
its optimum-path tree and each node is classified according to its strongly connected prototype,
that defines a discrete optimal partition (influence region) of the feature space. The OPF-based
classifiers have some advantages with respect to
the aforementioned classifiers (i) one of them is
free of parameters, (ii) they do not assume any
shapeseparability of the feature space and (iii)
run training phase faster, which allows the development of real time applications for fraud detection in electricity systems.
The non technical losses automatic identification by means of OPF classifier was first addressed
by Ramos et al. (Ramos et al., 2009), which presented a new fast and accurate approach to detect
commercial losses considering information from
databases of a brazilian energy company. The results of OPF outperformed SVM and ANN-MLP

in that case.
As each consumers profile can be seen as a
sample in the feature space, different metrics can
be applied to measure how much two samples
are connected to each other, i.e., the connectivity power. This fact lead us to work in the metric
space, which associates for each dataset, a specific
metric function. The OPF classifier uses the Euclidean distance as default metric to measure the
similarity between two samples. However, we can
also apply many other distance functions that can
best fit our problem because the OPF frameworks
can handle several metrics, instead of an artificial neural network using multilayer perceptron,
for instance, which uses the Euclidean distance
for computing the distance between samples of the
feature space, and may not handle other metrics.
In this paper, we introduce the OPF algorithm with different metrics for non-technical
losses detection, and this version contains improvements regarding the one presented by Ramos
et al. (Ramos et al., 2009). The remainder of this
paper is organized as follows. Section 2 describes
the theory of Optimum-Path Forest and Section 3
presents the dataset and recognition features used.
Finally, experimental results and conclusions are
stated in Sections 4 and 5, respectively.
2

Optimum-path forest classifier

Let Z1 and Z2 be the training and and test sets
with Z1  and Z2  samples such as points or image elements (e.g., feature vectors, pixels, voxels, shapes and texture information). Let (s) be
the function that assigns the correct label i, i 
1, 2, . . . , c, from class i to any sample s  Z1  Z2 .
Z1 is a labeled set used to the design of the classifier and Z2 is used to assess the performance of
classifier and it is kept unseen during the project.
Let S  Z1 be a set of prototypes of all classes
(i.e., key samples that best represent the classes).
Let v be an algorithm which extracts n attributes
(color, shape or texture properties) from any sample s  Z1  Z2 and returns a vector v (s)  n .
The distance d(s, t) between two samples, s and
t, is the one between their feature vectors v (s)
and v (t). One can use any valid metric (e.g., Euclidean) or a more elaborated distance algorithm.
Our problem consists of using S, (v, d) and Z1 to
project an optimal classifier which can predict the
correct label (s) of any sample s  Z2 . The OPF
classifier creates a discrete optimal partition of the
feature space such that any sample s  Z2 can be
classified according to this partition. This partition is an optimum path forest (OPF) computed
in n by the image foresting transform (IFT) algorithm (Falcao et al., 2004).
Let (Z1 , A) be a complete graph whose the
nodes are the samples in Z1 and any pair of samples defines an arc in A  Z1  Z1 (Fig. 1a) . The

109

arcs do not need to be stored and so the graph does
not need to be explicitly represented. A path is a
sequence of distinct samples   hs1 , s2 , . . . , sk i,
where (si , si+1 )  A for 1  i  k  1. A path is
said trivial if   hs1 i. We assign to each path  a
cost f () given by a path-cost function f . A path
 is said optimum if f ()  f (  ) for any other
path   , where  and   end at a same sample sk .
We also denote by   hs, ti the concatenation of a
path  with terminus at s and an arc (s, t).

The OPF algorithm assigns one optimum
path P  (s) from S to every sample s  Z1 , forming an optimum path forest P (a function with no
cycles which assigns to each s  Z1 S its predecessor P (s) in P  (s) or a marker nil when s  S.
Let R(s)  S be the root of P  (s) which can be
reached from P (s). The OPF algorithm computes
for each s  Z1 , the cost C(s) of P  (s), the label
L(s)  (R(s)), and the predecessor P (s), as follows.
Algorithm 1  OPF Algorithm

0.8

0.7

Input

0.6

0.2

(0.0,2)

0.3

0.5

(0.0,1)

0.8
0.1
0.7

Output

(0.2,2)

Auxiliary

(0.5,1)
(0.2,2)

0.8

(a)

(b)

(0.0,2)
(0.0,1)
(0.0,2)
(0.2,2)

0.6

0.7

(0.0,1)

(0.5,1)
(0.2,2)

0.3

0.4

(0.2,2)
(0.5,1)

(?,?)

(0.2,2)
(0.4,2)

0.5

(c)

(d)

Figure 1 (a) Complete weighted graph for a simple training set. (b) Resulting optimum-path forest for fmax and two given prototypes (circled
nodes). The entries (x, y) over the nodes are,
respectively, the cost and the label of the samples. The directed arcs indicate the predecessor
nodes in the optimum path. (c) Test sample (gray
square) and its connections (dashed lines) with
the training nodes. (d) The optimum path from
the most strongly connected prototype, its label
2, and classification cost 0.4 are assigned to the
test sample.



1. For each s  Z1 S, set C(s)  +.
2. For each s  S, do
3.
C(s)  0, P (s)  nil, L(s)  (s).
Insert s in Q.
4.
5. While Q is not empty, do
6.
Remove from Q a sample s with lowest C(s).
7.
For each t  Z1 with t 6 s and C(t) > C(s),
8.
Compute cst  maxC(s), d(s, t).
9.
If cst < C(t), then
10.
If C(t) 6 +, then
11.
Remove t from Q.
12.
P (t)  s, L(t)  L(s),
C(t)  cst and insert t in Q.
13.

Lines 1  4 initialize maps and insert prototypes in Q. The main loop computes an optimum
path from S to every sample s in a non-decreasing
order of cost (Lines 5  13). At each iteration,
a path of minimum cost C(s) is obtained in P
when we remove its last node s from Q (Line 6).
Ties are broken in Q using first-in-first-out policy.
That is, when two optimum paths reach an ambiguous sample s with the same minimum cost, s
is assigned to the first path that reached it. Note
that C(t) > C(s) in Line 7 is false when t has
been removed from Q and, therefore, C(t) 6 +
in Line 10 is true only when t  Q. Lines 9  13
evaluate if the path that reaches an adjacent node
t through s is cheaper than the current path with
terminus t and update the position of t in Q, C(t),
L(t) and P (t) accordingly.

The OPF algorithm may be used with any
smooth path-cost function which can group samples with similar properties (Falcao et al., 2004).
We are interested in prototypes that fall in the
region between classes, which are generally overlapped regions. So, we will address the path-cost
function fmax , because of its theoretical properties
for estimating prototypes that have this behavior (Section 2.1 gives the details about this procedure)

0
if s  S,
fmax (hsi) 
+ otherwise
fmax (  hs, ti)

A -labeled training set Z1 , prototypes S  Z1 and the pair (v, d) for
feature vector and distance computations.
Optimum-path forest P , cost map C
and label map L.
Priority queue Q and cost variable cst.

2.1

Training

We say that S  is an optimum set of prototypes
when Algorithm 1 minimizes the classification errors for every s  Z1 . S  can be found by exploiting the theoretical relation between minimumspanning tree (MST) and optimum-path tree for
fmax (Papa et al., 2009). The training essentially
consists of finding S  and an OPF classifier rooted
at S  .

maxfmax (), d(s, t), (1)

such that fmax () computes the maximum distance between adjacent samples in , when  is
not a trivial path.

110

By computing an MST in the complete graph
(Z1 , A), we obtain a connected acyclic graph
whose nodes are all samples of Z1 and the arcs
are undirected and weighted by the distances d between adjacent samples. The spanning tree is optimum in the sense that the sum of its arc weights
is minimum as compared to any other spanning
tree in the complete graph. In the MST, every pair of samples is connected by a single path
which is optimum according to fmax . That is, the
minimum-spanning tree contains one optimumpath tree for any selected root node.
The optimum prototypes are the closest elements of the MST with different labels in Z1 (i.e.,
elements that fall in the frontier of the classes).
By removing the arcs between different classes,
their adjacent samples become prototypes in S 
and Algorithm 1 can compute an optimum-path
forest with minimum classification errors in Z1
(Figure 1b). Note that, a given class may be represented by multiple prototypes (i.e., optimum-path
trees) and there must exist at least one prototype
per class.
2.2

 Measured Demand or Maximum Demand
(Dmax ) the maximum demand for active
power, verified by measurement, at intervals
of fifteen minutes during the billing period, in
kilowatts (kW)
 Load Factor (LF ) the ratio between the average demand (Daverage ) and maximum demand (Dmax ) of the consumer unit, recorded
in the same time period, as follows
LF 

Daverage 
and T is given by
Z

T
,
T

(4)

T

D(t)dt,

(5)

0

For any sample t  Z2 , we consider all arcs connecting t with samples s  Z1 , as though t were
part of the training graph (Figure 1c). Considering all possible paths from S  to t, we find the
optimum path P  (t) from S  and label t with the
class (R(t)) of its most strongly connected prototype R(t)  S  . This path can be identified incrementally, by evaluating the optimum cost C(t)
as

in which D(t) is the demand curve.
 Installed Power (Pinst ) the sum of the nominal power of electrical equipments installed
and ready to operate at the consumer unit,
in kilowatts (kW).
4

Experimental Results

We performed two series of experiments in the
former (Section 4.1) we used 50 of the whole
dataset for training and the remaining 50 for
testing classifiers, and in the last one (Section 4.2)
we executed the experiments using the same aforementioned training and test sets configuration,
but now with different metrics to evaluate them
in the OPF. For the first round of experiments,
we executed OPF, SVM-RBF (SVM with RBF as
kernel function), SVM-LINEAR (SVM with a linear kernel function) and ANN-MLP (ANN-MLP
trained by backpropagation algorithm) 10 times
with randomly generated training and test sets, to
compute the mean accuracy and its standard deviation, and the mean training and test execution
times (in seconds). Regarding the second round
of experiments, we also executed the OPF algorithm 10 times with randomly generated training
and test sets for each metric function.
For SVM-RBF, we used the latest version of
the LibSVM package (Chang and Lin, 2001) with
Radial Basis Function (RBF) kernel, parameter
optimization and the one-versus-one strategy for
the multi-class problem. With respect to SVMLINEAR, we used the LibLINEAR package (Fan
et al., 2008) with C parameter optimized by cross

(2)

Let the node s  Z1 be the one that satisfies
Equation 2 (i.e., the predecessor P (t) in the optimum path P  (t)). Given that L(s )  (R(t)),
the classification simply assigns L(s ) as the class
of t. An error occurs when L(s ) 6 (t).
3

(3)

The LF is an index factor that shows how
the electric power is used in a rational way,
and Daverage is defined as the ratio between
the total energy (T ) and the period T , as
described by

Classification

C(t)  minmaxC(s), d(s, t), s  Z1 .

Daverage
.
Dmax

Material and Methods

In this section we will describe the dataset used
in the experiments, as well the features extracted
from each consumer profile.
For the development of this work, we used a
dataset obtained from a brazilian company of electric power composed by 736 profiles, divided into
116 illegal and 620 legal consumers. This dataset
was previously labeled by technicians of the aforementioned company. Each consumer profile is represented by four features, as follows
 Contracted Demand the value of demand to
be continuously available by the energy company and shall be paid likewise whether the
electric power is used or not by the consumer,
in kilowatts (kW)

111

validation manifold. For OPF we used the LibOPF (Papa et al., 2008), which is a library for the
design of optimum-path forest-based classifiers,
and for ANN-MLP we used the Fast Artificial
Neural Network Library (FANN) (Nissen, 2003).
We applied two different architectures for ANNMLP the first network configuration is ih1 h2 o,
where i  n (number of features), h1  h2  8
and o  c (number of classes) are the number of
neurons in the input, hidden and output layers,
respectively, and the second configuration is iho,
in which i and o have the same value of the first
neural architecture and h  8. We distinguish
the neural architectures by using ANN-MLP1 for
the first one and ANN-MLP2 for the latter architecture, i.e., the one that uses only one hidden layer. Recall that both neural networks were
trained with a backpropagation algorithm, and its
architecture was empirically chosen.
4.1

different metrics for OPF algorithm. Table 2 displays the mean accuracies over the test set after
10 rounds of experiments using 50 for training
and 50 for testing.
Table 2 Mean accuracy using different metrics for
OPF classifier.

We evaluate here the OPF, SVM-RBF, SVMLINEAR, ANN-MLP1 and ANN-MLP2 for nontechnical losses detection using 50 for training
and 50 for testing. Table 1 shows the mean accuracies and mean training and classification times
(in seconds) after 10 runnings with randomly generated training and test sets.
Table 1 Mean accuracy (Acc) and mean training (Tr) and classification (Class) times in seconds dor OPF, SVM-RBF, SVM-LINEAR, ANNMLP1 and ANN-MLP2 .
Acc

Tr time

Class Time

OPF

90.212.93

0.0257

0.0223

SVM-RBF

88.933.07

13.4817

0.0222

SVM-LINEAR

45.406.31

2.4514

0.0048

ANN-MLP1

53.016.95

1708.85

0.0078

ANN-MLP2

51.382.79

112.30

0.0006

Manhattan

91.092.19

Canberra

89.841.94

Bray Curtis

89.243.00

Squared Chord

91.022.43

Squared Chi-Squared

90.941.74

5

Conclusions

We have presented here a fast graph-based approach for automatic non-technical losses recognition with different metric for OPF algorithm that
improved the results recently addressed by Ramos
et al. (Ramos et al., 2009). The irregular measurement detection caused by frauds in power electrical systems is a important topic researched in the
international scene, and we are the first to introduce the OPF classifier in this context.
Experiments using OPF, SVM-RBF, SVMLINEAR and two neural networks with different
architectures in a dataset with 50 for training
and 50 for testing demonstrated that OPF and
SVM-RBF are similar and outperformed the remaining ones, but OPF training phase is much
faster, making it able for real time trainingdepending systems, in which new consumers profiles can be added at moment and a fast system
re-training will be necessary.
The experiments using OPF were repeated
with different metrics and presented that Manhattan Metric has mean accuracy better than others.
This lead us to study another metrics aiming to
try to outperform the results already obtained by
our research group.

We can see that OPF and SVM-RBF can produce similar results and also outperformed SVMLINEAR, ANN-MLP1 and ANN-MLP2 . Even
though, OPF was 524.57 times faster than SVMRBF in the training phase. This point can
make OPF able for real-time training depending
systems, in which samples from knownunseen
classes can be added to training set and re-training
is needed. Similarly, one can have a real time detection system for non-technical losses in which
new consumers profiles can be added and the system need to be re-trained (reseted) as fast as possible, with minimum costs.
4.2

Accuracy
90.212.93

We can see that OPF algorithm with Manhattan and Squared Chord metrics presented similar performances, increasing their mean accuracy
with respect to the Euclidean Metric, which made
OPF the most accurate classifier in Section 4.1.
This results may lead us to show that a feature
vector (consumer profile) needs to be used with
it own metric function, i.e., we can increase the
accuracy of a given classifier by just changing the
metric.
Although the user may argue that if we take
into account the standard deviation of the experiments with different metrics, the results will be
similar, the main idea here is to sheds light the
importance of trying other distance functions, instead of just using the standard ones.

Classifiers evaluation

Classifier

Metric
Euclidean

OPF Algorithm with different metrics

We evaluate here the mean accuracy with respect
to variations on the OPF algorithm. We repeated
the experiments shown in previous section with

112

Nagi, J., Mohammad, A., Yap, K., Tiong, S. and
Ahmed, S. (2008). Non-technical loss analysis for detection of electricity theft using support_vector_machines, Proceedings of the 2nd
IEEE International Power and Energy Conference, pp. 907912.

References
Alves, R., Casanova, P., Quirogas, E., Ravelo, O.
and Gimenez, W. (2006). Reduction of nontechnical losses by modernization and updating of measurement systems, Proceedings of
the IEEEPES Transmission and Distribution Conference and Exposition Latin America, pp. 15.

Nagi, J., Yap, K., Tiong, S., Ahmed, S. and Mohammad, A. (2008). Detection of abnormalities and electricity theft using genetic support_vector_machines, IEEE TENCON Region 10 Conference, pp. 16.

Boser, B., Guyon, I. and Vapnik, V. (1992). A
training algorithm for optimal margin classifiers, Proceedings of the 5th Workshop on
Computational Learning Theory, ACM Press,
New York, NY, USA, pp. 144152.

Nissen, S. (2003). Implementation of a Fast Artificial Neural Network Library (FANN). Department of Computer Science University of
Copenhagen (DIKU). Software available at
httpleenissen.dkfann.

Chang, C. C. and Lin, C. J. (2001). LIBSVM A Library for Support Vector
Machines.
Software available at url
httpwww.csie.ntu.edu.tw cjlinlibsvm.

Nizar, A. and Dong, Z. (2009). Identification and
detection of electricity customer behaviour
irregularities, Proceedings of the IEEEPES
Power Systems Conference and Exposition,
pp. 110.

Davidson, I. (2002). Evaluation and effective
management of nontechnical losses in electrical power networks, Proceedings of the 6th
IEEE Africon Conference in Africa, Vol. 1,
pp. 473477.

Nizar, A., Dong, Z. and Wang, Y. (2008).
Power utility nontechnical loss analysis with
extreme learning machine method, IEEE
Transactions on Power Systems 23 946955.

de Oliveira, M., Boson, D. and Padilha-Feltrin, A.
(2008). A statistical analysis of loss factor to
determine the energy losses, Proceedings of
the IEEEPES Transmission and Distribution Conference and Exposition Latin America, pp. 16.

Nizar, A., Dong, Z., Zhao, J. and Zhang, P.
(2007). A data mining based ntl analysis
method, Proceedings of the IEEE Power Engineering Society General Meeting, pp. 18.

Falcao, A., Stolfi, J. and Lotufo, R. (2004).
The image foresting transform theory, algorithms, and applications, IEEE Transactions on Pattern Analysis and Machine Intelligence 26(1) 1929.

Panda, N., Chang, E. and Wu, G. (2006). Concept
boundary detection for speeding up svms,
Proceedings of the 23th International Conference on Machine learning, ACM Press, New
York, NY, USA, pp. 681688.

Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang,
X.-R. and Lin, C.-J. (2008). LIBLINEAR A
library for large linear classification, Journal
of Machine Learning Research 9 18711874.

Papa, J., Falcao, A. and Suzuki, C. (2009).
Supervised pattern classification based on
optimum-path forest, International Journal of Imaging Systems and Technology
19(2) 120131.

Haykin, S. (1994). Neural networks a comprehensive foundation, Prentice Hall.

Papa, J., Suzuki, C. and Falcao, A. X. (2008). LibOPF A library for the design of optimumpath forest classifiers.
Software version
1.0 available at httpwww.ic.unicamp.
brafalcaoLibOPF.

Koza, J. (1992). Genetic programming on the
programming of computers by means of natural selection, The MIT Press, Cambridge,
MA.
Kuncheva, L. I. (2004).
Combining Pattern
Classifiers Methods and Algorithms, WileyInterscience.

Ramos, C., Souza, A., Papa, J. and Falcao
(2009). Fast non-technical losses identification through optimum-path forest, Proceedings of The 15th International Conference
on Intelligent System Applications to Power
Systems, pp. 15.

Monederon, I., Biscarri, F., Leon, C., Biscarri, J.
and Millan, R. (2006). Midas Detection of
non-technical losses in electrical consumption
using neural networks and statistical techniques, Proceedings of the International Conference on Computational Science and Applications, Vol. 3984, Lecture Notes in Computer Science, Springer BerlinHeidelberg.

Reyzin, L. and Schapire, R. (2006). How boosting the margin can also boost classifier complexity, Proceedings of the 23th International Conference on Machine learning, ACM
Press, New York, NY, USA, pp. 753760.

113