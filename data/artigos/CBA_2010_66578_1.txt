XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

CONVERGENCIA E DESEMPENHO DE UM ALGORITMO DE
DESCONVOLUCAO CEGA
Diego Barreto Haddad



, Mariane Rembold Petraglia, Paulo Bulkool Batalheiro


Dept. Telecomunicacoes
CEFET-RJ UnEd Nova Iguacu
CEP 26041-271, Nova Iguacu, RJ, Brasil


Universidade Federal do Rio de Janeiro (UFRJ), PEECOPPE
Laboratorio de Processamento Analogico  Digital de Sinais (PADS)
Rio de Janeiro, RJ, Brasil

Universidade do Estado do Rio de Janeiro (UERJ)
Departamento de Engenharia Eletronica e Telecomunicacoes
Rio de Janeiro, RJ, Brasil

Emails diego@pads.ufrj.br, mariane@pads.ufrj.br, bulkool@pads.ufrj.br
Abstract Blind deconvolution algorithms have as great advantage the weakness of their hypothesis. They do
not need training sequences, which makes them useful in many contexts. Nevertheless, the non-linearity of their
update equations make their analysis very difficult. In this paper, we make analytical and numerical predictions
of convergence and performance of a blind deconvolution algorithm, which uses as optimization method a type
of natural gradient.
Keywords

Blind Deconvolution, Convergence Analysis, Intersymbol Interference.

Resumo Algoritmos de desconvolucao_cega tem como grande vantagem a fraqueza de suas hipoteses. A
falta de exigencia de acesso a trechos das fontes os tornam aplicaveis a um grande leque de situacoes. Porem a
nao-linearidade de suas equacoes de atualizacao torna sua analise extremamente difcil. Neste artigo, efetuamos
predicoes analticas e numericas da convergencia e desempenho de um algoritmo de desconvolucao_cega, que
emprega como metodo de otimizacao um tipo de gradiente natural.
Palavras-chave

.

tambem nao exigirem um conhecimento acerca da
funcao de transferencia do canal. A reducao da
complexidade de informacao costumeiramente e
obtida a custa do aumento do custo_computacional (C. C. Cavalcante, 2009).
Podemos efetuar interessantes relacoes entre
as tecnicas de separacao cega e desconvolucao_cega
de fontes, porem ha importantes distincoes entre
elas. Para a desconvolucao cumpre preservar a
estrutura temporal das fontes, o que nao e necessario nas tecnicas convolutivas de separacao de
fontes2 , devido a conhecida ambiguidade de filtragem. A restricao de o numero de fontes ser pelo
menos igual a 2 nas tecnicas de separacao de fontes
nao e necessaria para tecnicas de desconvolucao,
as quais podem atuar num contexto monocanal.
Embora amplamente utilizadas, analises de
convergencia, estabilidade e desempenho sao difceis de se obter devido a nao-linearidade das
equacoes de atualizacao, bem como a dificuldade
de desacoplamento das equacoes multidimensionais (Minker, 2007). Abordagens analticas de alguns destes algoritmos podem ser vistas em S.I. Amari (1998) ou X. Sun (2001) comparacoes
de desempenho via simulacoes e medias do tipo

Introducao

A ubiquidade do fenomeno dos multiplos percursos acaba por demandar ferramentas de processamento capazes de recuperar os sinais originais1 ,
numa operacao que chamamos de desconvolucao
ou equalizacao. Podemos, grosso modo, dividir as
tecnicas que almejam contornar este problema em
dois grandes grupos as que atuam no espaco de
identificacao da funcao de transferencia dispersiva
(modelo do canal) ou no espaco de inversao desta
funcao de transferencia. Esta ultima abordagem
sera a contemplada neste artigo ela procura encontrar filtros (em geral, do tipo FIR) que, atuando sobre o sinal recebido, desfacam ou atenuem
o efeito do canal.
Em alguns contextos, como em comunicacoes
digitais, e possvel inserir um trecho no sinal original que seja previamente conhecido. Este conhecimento previo possibilita a insercao de tecnicas de
filtragem_adaptativa supervisionada, que constituem um ramo maduro da area de processamento
de sinais (Haykin, 1996).
Quando nao ha (ou e indesejavel) um acesso a
trechos das fontes, cumpre recorrer a tecnicas de
processamento cego, as quais sao poderosas por
1 Na

2 Nas misturas instantaneas de separacao de fontes, a
estrutura temporal e preservada devido a ausencia de interferencia entre amostras de cada estimativa.

nossa terminologia, estes sinais sao denominados

fontes.

4335

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Monte Carlo sao efetuadas em P. Chevalier (2004)
e Y. Singh (2001).
Este artigo tem por objetivo analisar a convergencia, limites para o fator de aprendizagem e
o desempenho de uma versao monocanal de um
algoritmo de desconvolucao_cega, o qual emprega
o gradiente natural como tecnica de otimizacao da
funcao custo. Para efetuar as analises, recorremos
a modelos analticos aproximados e exatos, bem
como a simulacoes computacionais.
Em artigos anteriores (D. B. Haddad, 2009b),
(D. B. Haddad, 2009a), apresentamos as analises
exata e aproximada do algoritmo enfocado neste
artigo. Neste trabalho sao investigadas novas
caractersticas de convergencia, e proposta uma
abordagem hbrida e algumas relacoes entre as
pdfs (funcoes de densidade de probabilidade) real
e aproximada da fonte sao analisadas.
2

com esta possibilidade.
A estimativa p(s) pode divergir significativamente da pdf real p(s), sendo um parametro de
perturbacao (nuisance) (Cardoso, 1998) do algoritmo. Em geral, basta-nos saber se a fonte e supergaussiana ou subgaussiana3 . Se p(y) e a pdf
utilizada, a funcao score f (y) dela derivada e dada
por
 log p(y)
.
(4)
f (y)  
y
A funcao-custo do algoritmo DCGN e descrita
por
H
1
log W (z) z 1 dz
J (W (z))   2j
E log p(y(k)) ,

PL
onde W (z)  l0 wl (k)z l e o ndice k referese a k-esima iteracao (neste artigo, contemplamos
apenas configuracoes on-line do algoritmo). Esta
funcao custo pode ser alternativamente colocada
da forma a seguir (L. Zhang, 2004)

O algoritmo DCGN

O algoritmo DCGN (Desconvolucao Cega utilizando Gradiente Natural) foi proposto em
S. C. Douglas (2005). Sua versao monocanal e
o foco deste artigo. Seja s(k) a k-esima amostra
da fonte o sinal x(k), obtido no receptor apos o
efeito do filtro de canal h(k), pode ser descrito
como
x(k) 


X

h(l)s(k  l)  (h  s)(k),

J (w) 

0

rj (l) 

X

wp (j)wp+l (j), L  l  L,

(7)

p0

(1)


rk (0)
 rk (1)

R(k)   .
 ..
rk (L)

rk (1)
rk (0)
..
.
rk (L + 1)


x(k)  x(k) x(k  1) . . .
wl (k)x(k  l)  (w  x)(k)  (w  h  s)(k).

...
...
..
.
...


rk (L)
rk (L  1)

,
..

.
rk (0)
(8)


x(k  L) ,

(9)

podemos calcular um tipo de gradiente natural, o
que origina a equacao de atualizacao do algoritmo
DCGN


w(k + 1)  w(k) +  w(k)  f (y(k))zT (k) ,
(10)
onde  e o fator de aprendizagem, ()T indica
transposicao e z(k)  R(k)x(k).

l0

(2)

Para que consideremos a equalizacao bemsucedida, devemos obter, ao final da otimizacao
y(k)  ds(k  D),

(6)

Ll

onde  significa a operacao de convolucao.
Minimizar a funcao custo do algoritmo significa encontrar os coeficientes wl (k) do filtro equalizador de ordem L, o qual gera uma estimativa y(k)
da fonte
y(k) 

R 2

PL
jl
d
log
l0 wl e
E log p(y(k))
1
2

Definindo

l0

L
X

(5)

(3)

onde d e D respondem, respectivamente, pelo fator de escalamento e por um atraso arbitrario.
O algoritmo necessita de uma estimativa p(s)
da pdf da fonte, cujas amostras sao supostas
iid (independentes e identicamente distribudas).
Embora, num contexto de separacao de fontes,
C. Fevotte (2006) sugira que a hipotese de amostras iid nao inutiliza o algoritmo cego quando
a fonte apresenta dependencia estatstica entre
amostras (tratando-se apenas de uma opcao por
nao utilizar esta dependencia), em J. LeBlanc
(1994) conclui-se que esta dependencia pode alterar os mnimos da superfcie da funcao-custo.
De todo modo, neste artigo, as fontes a recuperar
sao realmente iid e nao precisamos nos preocupar

3

Analise do Algoritmo DCGN

Em D. B. Haddad (2009b), propusemos uma tecnica de analise aproximada do algoritmo DCGN,
a qual sera aqui sucintamente exposta.
Supondo L  1, as equacoes de iteracao podem ser escalarmente formuladas como
w0 (k + 1)w0 (k)+w0 (k)f (y(k))w02 (k)x(k)
f (y(k))w12 (k)x(k)
f (y(k))w0 (k)w1 (k)x(k  1)
(11)
3 Nao e possvel aplicar os algoritmos de desconvolucao
quando a fonte e gaussiana.

4336

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

w1 (k + 1)w1 (k)+w1 (k)f (y(k))w0 (k)w1 (k)x(k)
w02 (k)f (y(k))x(k  1)
w12 (k)f (y(k))x(k  1)
(12)

das Equacoes (13) e (14), sabendo7 que x(k  i) 
h0 s(k  i) + h1 s(k  i  1). Por exemplo, para
D  2, fontes iid e de media zero, encontramos

Apos a convergencia, podemos elidir o ndice
k de w0 (k) e w1 (k), bem como impor a condicao
wi (k + 1)  wi (k), o que nos leva a



E f (y(k))x(k)  (h0 c0 + h1 c1 )E f 0 (c2 s(k  2)) s2 ,
(17)

w0



w02 E f (y(k))x(k)

w12 E f (y(k))x(k)

+
+w0 w1 E f (y(k))x(k  1) ,

(13)
w1  w0 w1 E f (y(k))x(k) + w02 E f (y(k))x(k  1)
+w12 E f (y(k))x(k  1) ,
(14)

onde admitimos k   e E  e o operador de
media estatstica. O calculo do valor esperado
pode ser exato ou aproximado. Ainda que este
calculo seja exato, nao estaramos rigorosamente
empreendendo uma analise exata da convergencia
do algoritmo, dado que supomos implicitamente
a independencia entre wi e x(k  j). Se esta
hipotese revela-se razoavelmente acurada em algoritmos de filtragem_adaptativa supervisionada,
e ainda mais valida em contextos cegos, devido
a lenta convergencia do filtro equalizador. Isso
ajuda a explicar a grande coincidencia entre a
abordagem exatae as simulacoes.

3.1

onde s2 e a variancia da fonte. Portanto, conhecida
a funcao f e a pdf das fontes, os valores esperados
das Equacoes (13) e (14) podem ser aproximados.
Isso gera um sistema de equacoes nao-linear, cuja
solucao nos fornece uma estimativa dos valores
para os quais o algoritmo converge. Em algumas
situacoes, esta abordagem nos permite encontrar
formulas analticas para as estimativas de w0 e
w1 , as quais podem ilustrar que o algoritmo tende
a equalizar perfeitamente o canal quando f(s) e
oriunda da pdf da fonte (D. B. Haddad, 2009b).
3.2

Ainda que interessante, o potencial analtico da
analise aproximada e limitado, pois suas estimativas da ISI (interferencia_inter-simbolica) sao
razoaveis somente quando M e L sao reduzidos
(D. B. Haddad, 2009a).
Podemos evitar o uso da aproximacao (15)
e calcular os valores esperados analiticamente8 .
Em D. B. Haddad (2009a), a pdf das fontes
era exponencial e a funcao f (s) era a ideal, o
que gerava resultados analticos dependentes dos
sinais dos parametros hi e wi . As propriedades
desejaveis obtidas pela analise (e confirmadas por
simulacoes) poderiam motivar uma conjectura a
de que sao oriundas do fato de empregarmos uma
funcao f ideal. Porem, verificaremos neste artigo
que esta conjectura nao e verdadeira.

Analise Aproximada do Algoritmo DCGN

Seja c  h  w o filtro global que incorpora as
transformacoes efetuadas tanto pelo filtro do canal quanto pelo filtro de equalizacao. Supor que o
algoritmo seja bem-sucedido implica que a Equacao (3) e satisfeita4 e que podemos aproximar o
termo f (y(k)) por
MX
+L+1

f (y(k)) f (cD s(k D))+f 0 (cD s(k D))

Analise Exata do Algoritmo DCGN

ci s(k i)

i0,i6D

(15)

4

A aproximacao de primeira ordem acima
exige a determinacao a priori de D, cujo valor
depende nao somente do filtro de canal5 mas tambem da inicializacao do filtro. A despeito dessa deficiencia, a analise aproximada permite-nos esclarecer algumas propriedades do algoritmo DCGN,
como a equivariancia (J.-F. Cardoso, 1996) em
contextos simplificados e sem atraso final, como
por exemplo a convergencia de c0 para um valor
independente do canal6 
c0  

1
.
E f (c0 s(k))s(k)

Analise Hbrida Um estudo de caso

A abordagem aproximada, em alguns casos,
permite-nos encontrar solucoes analticas para alguns coeficientes wi , porem para outros as equacoes nao-lineares admitem infinitas solucoes. Estimar todos os parametros e essencial para a predicao do desempenho do algoritmo. Por isso propomos uma abordagem hbrida, a qual utiliza a
analise aproximada (que engendra um resultado
analtico) para encontrar um parametro e a exata
para encontrar o restante.
Para tornar o resultado mais realista, sera empregada uma pdf nao-ideal. A distribuicao da
fonte e uniforme no intervalo 1, 1 e arbitramos
f (s)  s3 (escolha comum para distribuicoes subgaussianas).
Em muitas simulacoes9 , o algoritmo converge

(16)

A partir da aproximacao (15), e possvel calcular os termos E f (y(k))x(k) e E f (y(k))x(k  1)
4 Ou seja, temos que c
D  d e cD  >> ci , para
i  0, 1, . . . , M + L + 1 e i 6 D M e a ordem do filtro
correspondente ao canal.
5 Algumas caractersticas do filtro de canal, como por
exemplo o decaimento, podem ser conhecidas a priori e
podem determinar o valor de D.
6 O resultado depende de algumas condicoes, explicitadas em D. B. Haddad (2009b).

7 Aqui

supomos, por simplicidade, o caso M  L  1.
resultados apresentam grande extensao, sendo
por isso omitidos aqui. Cumpre ressaltar que para obte-los
e necessario efetuar integracoes multidimensionais.
9 Estamos contemplando o caso M  L  1
8 Estes

4337

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

para uma boa solucao na qual temos D  2. Por
isso, empregamos a aproximacao (15) com D  2.
Esta aproximacao (e o calculo do valor esperado
consequente) permite-nos obter uma formula analtica para w1 

5
5
w1 
.
(18)
h1
1
Sendo D  2, temos que c2  h1 w1  
in5
5
depende do canal, o que mostra que uma funcao f
nao-ideal pode realmente desfazer completamente
o efeito do canal.
A ISI (em dB) obtida pelo algoritmo equalizador deve ser minimizada e e definida por

"
ISI(k)  10.log10

PM

2
l0 cl (k)
max0jM c2j (k)


 1 . (19)

Figura 1 Evolucao dos coeficientes w0 e w1 (tracejados) numa simulacao, comparados com a analise exata (linha solida), em 2000 iteracoes. (a)
  102 e h  0, 5 1 (b)   2  103 e
h  0, 2 3 (c)   6  103 e h  1  0, 5
e (d)   5  103 e h  0, 4  0, 3.

Supondo que o algoritmo convirja para
uma solucao de bom desempenho, teramos que
c2  >> ci , para i  0, 1. Apesar de termos uma
estimativa de c2 , a estimativa da ISI exige uma
estimativa de w0 , a qual nao e possvel de se obter
pela analise aproximada (o sistema obtido admite
infinitas solucoes). Entao introduzimos a analise
exata apenas para a estimativa de w0 , utilizando
o valor de w1 estimado pela analise aproximada.
Este procedimento, ainda que nao resulte numa
expressao analtica, permite-nos estimar a ISI.

6

Em todas as simulacoes abaixo, utilizamos M 
L  1 e f (y(k))  y 3 (k). A distribuicao da fonte
e uniforme e restrita ao intervalo -1,1.
6.1

5

Evolucao dos parametros

A analise exata acompanha fielmente a trajetoria
dos parametros, conforme podemos ver na Figura
1. As equacoes que descrevem esta evolucao sao
muito grandes e ja expressam automaticamente o
resultado de medias do tipo Monte Carlo efetuadas sobre milhares de simulacoes.
Mantendo fixo o filtro de canal e variando ,
vemos na Figura 2 que o resultado medio final e
inalterado. O aumento da variacao estocastica dos
coeficientes com o acrescimo de  nao e indicado
por esta figura, porque na media estas variacoes
se anulam.
Na Figura 3, a evolucao do valor esperado de
wi (k + 1) e apresentada. Verificamos que wi
tende a zero com o aumento do numero de iteracoes, indicando a convergencia do algoritmo.

Extensao da Analise Exata

A analise exata calcula o valor esperado dos coeficientes wi finais. Ela revela que estes valores
medios independem de . Por obvio, o aumento
de  implica maior variacao dos parametros, podendo inclusive induzir fenomenos de divergencia,
os quais nao sao captados pela analise exata acima
descrita. Por isso, introduzimos os parametros
wi (k + 1), definidos por
wi (k + 1)  wi (k + 1)  wi (k).

Simulacoes

(20)

Podemos encontrar wi (k + 1) transpondo
para o lado esquerdo da equacao os primeiros
termos do lado direito das Equacoes (11) e (12).
Apos obter estes valores, elevamo-los ao quadrado,
pois wi (k + 1) tende a zero com o aumento de k,
porem limk wi2 (k + 1) tende a um valor que
aumenta concomitantemente
de
 com o acrescimo

. Esta propriedade de E wi2 (k + 1) pode nos
auxiliar a encontrar um limite superior para 
que garanta a convergencia, fornecendo-nos uma
ferramenta de predicao de estabilidade essencial
para o estudo do algoritmo. Discutiremos esta
possibilidade na secao de simulacoes.

6.2

Abordagem hbrida

Seja o caso em que o filtro de canal e dado por
h  0, 5 1. Caso o filtro de equalizacao seja
inicializado como w  0 1, o algoritmo converge
para uma solucao de baixa ISI.
A comparacao da estimativa exata com a hbrida10 para os parametros w0 e w1 (a qual in10 O filtro de canal escolhido e um dos que apresentam
melhor concordancia entre a estimativa aproximada e a
exata de w1 . Mais a frente, veremos que pode haver maior
divergencia entre estas estimativas.

4338

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Figura 4 Utilizando o filtro de canal da forma h 
h0 1 e variando h0 , temos em (a) o valor final de
w1 e em (b) a ISI final obtida pelo algoritmo. A
linha tracejada indica o valor teorico obtido pela
analise aproximada.
depende de ) e mostrada na Tabela 1. A qualidade da estimativa significa que podemos reduzir
significativamente a complexidade das estimativas
exatas empregando a abordagem aproximada para
encontrar alguns parametros com uma formula
analtica de baixo_custo_computacional, como a
da Equacao (18).
Porem, cabe atentar para uma deficiencia
da estimativa aproximada a de que o algoritmo
converge para uma boa solucao (ou seja, de baixa
ISI). Se esta hipotese nao se verificar11 , a expressao (18) deixa de ser valida. Este fato e ilustrado
pela Figura 4, onde a variacao de h0 faz com que
o algoritmo estime equivocadamente os valores finais da ISI. Quando a ISI e inferior a aproximadamente -11 dB, o modulo da diferenca entre os
valores reais e estimados de w1 fica quase sempre
abaixo de 0,1 (ou seja, o erro percentual e inferior
a 7, 5).

Figura 2 Evolucao media (oriunda da analise exata) dos parametros wi e da ISI em funcao do
numero de iteracoes, com diferentes valores de ,
para h  0, 5 1.

6.3

Limites superiores de 

Como vimos, o valor esperado de wi (k) nao nos
prove de informacoes acerca de limites superiores
para o fator de aprendizagem
. Por

 isso, propomos uma analise de E wi2 (k + 1) . A analise
sera exata.
Seja o filtro de canal h  0, 5 1 e L  1. A
Figura 5 ilustra o aumento de wi2 coerente com
11 Ou

Figura 3 Evolucao media (oriunda da analise exata) dos parametros wi e da ISI em funcao do
numero de iteracoes, com diferentes valores de .

mesmo se tivermos D 6 2.

Tabela 1 Comparacao entre as estimativas exata
e hbrida dos parametros finais w0 e w1 .
parametro
w0
w1

4339

est. exata
0,6131
1,3738

est. hbrida
0,6105
1,3797

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Figura 7 Valor de maxi wi2 (k + 1) variando-se o
valor de  para h  0, 5 1.

2

Figura 5 Evolucao de w (k + 1) ao longo das
iteracoes, com diferentes valores de . E mostrado
o maior dos valores (maxi wi2 (k + 1)).

empregado no algoritmo DCGN, porque e muito
maior do que o maior valor aceitavel que nao provoca divergencia12 .
A Figura 7 ilustra o valor final de
maxi wi2 (k + 1), para os valores de  utilizados
na Figura 6. A comparacao entre as Figuras sugere uma possvel regra o limite superior de  que
provoca divergencia apresenta maxi wi2 (k+1) superior a 4  103 . Claro que essa regra e emprica
e oriunda de um unico caso do filtro de canal e
de pdf da fonte e portanto pode ser muito limitada. Alteremos portanto o filtro de canal para
h  2 0, 5.
A Figura 8 apresenta maxi wi2 (k + 1) (para
k  ) em funcao de . Pela regra emprica encontrada, suporamos que  nao pode ser maior
do que 101.3  0, 05. A Figura 9 mostra que comeca a ocorrer divergencia quando  ultrapassa o
li- miar de 101.35  0, 044. Ou seja, mesmo com
outro filtro de canal, o limite superior fornecido
pela analise exata nos fornece uma boa estimativa de max . E claro que reduzindo o limiar de
maxi wi2 (k + 1) para algo ligeiramente inferior,
poderamos evitar a divergencia em ambos os casos.
Um possvel obstaculo ao uso da analise
exata para encontrar o limite superior de  reside na sua complexidade. Porem, caso utilizemos
um  elevado para analisar a evolucao de wi (k),
podemos rapidamente (ou seja, em poucas iteracoes) calcular seus valores finais (ja que em media
estes valores tendem para o mesmo
 limite). Com
estes valores, basta-nos calcular E wi2 (k) (cujo
valor depende de ). Ou seja, somente o ultimo
passo deve ser efetuado varias vezes (variando-se o
parametro ) e assim podemos encontrar limiares
para  de forma muito mais rapida do que recorrendo a medias do tipo Monte Carlo oriundas de

Figura 6 Probabilidade de divergencia do algoritmo em funcao de  para h  0, 5 1.
o aumento de .
A partir de quais valores de  temos tendencia a divergencia? Para calcular a probabilidade de divergencia, efetuamos 200 simulacoes
para cada valor de , considerando que ocorre divergencia quando algum parametro wi (k + 1) seja
maior que 1000 em pelo menos uma das 5000 iteracoes. Para um filtro de canal h  0, 5 1, vemos o incio do fenomeno da divergencia quando
 passa a ser maior do que 101.6  25  103 .
Na falta de resultados teoricos para limites
de  que evitem a convergencia em algoritmos cegos, opta-se por utilizar um limite de algoritmos
adaptativos supervisionados. Por exemplo, um limite muito utilizado para o LMS (Haykin, 1996)
e
1
,
(21)
0<<
max
onde max e o maior autovalor da matriz de correlacao Rx de x(k). Para o filtro e a fonte utilizados
para gerar a Figura 6, temos que  deve ser menor
do que 1,7254. Isso significa que o limite superior
para  utilizado no algoritmo LMS nao pode ser

12 Em Diniz (2002) ha a observacao de que se ha grande
espalhamento dos autovalores, e necessario escolher um valor de  bem inferior ao limite superior porem, no caso
analisado, o espalhamento nao e grande.

4340

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

inumeras simulacoes.
6.4

Influencia de f (y(k))

Como vimos, a funcao f (y) deriva, pela Equacao
(4), de p(y). Se temos f (y)  y 3 , podemos descobrir (apos uma mudanca de variavel e resolvendo
uma equacao diferencial linear e homogenea) p(y).
Normalizando-a para que seja uma pdf valida, encontramos
( 43 )  y4
e 4.
(22)
p(y) 

Obviamente, temos que p(y) nao corresponde
a uma pdf uniforme13 . Se as fontes tiverem uma
pdf p(s) uniforme no intervalo , , a alteracao do valor de  implica alteracoes na ISI final (a
qual, idealmente, deve ser reduzida), como ilustra
a Figura 10(a).
Podemos relacionar p(y) e p(y) (a qual e influenciada por ) por meio de uma metrica de distancia entre elas. A metrica entre pdfs mais comumente utilizada e a distancia de Kullback-Leibler
Z
p(s)
ds.
(23)
DKL (pp)  p(s)ln
p(s)

Figura 8 Valor de maxi wi2 (k + 1) variando-se o
valor de  para h  2 0, 5.

O valor de DKL para diferentes valores de  e
mostrado na Figura 10(b). Infelizmente, esta metrica nao permite relacionar de forma simples a
distancia entre p(s) e p(s) com a ISI final obtida.
A metrica oriunda de DKL nao satisfaz os axiomas de distancia. Uma alternativa que os satisfaz e a distancia de Hellinger, definida por
(S. Amari, 2000)
Z p
2
p
DH (pp)  2
p(s)  p(s) ds. (24)
Quando comparamos DH com a ISI final (vide
partes (a) e (c) da Figura 10), verificamos que ha
uma correlacao entre ambas. Ou seja, ha uma tendencia (embora nao muito exata) entre distancia
de Hellinger reduzida e baixa ISI final. Isso expressa uma melhor modelagem de p(s) por meio
de f (y), o que significa que a distancia de Hellinger e mais informativa quando desejamos avaliar
como o desempenho do algoritmo e influenciado
pela divergencia entre p(s) e p(s).

7
Figura 9 Probabilidade de divergencia em funcao
de  para h  2 0, 5.

Conclusoes

Este artigo dedicou-se a analise de um algoritmo
de desconvolucao_cega, na sua versao monocanal.
Analises aproximadas e exatas foram efetuadas e
algumas propriedades deste algoritmo foram elucidadas. Uma delas evidenciou a tendencia de equalizacao independente do filtro de canal (ou seja, de
13 Nao podemos modelar a pdf uniforme exatamente, senao encontramos f (y)  0, condicao na qual o algoritmo
nao efetua uma otimizacao

4341

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

D. B. Haddad, M. R. Petraglia, P. B. B. (2009b).
Equivariancia e desempenho de um algoritmo
de deconvolucao cega, IX Congresso Brasileiro de Redes Neurais  Inteligencia Artificial (IX CBRN), pp. 15.
Diniz, P. S. R. (2002). Adaptive Filtering - Algorithms and Practical Implementation, Kluwer
Academic Publishers.
Haykin, S. (1996). Adaptive Filter Theory, Prentice Hall.
J.-F. Cardoso, B. H. L. (1996). Equivariant adaptive source separation, IEEE Transactions on
Signal Processing, 44(12) 30173030.
Figura 10 (a) valor da ISI final (em dB) obtida para diferentes valores de  (b) Distancia
de Kullback-Leibler e (c) Distancia de Hellinger.

J. LeBlanc, K. Dogancay, R. K. R. J. (1994). Effects of input data correlation on the convergence of blind adaptive equalizers, IEEE
International Conference on Acoustic, Speech
and Signal Processing, 3 313316.

forma equivariante) mesmo quando p(s) difere de
p(s).
Foi proposta uma abordagem para estimar o
limiar superior do fator de aprendizagem de modo
a evitar o fenomeno da divergencia. Esta abordagem se revelou valida em algumas configuracoes.
Pretendemos generaliza-la para outras situacoes
(diferentes filtros de canal, diferentes pdfs das fontes e pdfs modeladas, etc.).
O uso de estatsticas de segunda ordem das
variacoes dos parametros foram essenciais nesta
abordagem. Por fim, foi estabelecida uma relacao
entre a distancia de Hellinger entre as pdfs real
e aproximada da fonte com o desempenho obtido
pelo algoritmo. Embora todas as analises tenham
enfocado o caso M  L  1, a extensao para outras configuracoes nao e difcil.

L. Zhang, A. Cichocki, S.-I. A. (2004). Multichannel blind deconvolution of nonminimunphase systems using filter decomposition,
IEEE Transactions on Signal Processing,
52(5) 14301442.
Minker, J. B. W. (2007). Time-Domain Beamforming and Blind Source Separation - Speech
Input in the Car Environment,, Springer.
P. Chevalier, L. Albera, P. C. A. F. (2004). Comparative performance analysis of eight blind
source separation methods on radiocommunications signals, IEEE IJCNN, 1 2529.
S. Amari, H. N. (2000). Methods of Information
Geometry,, Oxford University Press.
S. C. Douglas, H. Sawada, S. M. (2005). Natural gradient multichannel blind deconvolution and speech separation using causal fir
filters, IEEE Transactions on Signal Processing, 13 92104.

Referencias
C. C. Cavalcante, J. M. T. R. (2009). On the relationships between mmse and informationtheoretic-based blind criterion for minimum
ber filtering, Lectures Notes in Computer Science, pp. 1724.

S.-I. Amari, A. C. (1998). Adaptive blind signal
processing - neural network approaches, Proceedings of the IEEE, 86(10).

C. Fevotte, S. J. G. (2006). A bayesian approach
for blind separation of sparse sources, IEEE
Transactions on Audio and Speech Processing, pp. 21742188.

X. Sun, S. C. D. (2001). Mean square error analyses of multichannel blind deconvolution algorithms, Proc. 35th Annual Asilomar Conf. on
Signals, Systems, and Computers 1 64852.

Cardoso, J.-F. (1998).
Blind signal separation Statistical principles, Proceedings of the
IEEE, 86(10) 20092025.

Y. Singh, C. S. R. (2001). A comparison of
bss algorithms, Proceedings of IEEE IJCNN,
2 1519.

D. B. Haddad, M. R. Petraglia, P. B. B. (2009a).
Analises exata e aproximada de um algoritmo
de deconvolucao cega, IX Congresso Brasileiro de Redes Neurais  Inteligencia Artificial (IX CBRN), pp. 15.

4342