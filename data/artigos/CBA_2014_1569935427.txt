Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

DESENVOLVIMENTO DE INTERFACE BASEADA EM GESTOS MANUAIS APLICADA EM
CONTROLE DE PROCESSOS INDUSTRIAIS
YVES L. COELHO, JOÃO M. SALOMÃO, HANS R. KULITZ
Coordenadoria de Engenharia Elétrica, Campus Vitória, Instituto Federal de Educação, Ciência e Tecnologia
do Espírito Santo - Ifes
Av. Vitória, 1729, 29040-780, Vitória, ES, Brasil
E-mails yvesluduvico@gmail.com, salomao@ifes.edu.br, hans@ifes.edu.br
Abstract The interaction between human and machine by gestures has often been object of study in the recent literature and it
is increasingly present in the lives of ordinary users. Televisions, mobile devices and videogames that respond to gesture commands are increasingly popular. In an industrial context, the gesture-based interfaces, in general, need to me more investigated
before being introduced into control systems. This paper proposes a Human-Machine Interface by static hand gestures to be applied in industrial process control. To achieve this goal, a gesture recognition system based on wavelet transform and Artificial
Neural Networks was developed. A Programmable Logic Controller receives the commands performed by static hand gestures
and applies them to the control of a didactic industrial plant. The OPC technology was used to provide the communication between the controller and the gesture recognition system. The proposed model in operation and the results of the tests performed
during the developmental steps will be presented.
Keywords Human-Machine Interface, Gesture Recognition, Artificial Neural Networks, Industrial Process Control, OPC
Technology.
Resumo A interação entre homem e máquina por meio de gestos tem sido frequentemente objeto de estudo na literatura recente e está cada vez mais presente na vida de usuários comuns. Televisores, dispositivos_móveis e videogames que respondem a
comandos gestuais tornam-se cada vez mais populares. No cenário industrial de uma maneira geral, interfaces baseadas em gestos ainda carecem de estudos antes de serem introduzidas nos sistemas_de_controle. Este trabalho propõe uma Interface HomemMáquina por gestos manuais estáticos para ser aplicada no controle_de_processos_industriais. Para concretizar este objetivo foi
desenvolvido um sistema de reconhecimento_de_gestos baseado em transformada_wavelet e Redes Neurais Artificiais. Um Controlador Lógico Programável recebe os comandos executados por gestos manuais estáticos e os aplica no controle de uma planta
industrial didática. Para realizar a comunicação entre o sistema de reconhecimento_de_gestos e o controlador utilizou-se a tecnologia OPC. O modelo proposto em operação e os resultados dos testes realizados durante as etapas de desenvolvimento serão
apresentados.
Palavras-chave .

dos que abordam as interfaces baseadas em gestos
aplicadas em automação_industrial.
Nas indústrias, o controle manual é realizado por
meio de chaves de manobra, botoeiras, ou  distância
em salas de controle. De acordo com Alves (Alves,
2005), em processos automáticos, o principal dispositivo de controle industrial atualmente é o Controlador
Lógico Programável (CLP).
O objetivo deste trabalho é apresentar o desenvolvimento de uma IHM por comandos gestuais estáticos para ser aplicada em controle_de_processos_industriais. Dada a lacuna existente no campo científico
a respeito deste assunto, entende-se que este projeto
tem caráter inovador.
A introdução de uma IHM baseada em gestos na
indústria pode contribuir para um controle mais intuitivo, e assim facilitar a utilização de uma interface
pelo usuário. A respeito de reconhecimento_de_gestos, a literatura divide-se principalmente entre técnicas de visão_computacional e luva com sensores.
Para implementar o modelo proposto, desenvolveu-se um sistema de reconhecimento_de_gestos, utilizando técnicas de visão_computacional tendo como
suporte a transformada_wavelet e as Redes Neurais
Artificiais (RNA). A tecnologia Object Linking and
Embedding (OLE) for Process Control (OPC) foi

1 Introdução
A Interface Homem-Máquina (IHM) sempre foi um
desafio para a ciência da computação. Inicialmente, a
comunicação interativa entre homem e computador
somente era possível por meio de linhas de comando,
o que exigia do usuário conhecimento em linguagem
de programação. Com o advento do mouse e da interface_gráfica, a interação tornou-se mais intuitiva,
proporcionando aos usuários maior usabilidade.
A evolução da IHM possibilita uma interação de
nível cada vez mais alto, ou seja, requer cada vez
menos conhecimento da tecnologia por trás da máquina por parte do usuário. Como resultado do avanço tecnológico, a ciência oferece hoje interfaces baseadas em comandos naturais do homem, como gestos e fala. Já são comuns robôs, dispositivos_móveis e
televisores que interpretam comandos gestuais.
Atualmente algumas pesquisas tratam de interfaces por gestos, e geralmente envolvem interfaces
virtuais (Rautaray  Agrawal, 2012), aplicações em
robótica (Chen et al., 2011) ou jogos (Lee  Hong,
2010). Entretanto ainda há poucos trabalhos publica-

3358

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

utilizada para prover a comunicação entre este sistema e um CLP.

Jalab (Jalab, 2012) aborda em seu trabalho um
algoritmo para reconhecimento_de_gestos baseado em
transformada_wavelet e RNA. O autor obteve 97 de
acertos na classificação de seis diferentes gestos.
Yewale e Bharne (Yewale  Bharne, 2011)
apresentam uma técnica de detecção_de_bordas na
etapa de segmentação e um algoritmo neural para
classificar os gestos. Os autores concluem que a aplicação destes métodos em conjunto é uma excelente
solução para o reconhecimento_de_gestos utilizando o
software MATLAB.
Já Zang, Wang e Deng (Zang, Wang  Deng,
2011) apresentam um sistema classificador baseado
em uma rede_neural com treinamento backpropagation aliada a uma técnica chamada Simulated Annealing para melhorar o desempenho da rede. Com o
objetivo de classificar 40 diferentes gestos, eles obtiveram uma taxa de acertos de 92,7, utilizando 30
amostras de cada gesto para treinamento e 10 para
validação.

1.1 Visão computacional
A visão_computacional é um ramo da Inteligência
Artificial que utiliza o computador para emular a
visão humana, incluindo o aprendizado e a capacidade de tomar decisões baseadas em informações visuais (Gonzalez  Woods, 2010). Esta técnica é amplamente aplicada em reconhecimento_de_gestos.
No escopo deste trabalho entende-se que a visão
computacional está presente desde a captura até a
interpretação dos gestos executados. Dentro deste
processo encontram-se o processamento digital da
imagem obtida e a classificação utilizando um algoritmo neural. A Figura 1 ilustra o processo contendo
as etapas que compõem a aplicação da visão_computacional após a aquisição da imagem.

2.2 Comandos gestuais na indústria
A área industrial tem características bastante peculiares, e exige o cumprimento de requisitos importantes,
principalmente aqueles relacionados  segurança e 
confiabilidade. Assim, torna-se mais cautelosa a introdução de uma IHM baseada em gestos neste cenário. Na conjuntura atual, interfaces baseadas em gestos na indústria são muito mais objetos de estudo do
que de aplicação prática.
Entretanto, a literatura ainda carece de trabalhos
relacionados a este assunto. Um dos poucos exemplos é o trabalho de Skripcak et al. (Skripcat et al.,
2013), que propõe a criação de uma parede virtual
para monitoramento de uma planta industrial, onde
comandos naturais, entre eles os gestuais, são aplicados na interação com o sistema.
Outra pesquisa acerca deste assunto, realizada
por Segura et al. (Segura et al., 2007), apresenta a
aplicação de uma interface redundante baseada no
reconhecimento dos gestos e da fala, para garantir
maior robustez, aplicada na operação de guindastes
de contêineres.

Figura 1. Etapas da visão_computacional.

1.2 Tecnologia OPC
A tecnologia OPC oferece um conjunto de protocolos
padrões de interface OLECOM (Component Object
Model) da Microsoft com o objetivo de garantir maior integração entre dispositivos e aplicações (OPC
Foundation, 2003). Uma especificação da tecnologia
OPC é a OPC Data Access, que é utilizada para mover dados em tempo_real de dispositivos, como um
CLP, para aplicações chamadas clientes.
A tecnologia OPC é uma solução para a integração dos sistemas proprietários, muitas vezes encontrados nas indústrias. Servidores OPC permitem que
diversos clientes conectem-se a eles, independentemente do fabricante ou do protocolo de comunicação
utilizado.

3 O sistema proposto
A finalidade do modelo proposto neste trabalho é
reconhecer quatro diferentes gestos e interpretá-los
como comandos para controlar uma planta industrial
didática a partir de um CLP. Esta seção descreve
cada uma das etapas de desenvolvimento da IHM
proposta, relacionando os dispositivos, softwares e
técnicas aplicados em cada estágio.
O sistema de reconhecimento_de_gestos foi implementado no software MATLABSimulink da empresa MathWorks. Neste ambiente, implementaramse as etapas de aquisição, segmentação, descrição e
classificação dos gestos, que serão abordadas na se-

2 Estado da Arte
2.1 Reconhecimento de gestos
As RNA são amplamente empregadas em classificadores de padrões, incluindo os sistemas de reconhecimento_de_gestos. Alguns exemplos são os trabalhos
de Jalab (Jalab, 2012), de Yewale e Bharne (Yewale
 Bharne, 2011) e de Zang, Wang e Deng (Zang,
Wang  Deng, 2011).

3359

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

quência. A Figura 2 apresenta os gestos do sistema
LIBRAS utilizados neste trabalho.

Um ponto no cubo RGB define uma cor de acordo com suas coordenadas, ou seja, de acordo com a
combinação da intensidade de cada componente vermelha, verde e azul.
Neste projeto, previamente  operação do sistema, deve-se determinar a cor do objeto de interesse.
Desta forma, obtém-se uma imagem da mão do usuário, recorta-se uma superfície preenchida por esta e
calcula-se a intensidade média de cada componente
RGB. O vetor de cor média, a, agrega os valores
normalizados da intensidade média de cada componente.
É importante que este vetor seja obtido no local
de operação do sistema, visto que as componentes
RGB do objeto capturado são influenciadas pela iluminação do ambiente. Também é necessário que o
vetor a seja definido para cada usuário do sistema,
devido a cores de pele distintas.
Na operação do sistema, a segmentação baseiase na comparação da cor dos pixels da imagem analisada com o vetor a definido previamente. Sendo z o
vetor que contém as componentes RGB normalizadas
de cada pixel analisado na imagem capturada, realiza-se uma varredura por toda a imagem, calculando a
distância_euclidiana entre os vetores a e z.
O vetor a pode ser representado por um ponto
tridimensional no cubo RGB. Desta forma, define-se
como faixa de similaridade a esfera de raio D0 em
torno deste ponto. Quando o valor da distância_euclidiana entre a e z é menor ou igual a este limiar D0, o
ponto z está inserido na esfera em torno de a, e assim, classifica-se o pixel analisado como similar ao
objeto de interesse.
Após a análise de toda imagem pixel a pixel obtém-se como resultado uma imagem binária, na qual
os pixels classificados como similares ao objeto de
interesse são caracterizados como brancos. Já os restantes são definidos como pixels pretos. A Equação 1
mostra a formação da imagem binária b(x,y) resultante deste procedimento, sendo x e y correspondentes
s linhas e s colunas da imagem, respectivamente.

Figura 2. Gestos utilizados no projeto.

3.1 Aquisição de vídeo
A aquisição dos gestos é realizada por uma webcam
conectada a um computador por um cabo USB. O
vídeo é capturado no formato MJPG, com resolução
de 160 x 120 e no modelo de cores RGB. A taxa de
captura é de 10 quadros por segundo.
Optou-se pela menor resolução disponível, com
o objetivo de se obter um menor conjunto de dados e
reduzir o processamento. O modelo de cores RGB foi
utilizado na etapa de segmentação dos gestos. Como
exemplo, a Figura 3 apresenta a aquisição do gesto
L.

Figura 3. Captura do gesto L.

3.2 Segmentação baseada no modelo RGB
Devido a características do olho humano, as cores
são vistas como combinação das chamadas cores
primárias vermelho, verde e azul. No modelo de
cores RGB cada cor aparece em seus componentes
espectrais primários. Este modelo se baseia em um
sistema de coordenadas cartesianas, no qual o subespaço de interesse é o cubo, ilustrado na Figura 4
(Gonzalez  Woods, 2010).


1, se D(x, y)  D 0
b(x, y)  
(1)
0, se D(x, y)  D 0


A Figura 5 apresenta o resultado da segmentação após o processo de binarização.

Figura 5. Resultado da segmentação.

Nota-se a presença de ruídos após o processo de
segmentação da mão do usuário. Para eliminá-los

Figura 4. Esquema do cubo de cores RGB.

3360

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

A Figura 7 ilustra uma representação básica da
aplicação da FWT bidimensional  imagem do gesto
segmentado. Os filtros passa-altas (FPA) e passabaixas (FPB) são aplicados primeiramente ao longo
das linhas e efetua-se a subamostragem das colunas.
As subimagens resultantes são filtradas ao longo das
colunas e suas linhas são subamostradas. Os resultados são os coeficientes de detalhes diagonais (cD),
verticais (cV), horizontais (cH) e os coeficientes de
aproximação (cA).

aplica-se uma técnica conhecida como filtro espacial
de suavização. Neste caso utilizou-se o filtro de mediana. Na filtragem pela mediana, uma máscara percorre toda a imagem calculando a mediana entre os
valores envolvidos pela máscara, e inserindo o resultado no pixel central. O conjunto de resultados forma
a imagem filtrada.
Neste trabalho, optou-se por uma máscara de 5 x
5 pixels. O emprego do filtro de mediana eliminou
por completo os ruídos presentes na imagem, como
pode ser observado na Figura 6.

Figura 6. Resultado após filtragem pela mediana.
Figura 7. Aplicação da FWT bidimensional.

Esta técnica de filtragem mostrou-se eficiente,
visto que o método utilizado na segmentação do objeto elimina previamente conjuntos de pixels indesejados em grandes agrupamentos. Entretanto, para
alcançar um bom resultado, deve-se optar por um
ambiente de pouca complexidade, sem objetos de
cores similares  cor da mão do usuário.

Neste trabalho foi aplicada sobre a imagem binária do gesto uma FWT de seis níveis utilizando o
filtro de Haar (Haar, 1909). Os coeficientes de aproximação foram utilizados como entrada do banco de
filtros subsequente. O vetor de características (x) é
obtido concatenando-se todos os coeficientes de
aproximação e detalhes obtidos do último banco de
filtros, formando-se um vetor de 24 elementos. A
Figura 8 apresenta este procedimento.

3.3 Extração de características
A extração_de_características de uma imagem consiste
em representar os dados originais de forma eficiente
em um conjunto reduzido. Este trabalho utiliza os
coeficientes resultantes da aplicação da transformada
wavelet como vetor de características. As wavelets
são as bases de uma ferramenta para análise de sinais,
chamada de teoria multirresolução.
De acordo com Gonzalez e Woods (Gonzalez 
Woods, 2010), na análise multirresolução, uma função escala é utilizada para criar uma série de aproximações de uma função ou imagem, cada uma com
resoluções que diferem por um fator de 2 considerando suas aproximações de vizinhança mais próxima. Funções adicionais, chamadas de wavelets, são
utilizadas para codificar a diferença das informações
entre aproximações adjacentes.
A transformada_wavelet é uma ferramenta poderosa na compressão e análise de imagens e pode ser
utilizada na etapa de extração_de_características. A
expansão em série da transformada_wavelet na forma
discreta é chamada de transformada_wavelet_discreta
(DWT, de discrete wavelet transform).
A transformada rápida de wavelet (FWT, de fast
wavelet transform), é um algoritmo computacional da
DWT que pode ser implementado utilizando filtros e
subamostragens. Como resultado da aplicação da
FWT a um sinal obtêm-se coeficientes de detalhes e
de aproximação.

Figura 8. Aplicação da FWT de seis níveis.

Ainda que este método sequencial possa apresentar resultados redundantes, no fim do processo
obtém-se um conjunto de dados bastante reduzido,
quando comparado ao apresentado por Jalab (Jalab,
2012) com 128 elementos. Desta forma, o vetor de
entrada apresentado ao algoritmo classificador é menor, o que implica um menor tempo de processamento para identificar um gesto.
3.4 Classificação e interpretação
Na etapa de classificação do gesto foi desenvolvido
um algoritmo baseado em RNA. De acordo com Sil-

3361

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

va, Spatti e Flauzino (Silva, Spatti  Flauzino,
2010), uma rede_neural é um modelo computacional
inspirado no sistema nervoso dos seres vivos, que
possui capacidade de aquisição e manutenção de conhecimento.
A estrutura de uma rede_neural, as diferentes arquiteturas e topologias e os processos de treinamento
estão amplamente discutidos na literatura e são abordados com uma base sólida por Haykin (Haykin,
2001). O algoritmo classificador desenvolvido neste
trabalho baseia-se em uma arquitetura de rede_neural
conhecida como Perceptron Multicamadas (PMC),
que utiliza o algoritmo backpropagation como processo de treinamento.
Na primeira etapa de treinamento, os sinais de
entrada  no caso deste trabalho, os elementos do
vetor de características  são propagados até a saída
sendo ponderados pelos pesos sinápticos. As saídas
obtidas são comparadas com as esperadas, e a diferença entre elas são utilizadas no ajuste dos pesos na
etapa de retropropagação (backpropagation).
O ajuste dos pesos sinápticos depende da taxa de
aprendizagem (), do gradiente local () da camada e
das saídas da camada anterior. A taxa de aprendizagem indica com que velocidade a rede deve buscar a
convergência. Neste trabalho adotou-se   0,1. O
erro quadrático médio (EMédio), além de ser utilizado
no cálculo do gradiente local, também é usado como
critério de convergência da rede. O treinamento será
suficiente, quando a Equação 2 for satisfeita, sendo a
precisão () igual a 10-6.
anterior
E atual
Médio  E Médio  

nios e os gestos classificados pode ser observada na
Tabela 1.
Tabela 1. Relação entre saídas dos neurônios e gesto classificado.
Y2

Variável

0
0
1
1

0
1
0
1

B
L
P
T

Nota-se que este classificador não é capaz de interpretar um gesto diferente dos quatro escolhidos e
classificá-lo como gesto não identificado. Assim,
no caso de um gesto distinto dos selecionados ser
executado, o sistema o classifica erroneamente como
um dos gestos escolhidos. Pretende-se evoluir neste
aspecto no andamento deste projeto.
Para entender que não há gesto sendo executado,
o sistema classificador ignora imagens com número
de pixels similares ao objeto de interesse abaixo de
um determinado limiar. Desta forma, possíveis ruídos
não são identificados como um dos gestos.
Após a classificação do gesto, há uma etapa de
interpretação. Neste momento, o gesto classificado é
responsável por ativar uma entre quatro saídas do
sistema de reconhecimento. A Tabela 2 mostra as
associações entre os gestos executados e as saídas.
Tabela 2. Relações entre gestos executados e saídas do sistema.

(2)

Para definir o número de neurônios da camada
intermediária, foram realizados quatro testes com
cinco topologias candidatas. Em cada teste, 150
amostras de cada gesto foram utilizadas para treinamento, e 50 para validação. A topologia campeã foi
aquela que continha 20 neurônios na camada intermediária. Assim, as matrizes de pesos ajustados desta
topologia foram utilizadas durante a operação do
sistema. Os resultados serão apresentados na Seção
4.1.
A camada de saída é composta por dois neurônios. As saídas dos neurônios (y) estão no intervalo
entre zero e um, pois a função de ativação utilizada
foi a função_logística. Desta forma, como se trata de
um classificador de padrões, há um pósprocessamento para se obterem apenas valores inteiros. A Equação 3 apresenta este pós-processamento.

1, se y i  0,5
Yi  
0, se yi  0,5

Y1

Gesto

Saída

B
L
T
P

1
2
3
4

Finalmente, utiliza-se um registrador de deslocamento para armazenar 10 resultados do sistema de
reconhecimento_de_gestos. A saída será ativada apenas quando ocorrerem 10 classificações seguidas
iguais. Esta é uma forma de tornar o sistema mais
robusto, evitando um acionamento incorreto do controlador devido a uma identificação errada esporádica.
Este procedimento utilizando o registrador torna
o sistema mais lento, entretanto não está no escopo
deste trabalho criar um sistema com resposta instantânea. O objetivo é validar a possibilidade de interagir com máquinas industriais por meio de gestos, com
certa robustez.
3.5 Comunicação com o CLP

(3)

A tecnologia OPC é utilizada pra realizar a comunicação entre o sistema de reconhecimento_de_gestos
desenvolvido no MATLABSimulink e o CLP. Utilizou-se o software KEPServerEX da empresa Kepware Technologies para criar e configurar o servidor

Com a combinação dos resultados dos dois neurônios da camada de saída, pode-se classificar quatro
gestos distintos. A relação entre as saídas dos neurô-

3362

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

OPC. O Simulink é tratado como cliente OPC. A
Figura 9 ilustra o diagrama de comunicação.

água. A Figura 10 mostra a planta industrial didática,
que opera uma caixa dágua, utilizada no projeto.

Figura 9. Diagrama de comunicação do sistema.

O servidor OPC recebe dados do sistema de reconhecimento_de_gestos e os transmite ao CLP. Desta
forma, o CLP atua de acordo com os comandos gestuais realizados pelo usuário. Configurou-se, no servidor OPC, um canal de comunicação utilizando o
driver Siemens TCPIP Ethernet, e definiu-se o
modelo do CLP utilizado (S7-300, da Siemens). Assim, o CLP está associado ao servidor OPC.
Ainda no servidor OPC, criou-se um grupo para
conter as variáveis que são manipuladas pelos comandos gestuais. A Tabela 3 apresenta a associação
entre as variáveis, os endereços e os tipos, que devem
ser os mesmos daqueles definidos no programa do
CLP.

Figura 10. Planta industrial didática utilizada no projeto.

Um programa de controle básico ligadesliga foi
implementado no CLP, por meio do software Totally
Integrated Automation (TIA), da Siemens. Enquanto
o nível_de_água encontra-se abaixo do set point, a
bomba dágua da planta é acionada para encher a
caixa dágua. Quando o nível atinge o set point, a
bomba é desligada.
Os comandos gestuais têm as seguintes funções
o gesto L liga o sistema_de_controle o gesto B
desliga o sistema o gesto T incrementa o set point
enquanto é executado e o gesto P decrementa o set
point durante sua execução. Estes comandos são recebidos pelo CLP por intermédio do servidor OPC.

Tabela 3. Configuração das variáveis no servidor OPC.
Variável

Endereço

Tipo

LigaSistema
DesligaSistem
IncrementaSP
DecrementaSP

M0.1
M0.2
M0.3
M0.4

boolean
boolean
boolean
boolean

4 Resultados e análises
4.1 Classificação
Este tópico apresenta os resultados referentes ao desempenho das diversas topologias analisadas a serem
empregadas na rede PMC. Como descrito na Seção
3.4, obteve-se a média dos resultados dos quatro testes realizados para cada topologia candidata. A Tabela 5 apresenta os resultados, onde n é o número de
neurônios da camada intermediária.

No Simulink são utilizados dois blocos do OPC
toolbox para configurar o modelo como cliente. O
bloco OPC Configuration define o servidor OPC ao
qual o cliente será conectado. Já o bloco OPC Write
recebe as saídas do sistema de reconhecimento de
gestos e associa cada uma  respectiva variável manipulada pelo gesto. A Tabela 4 mostra a relação
entre gesto executado, saída do sistema de reconhecimento e variável do servidor OPC.

Tabela 5. Resultados dos testes da rede PMC.

Tabela 4. Relações entre gestos, saídas ativas e variáveis.
Gesto

Saída ativa

Variável

B
L
P
T

1
2
3
4

DesligaSistema
LigaSistema
IncrementaSP
DecrementaSP

Topologia

n

Acertos ()

1
2
3
4
5

50
35
20
10
5

98,25
98,88
99,25
98,63
98,50

Os resultados apresentados foram superiores
queles alcançados por Jalab (Jalab, 2012), que obteve uma taxa de acertos de 97 em média. Entretanto,
é importante elucidar que o presente trabalho foi mais
exigente quanto  precisão, e assim foi necessário um
número de épocas superior para o treinamento convergir.

3.6 Sistema de controle
Para validar o modelo proposto por este trabalho, aplicou-se o sistema desenvolvido no controle de
nível_de_água de uma planta_didática. Utilizou-se um
sensor de pressão para a determinação do nível de

3363

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Observa-se que a topologia com 20 neurônios na
camada intermediária apresentou a melhor taxa de
acertos. Além disso, esta mesma topologia levou um
menor número de épocas para convergir, demonstrando ser a mais eficiente para o caso. Portanto, escolheu-se esta para ser empregada no algoritmo classificador do sistema.
Tabela 6. Matriz de confusão.

Gestos identificados

Gestos
executados

B

L

P

T

B
L
P
T

199
0
0
0

0
199
0
4

1
0
200
0

0
1
0
196

Figura 12. Execução do gesto L.

Na sequência, realiza-se o gesto T para incrementar o set point degrau a degrau. Observa-se na
Figura 13 que o set point foi incrementado até o valor
7,36 polegadas, e a caixa dágua continua recebendo
água.

A Tabela 6 apresenta a matriz de confusão da
rede_neural definida. Nota-se que o pior caso ocorre
quando o gesto T é realizado, visto que por quatro
vezes o algoritmo o identificou erroneamente como
L. Conclui-se que as amostras destes dois gestos
podem estar em regiões próximas  fronteira de separabilidade no espaço de definição de classes.
O algoritmo apresenta o melhor desempenho ao
classificar o gesto P. Este gesto é o que apresenta
características mais particulares entre os gestos utilizados neste trabalho, pois exige uma posição lateral
da mão. Este fato pode ter contribuído para um melhor desempenho em sua classificação.

Figura 13. Execução do gesto T.

4.2 Sistema em operação
Este tópico apresenta o funcionamento do sistema
proposto. Os comandos gestuais são realizados e a
resposta do sistema pode ser visualizada na interface
virtual implementada no software TIA, da Siemens.
Inicialmente, o sistema encontra-se desligado, com
set point definido como 4 polegadas e nível atual
igual a 1,91 polegada, como mostra a Figura 11.

Para decrementar o set point, o gesto P é executado, como mostra a Figura 14. Pode-se observar
que o set point foi decrementado até o valor 4,94
polegadas, e que a bomba dágua foi desligada, pois
o valor do set point encontra-se agora abaixo do nível
atual de água.

Figura 11. Estado inicial do sistema.

Figura 14. Execução do gesto P.

Executa-se, então, o gesto L para ligar o sistema_de_controle. Nota-se na Figura 12 que o sistema
está agora ligado, bem como a bomba dágua, pois o
nível_de_água encontra-se abaixo do set point. O indicador de luz verde mostra que o gesto L está sendo
realizado.

Por fim, o gesto B é executado para desligar o
sistema_de_controle. A Figura 15 ilustra o comando
sendo realizado e o sistema desligado. O indicador de
luz verde mostra que o comando gestual B está
sendo realizado.

3364

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Technology Journal, Vol. 11, No. 9, pp. 12651271.
Lee, D.  Hong, K. (2010). Game Interface Using
Hand Gesture Recognition. IEEE 5th Conference
on Computer Science and Convergence
Information Technology (ICCIT), Vol. 2, pp.
1092-1097.
OPC Foundation (2003). Data Access Custom
Interface Standard.
Rautaray, S. S.  Agrawal, A. (2012). Design of
Gesture Recognition System for Dynamic User
Interface. IEEE International Conference on
Technology Enhanced Education (ICTEE), pp.
1-6, 2012.
Segura, J. D. G. et al. (2007). Using Virtual Reality
for Gesture and Vocal Interface Validation in
Industrial Environments. IEEE International
Conference
on
Artificial
Reality
and
Telexistence, pp. 294-295.
Silva, I. N. da, Spatti, D. H.  Flauzino, R. A (2010).
Redes Neurais Artificiais para engenharia e
ciências aplicadas. São Paulo Artliber.
Skripcak, T. et al. (2013).
Toward NonConventional Human-Machine Interfaces for
Supervisory Plant Process Monitoring. IEEE
Transactions on Human-Machine Systems, Vol.
43, No. 5, pp. 437-450.
Yewale, S. K.  Bharne, P. K. (2011) Hand Gesture
Recognition Using Different Algorithms Based
on Artificial Neural Network. IEEE International
Conference on Emerging Trends in Networks
and Computer Communications (ETNCC), pp.
287-292.
Zhang, H., Wang, Y.  Deng, C. (2011). Application
of Gesture Recognition Based on Simulated
Annealing BP Neural Network. In International
Conference on Electronic  Mechanical
Engineering and Information Technology, 2011.
Heilongjiang Harbin University of Science and
Technology, pp. 178-181.

Figura 15. Execução do gesto B.

5 Conclusões
Este trabalho apresentou a possibilidade de interação
com máquinas industriais a partir de comandos gestuais estáticos, e desta forma pretende-se contribuir
para o crescimento dos estudos neste contexto. O
classificador_neural apresentou resultados bastante
satisfatórios, entretanto o número reduzido de gestos
contribuiu para um melhor desempenho. A tecnologia
OPC foi fundamental para a concretização do modelo
proposto.
Deve-se elucidar que este trabalho teve como objetivo apenas apresentar uma possibilidade de interação não convencional para indústrias. Assim, não
foram abordados requisitos de segurança e confiabilidade, por exemplo, que são fundamentais para
qualquer operação de máquinas industriais.
Agradecimentos
Os autores agradecem ao Instituto Federal do Espírito
Santo pela estrutura de laboratórios, equipamentos e
softwares disponibilizados para o desenvolvimento
deste projeto.
Referências Bibliográficas
Alves, J. L. L. (2005). Instrumentação, Controle e
Automação de Processos. Rio de Janeiro LTC.
Chen, H. et al. (2011). View-Based Multi-Touch
Gesture Interface for Furniture Manipulation
Robots. IEEE Workshop on Advanced Robotics
and its Social Impacts (ARSO), pp. 39-42, 2011.
Gonzalez, R. C.  Woods, R. E. (2010).
Processamento Digital de Imagens. 3rd edition.
São Paulo Pearson Prentice Hall.
Haar, A. (1909). On the Theory of Orthogonal
Function Systems.
Haykin, S. (2001). Redes Neurais princípios e
prática. Porto Alegre Bookman.
Jalab, H. A. (2011). Static Hand Gesture Recognition
for Human Computer Interaction. Asian Network
for Scientific Information - Information

3365