Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

REDES NEURAIS LÓGICAS BOOLEANAS BASEADAS EM NEURÔNIOS AND E OR TREINADOS
POR ALGORITMO GENÉTICO
FLÁVIO H. M. DUTRA, ARNALDO DE M. GOMES, PYRAMO P. DA COSTA JR, GUSTAVO L. SOARES
Programa de Pós Graduação em Engenharia Elétrica, PUC-Minas
Av. Dom José Gaspar, 500 - Prédio 03 - Coração Eucarístico - Belo HorizonteMG, Brasil, 30535-610
E-mails flaviohmd@hotmail.com, arnaldo.gomes@gmail.com, pyramo@pucminas.br,
gsoares@pucminas.br

Abstract This paper presents results of research into the use of the Neural Logic Network concept to model Boolean expressions from the truth tables, getting the same results that are obtained on the basis of the Karnaugh map techniques. Different topologies are presented which apply logical AND and OR neurons. It allow one to create neural networks which determine the
logical outcome for any combinations at the network entry. The network training is performed by Genetic Algorithm appropriate for all topologies used in the experiments.
Keywords Neural Logic Network, OR, AND, Genetic Algorithm.
Resumo Este artigo apresenta resultados de pesquisas utilizando os conceitos da Rede Neural Lógica para modelar expressões
booleanas a partir das Tabelas Verdade, obtendo uma resposta idêntica que se utilizada as técnicas de mapa de Karnaugh. São apresentadas diferentes topologias, utilizando neurônios lógicos AND e OR, possibilitando a criação de redes_neurais que determinam o resultado lógico para quaisquer combinações na entrada desta rede. O treinamento desta rede é realizado por Algoritmos Genéticos adaptados para cada uma das topologias utilizadas nos experimentos.
Palavras-chave .

1

como ambiente_de_desenvolvimento em ambos os
casos.
Antes de iniciar as implementações, o artigo revisa alguns conceitos envolvendo os neurônios lógicos apresentados por Pedrycz (2006) e Hell (2006),
apresenta as arquiteturas das redes e os conceitos do
Algoritmo Genético utilizado no treinamento da rede.

Introdução

O cérebro humano é capaz de realizar vários processos em paralelos, permitindo reconhecer sons, odores
e formatos em frações de segundos e em simultâneo.
Esta facilidade de reconhecer padrões aumenta a
cada experiência vivenciada, devido a sua plasticidade, que permite se adaptar a diversas situações (Kandel, Schwartz and Jessel, 2000). Esta capacidade
cerebral comparada com um computador digital é
que motiva pesquisas envolvendo redes_neurais.
As redes_neurais artificiais são ferramentas de
Inteligência Computacional que modelam a maneira
como o cérebro humano funciona, com capacidade
de generalizar informações e calcular saídas alternativas diferentes para entradas desconhecidas durante
o treinamento (Haykin, 2001). A aplicação da rede
neural vem sendo difundida em diversas áreas do
conhecimento, e o entendimento de seu princípio de
funcionamento é um passo primordial para aplicá-la.
Para entender e aplicar os conceitos da rede_neural lógica que foi introduzido por McCulloch e Pitts
(1943), se deve compreender que um neurônio artificial que possui comportamento mais próximo de um
neurônio biológico é denominado neurônio nebuloso
(Rocha, 1987).
Este artigo, utiliza estas estruturas de redes_neurais para implementar as estruturas de processadores
lógicos apresentadas por Hell (2006), detalhando a
topologia do processador lógico do tipo soma de
mintermos (ANDOR), e tem com objetivo principal
implementar e validar a arquitetura multilayer do
experimento I sugerido por Pedrycz (2006), que
basicamente obtém uma combinação de 4 entradas
booleanas e uma saída simples, utilizando o Matlab

2 Fundamentos
2.1 Neurônios Lógicos
A criação de redes_neurais lógicas iniciou a partir da
construção de neurônios que exercem as funções
lógicas AND e OR. Para compreender estes conectivos lógicos é necessário conhecer sobre a teoria de
Conjuntos Nebulosos introduzida por Zadeh (1965),
que parte de um princípio em que os limites de um
conjunto não são bem definidos, ou seja, a transição
entre pertencer ou não ao conjunto é gradual, caracterizado por uma função de pertinência para cada elemento, diferentemente da teoria de Conjuntos Clássicos, no qual o elemento apenas pertence ou não pertence a um conjunto (Hell, 2006).
Uma forma de generalizar a interseção e união
da teoria de conjuntos_nebulosos são as funções de
agregação chamadas de normas triangulares (tnormas) e co-normas triangulares (t-conormas ou snormas), que são operações binárias, no intervalo 0,
1, satisfazendo as exigências de comutatividade,
associatividade, monotonicidade e condições de
fronteira (Calvo et. al., 2007) (Hell et. al., 2009).
Ambas operações possuem elementos neutros, ou
seja, elementos que não afetam a saída, sendo que
"1" é o elemento neutro da t-norma e "0" o elemento
1232

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

neutro da s-norma. Uma operação t-norma entre os
elementos x e w, pode ser escrita da seguinte forma

ser escritas de forma mais curta como y  AND(x w)
e y  OR(x w). Um modelo de neurônio pode ser
visto na Fig. 1.

(1)
Já a operação t-conorma ou s-norma pode ser escrita na forma
(2)
Estas funções de agregação podem utilizar diferentes conectores, tais como a função mínimo, produto algébrico, operador diferença limitada de Lukasiewicz e produto drástico, para t-norma e função máximo, soma probabilística, soma limitada de Lukasiewicz e soma drástica, para s-norma (Calvo et. al.,
2007).
Este trabalho, utiliza a função MIN, como operador de agregação para t-norma e a função MAX
como operador de agregação para s-norma. A implementação da t-norma e s-norma utilizando valores
booleanos 0 e 1 possibilita a atuação delas como
operadores lógicos padrões AND (MIN) e OR
(MAX) respectivamente. A Eq.1, considerando que
w assuma o valor do elemento neutro, pode ser reescrita como y  x t 1, logo, o MIN entre x e "1" será
sempre o próprio x, caracterizando o operador AND.
A mesma analogia pode ser feita para o operador
OR, porém, vale lembrar que seu elemento neutro
vale "0" e se utiliza função MAX.
Da mesma forma que se tem o elemento neutro,
as duas funções também possuem seus elementos de
absorção, que representa o valor que leva a saída para
uma determinada condição independente do outro
valor. Para a função t-norma, o elemento de absorção
vale "0" e para a função s-norma, o elemento de
absorção tem valor "1". A mesma analogia que exemplifica os operadores acima pode ser realizada
para mostrar o efeito destes elementos.
A criação de neurônios lógicos AND e OR parte
da composição destas duas normas triangulares vista
em Hirota e Pedrycz (1994) e Hell (2006). Considerando dois vetores de mesma dimensão, x e w, a
composição chamada t-norma suprema (sup-t) pode
ser definida pela expressão
,

Figura 1. Representação de um neurônio lógico AND ou OR.
Adaptado de Hell (2006).

Em um sistema_nebuloso, estes pesos referem-se
ao grau de pertinência da cada entrada, porém, em se
tratando deste modelo para lógica booleana, estes
pesos assumem valores discretos "0" ou "1" e definem quais entradas terão relevância. Segundo Pedrycz (2006), num neurônio lógico do tipo AND, as
entradas com pesos "1" serão mascaradas, ou seja,
serão desprezadas. A situação contrária acontece no
neurônio lógico do tipo OR, no qual as entradas com
peso "0" serão mascaradas.
Para o arranjo de redes_neurais lógicas, Hirota e
Pedrycz (1994), Bailey e Ye-Hwa (1998) e Pedrycz
(2006) utilizam um módulo denominado de neurônio
ORAND ilustrado na Fig. 2.

Figura 2. Neurônio ORAND. (Pedrycz 2006).

A essência deste módulo é a associação de dois
neurônios lógicos, AND e OR, agregados por outro
neurônio OR na saída. Dada esta estrutura funcional,
as relações gerais detalhadas deste neurônio
ORAND podem ser representadas da seguinte forma

(3)

sendo S representa uma s-norma de todos os resultados das t-normas, ou seja, S  (z1 s z2 s ... s zn) em
que zi corresponde aos resultados de xi t wi. Outra
composição denominada s-norma ínfima (inf-s),
pode ser definida pela expressão
,

(5)
(6)
(7)
Quando se tem os conectores v  1 0, o resultado é um modelo de agregação tipo AND, já que o
valor "0" conectado a uma OR irá suprimir a respectiva entrada (z2). Do mesmo modo, para v  0 1,
resulta num modelo de agregação tipo OR. Já v  1
1, produz uma lógica mista entre AND e OR. Estes
ajustes de pesos ajudam a controlar a forma de inte-

(4)

sendo T representa uma t-norma de todos os resultados das s-normas, ou seja, T  (z1 t z2 t ... t zn) em que
zi corresponde aos resultados de xi s wi. Os neurônios
AND e OR são modelados a partir das composições
inf-s e sup-t respectivamente. Suas expressões podem
1233

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

ração entre as entradas e saída, trazendo uma grande
variabilidade para as redes. Como exemplo desta
versatilidade, a Fig. 3 apresenta um resultado que
mescla AND e OR nos módulos propostos por Pedrycz e Rocha (1993), Hirota e Pedrycz (1994), Pedrycz e Gomide (1998).
Do ponto de vista funcional, pode-se agregar
como entradas do módulo, os complementos
(
) das entradas diretas (x), transformando
a quantidade de entradas "n", para um total igual a
"2n".

rônios OR e a camada de saída por um único neurônio AND, tendo como resultado uma expressão conhecida como Produto de Maxitermos ou Produto da
Soma.
A segunda arquitetura, proposta por Pedrycz
(2006), é arquitetada de forma modular (multilayer),
utilizando o neurônio ORAND em cascatas como
ilustrado na Fig. 5. Neste caso, a expressão lógica
resultante em f2, é obtida após duas camadas de neurônios ORAND. Em todas as camadas da rede são
consideradas todas as entradas possíveis, incluindo as
complementares, porém, os pesos correspondentes a
cada uma delas são diferentes em cada camada. Um
conjunto de pesos para a Entrada 1 diferentes do
conjunto de pesos para a Entrada 2 irá resultar em
combinações diferentes para cada uma das entradas,
já que alguns pesos suprimem a respectiva entrada.
Pode-se então dizer que as Entradas 1 e Entradas 2
são diferentes. Além destas colocações, todas as
camadas posteriores, também terão como entrada a
saída da camada anterior. A saída f1, representa uma
entrada para a segunda camada e também possui um
peso que a conecta na rede. O número de camadas e a
quantidade de entradas em cada neurônio torna a rede
cada vez mais profunda e larga respectivamente e
isto significa maior capacidade e flexibilidade para
exprimir as expressões lógicas, porém, solicita um
esforço computacional cada vez maior.

Figura 3. Neurônio ORAND com os pesos atribuídos.
Saída y  x1x3 + (x2 + x4).

2.2 Arquitetura das Redes Lógicas
As topologias das redes lógicas propostas neste artigo utilizam os neurônios AND e OR. A primeira
topologia representa uma Soma de Mintermos, também chamada de Soma de Produtos, ilustrada na
Fig.4 abordada em Hell (2006). Esta arquitetura é
formada por h neurônios AND em sua camada intermediária e apenas um neurônio OR na camada de
saída. A saída dos neurônios AND representa uma
sequência de produtos (mintermos) unidos pelo neurônio OR que realiza a soma. A saída desta rede
fornece uma relação no mesmo formato que a expressão resultante de uma análise pelo Mapa de Karnaugh. Nesta topologia, todas as entradas do sistema,
incluindo seus complementos também serão entradas
de todos os neurônios AND, sendo que cada uma
delas possui um peso que a conecta com cada AND.
Desta forma, algumas entradas são suprimidas em
cada AND, gerando diferentes produtos. Estas saídas
também podem ser suprimidas por seus respectivos
conectores ligados ao neurônio OR. A quantidade de
neurônios da camada intermediária é determinante
para que se consiga uma rede que representa a expressão lógica. Para garantir que a rede consiga representar qualquer expressão lógica, a quantidade de
neurônios AND da camada intermediária deve ser
proporcional  quantidade de variáveis de entrada (n)
segundo a seguinte função
. Em outra
topologia semelhante também abordada por Hell
(2006), a camada intermediária é composta por neu-

Figura 4. Processador lógico do tipo Soma de Mintermos. (Hell
2006).

Figura 5. Conexão em cascata neurônios ORAND. Adaptado de
Pedrycz (2006).

2.3 Algoritmos Genéticos
Nas topologias propostas neste trabalho, todas as
entradas dos neurônios possuem conectores chamados pesos, que determinam a influência de cada entrada em relação a saída respectiva. A escolha destes
1234

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

pesos é que determina qual a função lógica representada pela rede. Esta seleção pode ser feita de modo
otimizado, utilizando Algoritmo Genético (Genetic
Algorithm), conhecido como GA, que é uma técnica
de otimização inspirada na teoria evolucionária proposta por Charles Darwin (1809 - 1882), na qual diz
que os seres melhores adaptados ao ambiente têm
maiores chances de sobrevivência e de deixar maior
número de descendentes (Linden, 2008) e (Biologia,
2013).
Estes seres selecionados reproduzem e cruzam
suas características genéticas passadas para seus
herdeiros. As características repassadas para a próxima geração podem ser aprimoradas e tornarem-se
ainda mais fortes. Geração após geração, se não
houver mecanismo que controle a diversidade, a
população tende a possuir o mesmo material genético, dificultando o processo de evolução. Uma forma
de inserir diversidade na população é a operação
mutação que tem o papel de alterar o material genético no indivíduo que passou pelo processo. Caso esta
alteração deixe o indivíduo mais apto, aumenta-se a
expectativa que este indivíduo passe a reproduzir as
alterações genéticas para as gerações futuras.
Outras formas de treinamento para as redes utilizando neurônios lógicos são encontradas na literatura, como visto em Bailey e Ye-Hwa (1998), Hell,
Costa Jr. e Gomide (2007a e 2007b), porém, a simplicidade do GA é suficiente para validar as topologias das redes_neurais lógicas.
No GA a característica genética de um indivíduo
é representada pelas variáveis da função objetivo a
ser otimizada. A população por sua vez é composta
por vários destes indivíduos gerados de modo aleatório, sendo todos avaliados a partir de uma comparação com a saída desejada. O processo de Seleção dos
indivíduos, tradicionalmente, utiliza os métodos da
Roleta e Torneio, conforme Soares (1997) e Linden
(2008).
Após esta Seleção, acontece o Cruzamento, que
é o principal mecanismo de geração de novos indivíduos, através da troca de material genético, e a Mutação, que para Soares (1997) e Pinho et al (2013), é
outro passo que introduz novas características genéticas ou mesmo restaura características perdidas ao
longo das gerações. A partir desta nova geração de
indivíduos, todos os passos anteriores serão repetidos
até que se encontre uma condição satisfatória que
interrompa este processo de criação de novas gerações. O pseudocódigo do GA utilizado neste trabalho
é apresentado na Fig. 6.

O resultado da rede lógica poderá ser comparado
com o obtido a partir do Mapa de Karnaugh segundo
a expressão, que tem como resultado
(8)
Nas topologias_de_redes propostas, o treinamento
é realizado por um Algoritmo Genético simples, com
baixo esforço computacional, com indivíduos que
representam os pesos da rede, podendo assumir os
valores "0" ou "1". Possui como principais parâmetros o número de indivíduos da população e a quantidade de gerações, sendo que outros parâmetros como
a probabilidade de cruzamento e de mutação foram
mantidos com os valores 0,7 e 0,05 respectivamente,
conforme definido por Pedrycz (2006), a partir de
sua experiência em GA.

Figura 6. Pseudocódigo do Algoritmo Genético.

Tabela 1. Tabela Verdade com 4 variáveis.

x4
x3
x2
x1
y

0
0
0
0
1

0
0
0
1
1

0
0
1
0
0

0
0
1
1
0

0
1
0
0
1

0
1
0
1
1

0
1
1
0
0

0
1
1
1
0

1
0
0
0
0

1
0
0
1
0

1
0
1
0
1

1
0
1
1
1

1
1
0
0
0

1
1
0
1
0

1
1
1
0
1

1
1
1
1
0

O desempenho f de cada indivíduo foi medido a
partir do somatório das diferenças da saída desejada
apresentada na Tabela 1, pela saída da rede lógica em
cada combinação de valores de entrada, podendo ser
representada pela equação abaixo
(9)

3 Descrição do Problema
Para compreender o que foi proposto neste trabalho,
um estudo experimental baseado no experimento 1
proposto por Pedrycz (2006), será realizado, de modo
a apresentar a função_booleana definida pela Tabela
Verdade de quatro entradas mostrada na Tabela 1.

sendo p2número de variáveis é a quantidade de combinações de entrada.
Conforme será explicado mais a frente, esta avaliação trás dificuldades, porém, é suficiente para
validar as topologias propostas. Miller (1999) utiliza
outra forma de avaliar que poderia ser empregada

1235

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

neste trabalho, porém, exigiria maior esforço computacional pela complexidade da formulação.
O método de Seleção implementado é o Torneio,
no qual é garantido que cada indivíduo terá seu desempenho comparado com outro apenas duas vezes,
sendo que na definição dos pares é mantida a aleatoriedade. Esta forma é vista como mais democrática
por garantir que todos os indivíduos possam, por
duas vezes, tentar fazer parte da nova população.
Dentre os diversos métodos de cruzamento explicitados por Soares (1997), este trabalho utilizou
apenas o método com um ponto de corte. Já no processo de Mutação, apenas foi invertido o bit, exceto
no último experimento que será explicado na próxima seção.
A criação de novas gerações é finalizada quando
o GA alcança o número máximo de gerações prédefinidas ou quando a força de algum indivíduo é
"0" (zero), já que se quer minimizar a diferença entre
as saídas da rede e a desejada.

Figura 7. Resultado do treinamento. As curvas apresentam os
valores máximo, médio e mínimo de a partir da Eq. 9, para análise
do comportamento do GA.

Com o objetivo de facilitar a execução dos algoritmos foram elaboradas interfaces gráficas a partir
de ferramentas disponíveis no Matlab (GUI, 2013),
que permite a entrada dos dados, analisar o comportamento do GA, observar os resultados na saída da
rede, seus erros e verificar a função_booleana resultante. A exibição da função dentro da interface não
contempla todas as regras de simplificação, apenas as
consideradas mais importantes para reduzir o número
de mintermos da expressão.
Aumentando a quantidade de indivíduos da população, o número de gerações para encontrar erro
zero irá reduzir, mantendo o tempo médio de execução do algoritmo. O traçado pontilhado representa a
média de erros de toda a população de indivíduos,
que é uma boa referência para definir os parâmetros
do GA, pois se conhece a diversidade de indivíduos
que a população possui.

(10)

4 Experimentos e Resultados
4.1 Rede do Processador Lógico
Nos testes para a topologia do processador lógico,
foram utilizados uma população de 700 indivíduos e
30 gerações, porém, quando o resultado desejado é
alcançado, o treinamento não mais processa as gerações restantes, por não trazer mais melhorias. Conforme já foi explicado neste trabalho, quando se tem
quatro entradas, segundo a expressão
,
serão necessários oito neurônios AND na camada
intermediária da rede, resultando em um total de 72
pesos a serem treinados. Com esta configuração em
particular, a rede sempre produziu erro zero, e em
média, após 18 gerações do GA, conforme Fig. 7, e
na pior situação de processamento, consumiu 36
segundos, apresentando como resultado a seguinte
função

4.2 Rede lógica multilayer com todas as possíveis
entradas
Nos testes para a topologia de multilayer, foram
consideradas 3 camadas de profundidade (neurônios
ORAND) e utilizados os mesmos parâmetros do GA
da topologia anterior, porém, existe maior dificuldade de treinamento, mesmo sendo 58 pesos (quantidade menor para ser ajustada), devido a profundidade e
largura desta rede, que a faz possuir uma menor
quantidade de combinações possíveis de pesos que
gera resultado ótimo.
Com esta configuração o algoritmo não conseguiu treinar a rede para erro zero, gastando 24 segundos de execução, apresentando no resultado apenas o termo
da expressão ideal. A Fig. 8 mostra
que os erros da rede ocorreram nas saídas 11, 12 e 15
da Tabela Verdade. Como forma de comprovar o
funcionamento da rede com erro zero, pode-se inserir
pesos, adquiridos após uma análise do comportamento da rede, possibilitando obter erro zero para a Tabela Verdade, comprovando seu funcionamento.

(11)
Esta função, aparentemente diferente da função
obtida pela técnica de Mapas de Karnaugh, possui o
mesmo resultado, afinal, utilizando as técnicas de
simplificação dos teoremas de Boole, é possível
verificar que as duas funções são idênticas. Outros
testes podem gerar funções aparentemente diferentes
para esta mesma tabela, porém, todas correspondem
a resultados idênticos.

1236

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

A alternativa foi desenvolver um treinamento
capaz de definir quais os pesos de cada entrada (número binário) e o sinal que deve estar em cada uma
destas entradas (número inteiro). Vale lembrar que a
partir da segunda camada, a saída da camada anterior
também deve ser considerada como uma possível
entrada.
Considerando uma rede com 2 camadas e 3 entradas por camada, pode-se arquitetar a topologia
apresentada na Fig. 9.
Definindo que a rede irá treinar uma relação lógica mostrada na Tabela 2, com 3 variáveis e considerando suas variáveis complementares, as entradas
Xa, Xb e Xc podem corresponder a 6 diferentes sinais. Já as entradas Xd, Xe e Xf podem corresponder
a 7 sinais, pois também deve ser considerado a saída
Y 1 da camada anterior.
Utilizando o GA para treinar esta rede, o indivíduo é dividido da forma apresentada na Fig. 10.

Figura 8. Saída da rede e Erro comparativo  saída desejada.

4.3 Rede lógica multilayer com entradas limitadas
Outra implementação para a topologia da rede lógica
multilayer é definida uma quantidade limitada de
entradas para os neurônios ORAND, ao invés de
todas as entradas estarem conectadas.
Foi criado um código que percorresse todas, ou
parte, das possibilidades de combinações de entradas
para cada indivíduo da população, porém, isto se
tornou computacionalmente inviável. Considerando a
rede com 2 camadas e 3 entradas por camada ilustrada na Fig. 9, e a Tabela 2, as quantidades de combinações de entrada possíveis serão


1 camada



2 camada



Combinações total  20 * 35  700.

Figura 10. Indivíduo do GA com 22 posições.

As posições destes indivíduos representados pela
letra I é um número inteiro que representa os diferentes sinais possíveis. Já a letra B é um valor binário
que representa o peso de cada entrada.
A partir da Tabela 2, a função de y pode ser extraída através das técnicas de Karnaugh, resultando
em

Considerando uma população com 500 indivíduos, em apenas uma geração, teria de ser realizada
350.000 avaliações. Se for incluída mais uma camada, este total de avaliações vai para 12.250.000 para
apenas uma geração. Ou seja, quanto mais profunda
e mais larga a rede, maior será a possibilidade de
entrada, o que torna inviável esta implementação.

(12)
Após o treinamento da rede utilizando GA, um
dos indivíduos encontrados com erro zero foi
3 5 4 0 1 1 0 1 1 1 1 2 1 7 1 0 0 0 0 0 1 0

As definições de entradas e os pesos são posicionados na rede de cima para baixo, da esquerda
para direita, uma coluna de cada vez na rede.
Analisando as condições para supressão das entradas e os teoremas booleanos para simplificação, o
resultado da saída da rede em Y2 é idêntico  Eq.12.
A estrutura do código do algoritmo_genético para
esta rede não teve grandes modificações, apenas a
criação da população com cada indivíduo possuindo
partes inteiras e partes binárias. Consequentemente, a
Mutação deverá identificar em qual parte do indivíduo será realizado o processo, onde se for um bit,
apenas inverte o valor, porém, se um valor inteiro,
deverá ser sorteado um novo número dentro das
possibilidades daquela posição.
Em comparação com a rede lógica multilayer
com todas as possíveis entradas, esta rede possui a

Figura 9. Rede em cascata com 2 camadas e 3 entradas.
Tabela 2. Tabela verdade com 3 variáveis e seus complementos.

0
0
0
0
1
1
1
1

0
0
1
1
0
0
1
1

0
1
0
1
0
1
0
1

1
1
1
1
0
0
0
0

1
1
0
0
1
1
0
0

1
0
1
0
1
0
1
0

y
0
0
0
0
1
1
0
1

1237

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

mesma dificuldade de avaliação e exige um esforço
computacional semelhante.
Tabela 3. Tabela comparativa das observações sobre as redes utilizadas nos experimentos.

Experimentos
4.1 Rede do Processador
Lógico
4.2 Rede lógica multilayer
com todas possíveis entradas
4.3 Rede lógica multilayer
com entradas limitadas

Observações
- Rede de fácil entendimento, porém, grande e com pouca flexibilidade
- Maior quantidade de pesos a serem ajustados
- GA simples com dificuldade na avaliação
- Rede com entendimento mediano, porém, reduzida e grande flexibilidade
- Menor quantidade de pesos a serem ajustados
- GA mediano com dificuldade na avaliação
- Rede com entendimento complexo, porém, mais reduzida e grande flexibilidade
- Quantidade de pesos ainda menor, porém, também necessita ajustar entradas
- GA complexo com dificuldade na avaliação
Aplicações com estas redes lógicas são interessantes em controle e automação na modelagem de
problemas como em Bailey e Ye-Hwa (1998), tendo
como ponto negativo um modelo do tipo caixa preta.

5 Conclusão
Neste trabalho foram propostos basicamente dois
tipos de redes_neurais lógicas uma baseada em multilayers de neurônios ORAND e outra de processamento baseado em Soma de mintermos. Para este
entendimento, foi necessário compreender as funções
de agregação triangulares de conjuntos_nebulosos. Os
agregadores binários t-norma e s-norma permitiram a
criação de neurônios lógicos AND e OR que posteriormente foram associados formando o neurônio
ORAND. A análise dos conectores (pesos) que interligam as entradas dos neurônios lógicos mostra
que o peso "1" suprime a entrada da AND e o peso
"0" na OR, que é extremamente necessário para se
fazer a análise correta e consequentemente a simplificação da expressão.
O experimento da subseção 4.3 buscou melhorar
o treinamento da rede multilayer e se mostrou bastante interessante do ponto de vista da arquitetura do
Algoritmo Genético, por utilizar um indivíduo com
uma característica peculiar por ser fragmentado em
partes inteiras e binárias melhorando o desempenho.
A topologia multilayer em geral se mostra bastante versátil e reduz a quantidade de pesos a serem
ajustados, porém, é mais complexo seu entendimento. Já a topologia de processador lógico organizado
na forma de soma de mintermos é de mais fácil entendimento, obtendo um bom êxito no treinamento.
Um resumo comparativo das observações de cada
experimento pode ser encontrado na Tabela 3.
O ponto crítico do experimento é treinar a rede
utilizando o Algoritmo Genético, que tem que ser
confiável e ao mesmo tempo não gerar um esforço
computacional desnecessário. Por se tratar de um
grande número de pesos binários a serem ajustados,
as quantidades de combinações são maiores que 250,
sendo que não necessariamente, um indivíduo que
possuir maior semelhança genética com o ideal, será
forte. Este é um problema bastante discreto, e como
proposta de um trabalho futuro é sugerido a utilização de um algoritmo_evolutivo mais robusto para
superar s dificuldades apresentadas no processo de
treinamento.

Agradecimentos
Nosso agradecimento a CAPES e toda equipe da
PPGEE da PUC-Minas, que viabilizaram este trabalho.
Referências Bibliográficas
Bailey, S. A.Ye-Hwa C. (1998). "A Two Layer
Network using ORAND Neuron", IEEE World
Congress on Computational Intelligence, 1998.
Biologia, S., (2013) "A Teoria de Darwin".
Disponível
em
www.sobiologia.com.br
conteudosSeresvivosCienciasbioselecaonatural
2.php (Acesso em 16122013).
Calvo, T Beliakov, G. and Pradera, A., (2007),
"Aggregation Functions A Guide for
Practitioners", Springer, Cap. 3 e 4, pp. 123220, 2007.
GUI, M., (2013). "Creating Apps with Graphical
User Interfaces in MATLAB". Disponível em
www.mathworks.comdiscoverymatlabgui.html (Acesso em 20112013).
Haykin, S. (2001). "Redes Neurais princípios e
prática", Porto Alegre. Ed. Bookman, 2 ed.
Tradução por Paulo Martins Engel.
Hell, M.B., (2006). Abordagem Neurofuzzy para
Modelagem de Sistemas Dinâmicos Não
Lineares", Programa de Pós-graduação em Eng.
Elétrica. UNICAMP, Cap. 2 p. 7-38, outubro
2006.
Hell, M. Costa Jr. P. Gomide, F. (2007a).
Recurrent Neurofuzzy Network in Thermal
Modeling of Power Transformers, IEEE Trans.
on Power Delivery, vol. 22, no. 2, Abril, 2007.
Hell, M. Costa Jr. P. Gomide, F. (2007b).
Nullneurons-based
hybrid
neurofuzzy
network, In Proceedings of Annual Meeting of
the North American Fuzzy Information
1238

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Processing Society, NAFIPS 07, pp. 331-336,
San Diego-CA, USA, Junho, 2007.
Hell, M. et al. (2009). "Uninetworks in Time Series
Forecasting", In Proc. North American Fuzzy
Information
Processing
Society
Annual
Conference, NAFIPS2009, Cincinnati, Ohio,
USA, Junho 2009.
Hirota, K. and Pedrycz, W., (1994). ORAND
neuron in modeling fuzzy set connectives,
IEEE Trans. Fuzzy Syst., vol. 2, pp. 151161,
1994.
Kandel, E. R., Schwartz, J. H.,  Jessel, T. M.
(2000). "Principles of Neural Science",
McGraw-Hill, NY, USA, 4a. edição, 2000.
Linden, R. (2008). "Algoritmos Genéticos Uma
importante
ferramenta
da
Inteligência
Computacional", Brasport, 2 ed, Rio de Janeiro,
2008.
McCulloch, W. S. and Pitts, W. H. (1943). "A logical
calculus of the ideas immanent in nervous
activity", Bulletin of Mathematical Biophysics,
5, 115133, 1943.
Miller, J. F. (1999). "An emprirical study of the
efficiency of learning boolean functions using a
Cartesian Genetic Programming approach", In
Proc. Genetic and Evolutionary Computation
Conference, pp. 1135-1142. Morgan Kaufmann,
1999.
Pedrycz, W. and Rocha, A., (1993). Knowledgebased neural networks, IEEE Trans. Fuzzy
Syst., vol. 1, pp. 254266, 1993.
Pedrycz, W. and Gomide, F., (1998). "An
Introduction to Fuzzy Sets", Analysis and
Design. Boston, MA MIT Press, 1998.
Pedrycz, W Reformat, M. and Li, K., (2006).
"ORAND Neurons and the Development of
Interpretable Logic Models", IEEE Transactions
Neural Network, vol. 17, maio 2006.
Pinho, A. F. de et al. (2013). "Meta-Heurísticas em
Pesquisa Operacional - Capítulo 2 - Algoritmos
Genéticos
Fundamentos e Aplicações",
Omnipax, Itajubá, 2013.
Rocha, A. F. (1987). "Brain as fuzzy System",
Pergamon Press, NY, USA, pp. 507507.
Soares, G.L., (1997). Algoritmos Genéticos Estudo,
Novas Técnicas e Aplicações, Programa de
Pós-graduação em Eng. Elétrica. UFMG, junho
1997.
Zadeh, L. A., (1965). "Fuzzy sets", Information and
Control, vol. 8, pp. 338-353, 1965.

1239