XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

UM ESTUDO COMPARATIVO DE CARACTERISTICAS DA FALA BASEADAS EM
WAVELETS PARA RECONHECIMENTO DE EMOCAO
Renan C. Nascimento, Daniel C. Cavalieri, Luiz A. Pinto, Alberto F. de Souza, Karin
S. Komati


Coordenacao de Informatica - Instituto Federal do Esprito Santo (IFES) campus Serra





Coordenacao de Automacao - Instituto Federal do Esprito Santo (IFES) campus Serra
Rodovia ES-010, Km 6,5, Manguinhos, Serra, ES - Brasil. 29173-087

Departamento de Informatica, Universidade Federal do Esprito Santo (UFES) campus Goiabeiras
Av. Fernando Ferrari, 514, Goiabeiras, Vitoria, ES - Brasil. 29075-910
Emails renan@costanascimento.com.br, daniel.cavalieri@ifes.edu.br,
luiz.pt@ifes.edu.br, alberto@lcad.inf.ufes.br, kkomati@ifes.edu.br
Abstract Emotional features extracted from a voice signal can improve the performance of speech recognition
systems. In this work, a comparative study of speech features based on wavelet families is proposed in order
to determine which family has the highest accuracy and sensitivity in recognizing speech emotions. To do so,
several wavelets families are used to extract features from a  of emotional speech, EmoDB (Berlin of
Emotional Speech). The feature extraction experiments cover seven wavelets families in seven different values of
decomposition levels, using the Discret Wavelet Transform. Finally, confusion matrices were generated, as well
as the measures Precision, Recall and F-measure were calculated in order to analyze the responses of emotion
recognition of different families and levels. At the end, the waveletlevel combination that achieved the best
performance was Coif1 with 20 levels of decomposition. Other interesting result is that the best performance of
the automatic recognition is achieved for the emotion of sadness, regardless of the wavelet family, being much
better than the result of human perception. In contrast, for the anger emotion, human perception is much better
than the automatic system.
Keywords

Speech Emotion Recognition, Discrete Wavelet Transform, Berlin Emotional .

Resumo Caractersticas emocionais extradas de um sinal de voz podem melhorar o desempenho de sistemas
de reconhecimento_de_fala. Neste trabalho, propoe-se um estudo comparativo de caractersticas da fala, extradas
atraves de famlias de wavelets, a fim de determinar qual das famlias possui a maior precisao e sensibilidade
no reconhecimento das emocoes e, alem disso, comparar os resultados do sistema automatico com os resultados
da percepcao humana. Para isso, o trabalho utiliza o banco_de_dados de vozes, EmoDB (Berlin of Emotional
Speech), classificadas quanto as seguintes emocoes humanas raiva, desgosto, medo, alegria, tristeza, tedio e
neutro. A extracao_de_caractersticas dos experimentos compreenderam sete famlias de wavelets em sete diferentes
valores de nveis de decomposicao, usando a Transformada Wavelet Discreta. Coletou-se os seguintes resultados
quantitativos as matrizes de confusao, as medidas Precision (precisao), Recall (sensibilidade) e F-measure
para analisar comparativamente as respostas do reconhecimento de emocoes das diferentes famlias e nveis. Ao
final, a combinacao de waveletnvel que obteve o maior valor medio de F-measure (0,78) foi o Coif1 com 20
nveis de decomposicao. Outro resultado interessante e que o reconhecimento automatico obteve resultado mais
eficiente que o resultado da percepcao humana para a emocao de tristeza, independente da famlia wavelet. Em
compensacao, a percepcao humana reconhece a emocao raiva melhor que o sistema automatico.
Palavras-chave
.

1

Reconhecimento de Emocao na Fala, Transformada wavelet discreta, Berlin Emotional

Introducao

Uma das formas mais naturais de interacao entre
seres humanos e a fala. De todas as formas de
comunicacao utilizadas por seres humanos, a fala e
uma das mais rapidas, e sua agilidade fez com que
esse meio de comunicacao fosse bastante utilizado
para implementar a interacao do ser humano com
maquinas.
No entanto, essa interacao homem-maquina
nao e tao natural quanto a interacao entre duas
pessoas. Um dos motivos e que para que o entendimento da fala seja completo e preciso mais do
que o significado da palavra falada, pois a forma
como ela e expressa contem uma grande quantidade de informacoes necessarias para o entendimento (Nicholson et al., 1999). Atraves da expres-

ISSN 2525-8311

sao de emocoes na fala e possvel distinguir, por
exemplo, a expressao bem feito com o significado
positivo de trabalho bem realizado e do significado negativo de prazer ao ver uma outra pessoa
sendo prejudicada. Esse e apenas um dos inumeros casos em que emocoes sao essenciais para o
entendimento mutuo de uma conversacao.
Aplicacoes que necessitam de interacao natural entre homem e maquina podem ser beneficiadas com o reconhecimento de emocoes na fala,
principalmente aquelas em que a resposta do sistema depende da emocao expressa pelo usuario.
Em (Schuller et al., 2004), um sistema de carro
detecta o estado mental do motorista, de maneira
que o sistema possa iniciar procedimentos que visem a seguranca do condutor. Ja em (France
et al., 2000), a tecnologia foi utilizada para de-

2854

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

terminar casos de depressao e potenciais riscos de
suicdio em pacientes. Alem disso, no trabalho
de (Hansen and Cairns, 1995) apresenta sistemas
de reconhecimento_de_voz para identificacao de
estresse em cabines de aeronaves. O reconhecimento de emocoes da fala tambem foi utilizado
para adaptar a resposta de sistemas de call center ao detectar frustracao ou aborrecimento da
voz do cliente (Ma et al., 2006).
Apesar da grande utilidade existente no reconhecimento de emocoes na fala, El Ayadi e colegas
(2011) citam diversas questoes que tornam a tecnologia bastante desafiadora. Uma delas e que nao
se conhece exatamente quais sao as caractersticas
da fala que possuem maior impacto para reconhecer determinadas emocoes. Alem disso, e possvel
que haja mais de uma emocao em um unico sinal
de voz, em que cada emocao esta presente em um
diferente trecho da fala. Essa caracterstica torna
trabalhosa a tarefa de identificar qual trecho de
voz carrega uma determinada emocao. Por fim,
emocoes iguais podem ser expressas de maneiras
diferentes dependendo do falante, seu sotaque e
sua cultura.
Nesse contexto, este trabalho propoe um estudo comparativo de extracao_de_caractersticas
baseadas em wavelets (Graps, 1995 Mallat, 2008)
variando a famlia e os nveis de decomposicao
para reconhecimento de emocoes da fala, a fim
de determinar qual das famliasnveis sao as que
possuem melhor desempenho, isto e, apresentam
melhor combinacao das medidas estatsticas de
precisao e sensibilidade. Escolheu-se como base de
dados de entrada, o EmoDB - Berlim of Emotional
Speech (Burkhardt et al., 2005), que possui audios
com sete emocoes Raiva, DesgostoNojo, Medo,
Alegria, Tristeza, Tedio e Neutro. Cada audio
possui apenas uma unica classificacao de emocao,
logo, nao ha variacao de emocao no mesmo audio.
2

Figura 1 Arquitetura generica de sistemas de reconhecimento de emocao da fala.
intuito de garantir qualidade das emocoes expressas nos audios verbalizadas por atores profissionais, logo, nao ha a necessidade da etapa de preprocessamento para retirada de rudos ou melhoria
do audio.
Este trabalho foca apenas na questao de qual
e o melhor conjunto de caractersticas baseada
em Wavelets, mantendo todas as demais etapas
identicas. Deciciu-se tambem que nao haveria a
selecao (diminuicao) de caractersticas e se manteria sempre o mesmo classificador, isto e, mantendo todo o sistema inalterado variando apenas a etapa de extracao_de_caractersticas baseada em Wavelets. A classificacao ocorreu atraves
do algoritmo LDA (Linear Discriminant Analysis) (Balakrishnama et al., 1999). A arquitetura
do sistema de testes deste trabalho e apresentada
na Figura 2.

Metodologia e Referencial Teorico

Sistemas de reconhecimento de emocoes comumente possuem 4 (quatro) etapas de processamento pre-processamento, extracao_de_caractersticas, selecao de caractersticas e classificacao de
caractersticas. A Figura 1, traduzida de (Bhatti
et al., 2004), ilustra a arquitetura generica deste
tipo de sistema.
A entrada dos dados do sistema e uma base
de dados composta de diversas gravacoes da
fala humana expressando diferentes emocoes, a
Berlin  of Emotional Speech (EmoDB)
(Burkhardt et al., 2005), que possui 535 audios.
Sua escolha se deu por dois motivos por ser uma
base de dados publica e gratuita, e por ter sido utilizada em diversos trabalhos correlatos, tais como
em (Kotti and Paterno, 2012 Pan et al., 2012). A
EmoDB foi desenvolvida seguindo rigorosos testes de gravacao e validacao de seus dados com o

ISSN 2525-8311

Figura 2 Arquitetura do sistema de testes.

2.1

Extracao de Caractersticas

A extracao_de_caractersticas e a fase em que os
audios sao analisados e um conjunto de descritores
e extrado, de modo que possa ser posteriormente

2855

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

utilizado para classificar as emocoes. Ha diversas tecnicas e algoritmos que possibilitam a extracao_de_caractersticas, como a Fourier Transform
e Wavelet Transform.
Wavelets sao funcoes que satisfazem certos requisitos matematicos e sao usadas para representar dados e outras funcoes, semelhante a Fourier.
O processamento de wavelets processa dados em
diferentes escalas e resolucoes, permitindo que sejam vistos tanto as informacoes globais quanto
os detalhes de um sinal. Uma wavelet, diferentemente de senos e cossenos, base da analise de Fourier, tem duracao limitada. Alem disso, enquanto
senoides sao suaves e previsveis, wavelets tendem
a ser irregulares e assimetricas (Graps, 1995).
O procedimento da analise wavelet e realizada
atraves da adocao de uma funcao base, ou ainda
uma mother wavelet. Os coeficientes sao ordenados em dois padroes dominantes, implementados
por bancos de filtros. O primeiro padrao suaviza
o sinal, enquanto o segundo mostra os detalhes
do mesmo. A decomposicao do sinal e feita em
duas partes iguais, uma contendo os coeficientes
do detalhe, e a outra os coeficientes de aproximacao. A decomposicao e entao reaplicada na parte
suavizada, dividindo o sinal em outras duas partes iguais, detalhe e suavizacao. Cada iteracao do
processo representa um nvel, ao final do processo
teremos decomposto o sinal em J+1 caminhos diferentes, em que J e a quantidade de nveis escolhido para executar o processo.
Foram realizadas extracoes utilizando sete famlias de wavelets e sete nveis de decomposicao
diferentes (5, 10, 15, 20, 25, 30 e 35) - totalizando
49 (quarenta e nove) diferentes conjuntos de caractersticas para cada um dos 535 audios da base de
entrada. Para cada nvel, calcula-se quatro caractersticas - energia, entropia, variancia e comprimento de onda. As seguintes famlias de wavelets
foram escolhidas para a extracao_de_caractersticas
 Biorthogonal Bior2.8 e Bior3.9
 Coiflets Coif1 e Coif5

Figura 3 Exemplo de uma matriz de confusao
Bior3.9 com 30 nveis de decomposicao.
Por fim, graficos foram gerados com o intuito de
melhor visualizar e comparar o desempenho das
waveletsnveis, estes graficos serao detalhados na
secao seguinte.
3

Experimentos, Resultados e Discussao

Todo o sistema para a execucao dos testes foi desenvolvido usando a ferramenta Matlab e o codigo
de extracao_de_caractersticas DWT foi baseado no
sistema de Kushaba (2013).
Foram feitas tres analises avaliacao de
qual(is) e(sao) o(s) melhor(es) nvel(is) de decomposicao, avaliando qual a melhor combinacao famlianvel e comparando-se os resultados do sistema automatico com os resultados da percepcao
humana.
3.1

Avaliacao por nvel de decomposicao

Um dos graficos gerados para cada experimento
foi o grafico de linha, um exemplo e mostrado na
Figura 4. O grafico apresentado mostra o resultado de F-measure para a famlia Biorthogonal
(Bior2.8 em azul e Bior3.0 em vermelho), e nesse
caso para a emocao da tedio. Seu eixo x representa o nvel de decomposicao utilizado no algoritmo de extracao, ja o eixo y indica o F-measure
resultante desse nvel. Por fim, sao tracadas um
numero de linhas igual a quantidade de wavelets
utilizadas da famlia analisada.

 Daubechies Db2, Db6 e Db8
2.2

Medidas Estatsticas

Para cada um dos 49 (quarenta e nove) conjuntos
de caractersticas, coleta-se o resultado do classificador sob a forma de matrizes de confusao. Um
exemplo da matriz de confusao gerada para cada
experimento e mostrada a seguir
Cada linha da matriz representa a emocao real
e cada coluna a emocao reconhecida pelo sistema.
Assim, quanto maior o valor na diagonal principal,
melhor foi o resultado.
Com base nas matrizes de confusao, e possvel
calcular as medidas precision, recall e F-measure.

ISSN 2525-8311

Figura 4 Exemplo de um grafico de linha para
famlia Biorthogonal na emocao Tedio.

2856

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

Independente da famlia e emocao, os graficos apresentaram os melhores resultados para os
nveis 20 e 25. Em quase todos os graficos, as curvas comecam com valores menores, passam por
um pico e depois tem a tendencia a diminuir o Fmeasure. Logo, para as secoes posteriores, manteremos as discussoes focadas apenas nestes dois
nveis.
3.2

nveis.

Em busca da melhor famlia

O objetivo dos graficos de radar da Figura 5 e
mostrar os valores de F-measure alcancados pelos melhores nveis de decomposicao (20 e 25) em
cada uma das emocoes estudadas. Cada radar representa uma emocao e possui sete eixos, duas linhas e catorze pontos. Os eixos representam as
wavelets utilizadas na etapa de extracao_de_caractersticas, ja as duas linhas indicam os nveis
que foram utilizados nesse experimento, por fim,
os pontos representam oF-measure alcancado pela
combinacao waveletnvel.
Comecando pelo grafico de alegria (Figura
5(a)), os melhores resultados sao obtidos pelo nvel
25, pois os pontos do nvel 25 estao mais afastados
do centro do que os do nvel 20. Ha uma excecao,
para a wavelet DB2 que e melhor no nvel 20. A
disparidade entre os dois nveis e melhor observada para a wavelet Coif5. Essa mesma wavelet,
no nvel 25, e responsavel pelo melhor resultado,
junto a Bior2.8 nos dois nveis. Coif1 e Bior3.9,
ambas no nvel 20, alcancam o pior desempenho
para a emocao.
Contrariamente ao ocorrido no radar de alegria, os valores de F-measure alcancados pelo nvel
20 no radar de desgosto sao maiores do que aqueles
alcancados pelo nvel 25, independente da wavelet.
Ha uma excecao, no entanto, a Bior3.9 com 25 nveis e levemente superior a Bior3.9 com 20 nveis.
Nao so isso, como tambem e essa a combinacao de
waveletnvel que possui o melhor F-measure para
a emocao de desgosto. Quanto a pior combinacao,
e difcil precisar, uma vez que, de modo geral, as
wavelets alcancaram desempenhos similares.
As emocoes de raiva e tristeza foram aquelas
que obtiveram os melhores resultados, independente de wavelet ou nvel. Tambem foi visto que,
para raiva, a quantidade de nveis pouco influenciava no desempenho final do classificador. Observando a Figura 5(c), o resultado independe da
wavelet utilizada para raiva.
Na Figura 5(d), de tristeza, o nvel 20 se destaca sobre os resultados do nvel 25, na maioria
das wavelets. A diferenca entre os dois nveis
pode ser observada mais facilmente para as wavelets Bior2.8, Coif5 e Db8. Com relacao a wavelet
que melhor representa a emocao, o melhor resultado e dada pela Coif1 com 20 nveis, seguido da
Db6 com 25 nveis e Bior2.8 com 20 nveis. Ja a
pior classificacao fica por conta da Coif5 com 25

ISSN 2525-8311

Figura 5 Graficos de radar que exibem o Fmeasure alcancado por todas as famlias, com os
nveis 20 e 25, para todas as emocoes.
As duas emocoes seguintes, ansiedade e tedio,
possuem graficos semelhantes em alguns pontos e
diferentes em outros. Sua semelhanca se da na
proximidade dos valores de F-measure alcancados
pelos nveis 20 e 25 para cada wavelet. No entanto
essa proximidade nao ocorre em todos os casos.
Para a emocao de ansiedademedo a disparidade
ocorre na Coif5, em que a linha dos 25 nveis e
superior a dos 20 nveis. Ja para o tedio essa diferenca ocorre principalmente na Bior2.8, mas dessa
vez e a linha dos 20 nveis que apresenta melhores
resultados que 25 nveis. Com relacao as wavelets
que obtem os melhores resultados para as emocoes, a famlia Coiflets merece destaque, uma vez
que o sentimento de ansiedade foi melhor representado por seus integrantes, Coif1 e Coif5, ambas com 25 nveis. Ja para o tedio, a wavelet que

2857

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

se destaca e a Bior2.8 com 20 nveis. De maneira
geral o nvel que melhor representa a emocao de
ansiedademedo e o 25, enquanto que os melhores
resultados do tedio sao alcancados pelo nvel 20.
A ultima emocao a ser analisada, neutro, nao
apresenta superioridade clara de um nvel para outro conforme vem acontecendo com os outros sentimentos. Em alguns momentos, o nvel 20 obtem
os melhores resultados para determinada wavelet,
como para as Bior2.8 e Db6, e em outros casos e
o nvel 25 que e superior, como para Coif5, Db2 e
Db8. De maneira geral ve-se que todas as wavelets obtiveram resultados semelhantes, mas e necessario dar destaque para a famlia Daubechies,
que com duas representantes, Db6 com 20 nveis e
Db8 com 25 nveis, conseguiu o melhor F-measure
emparelhada com a Coif5 com 25 nveis. Curiosamente, a famlia Daubechies tambem conseguiu
as piores classificacoes atraves de Db2 e Db8 com
20 nveis em ambas.
Para analisar os F-measures obtidos por todas
as wavelets em seus melhores nveis e para todas
as emocoes, foram somados todos os valores de Fmeasures, denominado de F-measure cumulativo.
A combinacao de maior F-measures acumulado foi
a wavelet Coif1 com 20 nveis com F-measure acumulado de 5,48.
3.3

de tristeza nao era esperada, ja que os resultados
obtidos em todas as outras emocoes foram bons.
Como a percepcao humana para a emocao de desgosto apresenta baixo desempenho, a disparidade
homem-maquina foi pequena para as combinacoes
Bior3.9 com 25 nveis, e Db2 com 20 nveis. Ambas aproximaram-se bastante do desempenho humano, mas a Bior3.9 apresentou resultados melhores, similar ao resultado obtido pelos humanos.

Comparacao com a Percepcao Humana

A EmoDB fornece os resultados de experimentos
(via medida Precision) feitos com seres humanos.
Essa secao visa comparar os resultados da percepcao humana com os resultados obtidos por cada
uma das waveletsnvel deste trabalho.
Para isso, foram criados sete graficos de radar (Figura 6), em que cada radar representa uma
wavelet. Alem disso, cada grafico possui 7 (sete)
eixos, 3 (tres) linhas e 21 (vinte e um) pontos. Os
eixos representam as emocoes estudadas, ja as linhas indicam os nveis que foram utilizados nesse
experimento (20 - laranja e 25 - cinza) e a taxa de
percepcao humana (azul), por fim, os pontos representam o precision alcancado por um nvel em
uma determinada emocao, ou ainda a taxa de percepcao humana alcancada em uma determinada
emocao. Note que a curva da percepcao humana
e a mesma em todos os graficos.
Para a maioria das emocoes, a taxa de reconhecimento humana supera, em muito, o desempenho do sistema de reconhecimento. No entanto
ha duas excecoes relevantes que precisam ser destacadas tristeza e desgosto. A primeira delas
pode ser vista em todos os graficos, independente
da wavelet ou nvel sob analise a superioridade
do sistema de reconhecimento para a emocao de
tristeza. A disparidade entre o sistema e a percepcao humana e bastante consideravel em todos
os casos, mas em especial para Coif1. Essa dificuldade do ser humano em perceber a emocao

ISSN 2525-8311

Figura 6 Graficos de radar que exibem o precision
alcancado por todas as famlias, com os nveis 20 e
25, assim como o grau de percepcao humana para
cada emocao.
Outra emocao em que o sistema conseguiu
bons resultados, em algumas combinacoes, em relacao ao reconhecimento humano foi a ansiedade.
As wavelets Bior2.8 e Coif1 com 20 nveis, assim
como a Coif5 com 25 nveis conseguiram resultados similares ao da percepcao humana. No entanto, a Coif1 com 25 nveis superou, por pouco,
o desempenho humano.
A percepcao humana conseguiu resultados
muito superiores para a raiva, e tambem ocorre
nos tres sentimentos restantes alegria, neutro e
tedio. A grande diferenca para a alegria ja era esperada, uma vez que o sistema automatico obteve
seus piores resultados para esse sentimento.

2858

XXI Congresso Brasileiro de Automática - CBA2016
UFES, Vitória - ES, 3 a 7 de outubro

O maior valor de Precision acumulado foi alcancado por Coif5 com 25 nveis (4,55), mas e menor que o desempenho da percepcao humana, Precision de 5,19.
4

Consideracoes Finais

O objetivo deste trabalho foi comparar conjuntos de caractersticas baseadas em wavelets com
o intuito de verificar o comportamento destas no
reconhecimento de sete emocoes expressas na fala.
Os resultados obtidos mostram que no geral, independente da wavelet ou nvel utilizado, o melhor
desempenho do reconhecimento e alcancado para
as emocoes de tristeza, seguida pela raiva. Por
outro lado, as emocoes que tem a pior taxa de
reconhecimento sao a alegria, seguida pelo tedio.
Com relacao aos nveis de decomposicao, valores dos extremos da faixa analisada, os mais baixos ou os mais altos, nao obtem bom desempenho,
sendo 20 e 25 os nveis que apresentaram os melhores resultados, independente da famlia. Em
termos de famlia, os melhores resultados foram
obtidos pela famlia Coiflets. Ao final, a combinacao de waveletnvel que alcancou o melhor
desempenho foi Coif1 com 20 nveis de decomposicao.
Comparando-se com a percepcao humana, o
sistema automatico e bem melhor para reconhecimento de tristeza, enquanto o ser humano e melhor para o reconhecimento da raiva.
Como trabalhos futuros, pretende-se avaliar
os resultados para bases de dados em outros idiomas, comparar outras tecnicas de extracao_de_caractersticas, implementar a etapa de selecao de
caractersticas, utilizar outros classificadores e implementar a validacao cruzada.
Referencias
Balakrishnama, S., Ganapathiraju, A. and Picone, J. (1999). Linear discriminant analysis for signal processing problems, Southeastcon99. Proceedings. IEEE, IEEE, pp. 7881.
Bhatti, M. W., Wang, Y. and Guan, L. (2004). A
neural network approach for human emotion
recognition in speech, Circuits and Systems,
2004. ISCAS 04. Proceedings of the 2004 International Symposium on, Vol. 2, pp. II
1814 Vol.2.
Burkhardt, F., Paeschke, A., Rolfes, M., Sendlmeier, W. and Weiss, B. (2005). A 
of german emotional speech, in Proceedings
of Interspeech, Lissabon, pp. 15171520.
El Ayadi, M., Kamel, M. S. and Karray, F. (2011).
Survey on speech emotion recognition Features, classification schemes, and s,
Pattern Recogn. 44(3) 572587.

ISSN 2525-8311

France, D. J., Shiavi, R. G., Silverman, S., Silverman, M. and Wilkes, M. (2000). Acoustical
properties of speech as indicators of depression and suicidal risk, IEEE Transactions on
Biomedical Engineering 47(7) 829837.
Graps, A. (1995). An introduction to wavelets,
IEEE Comput. Sci. Eng. 2(2) 5061.
Hansen, J. H. L. and Cairns, D. A. (1995). Icarus
Source generator based real-time recognition
of speech in noisy stressful and lombard effect
environments, Speech Commun. 16(4) 391
422.
Khushaba, R. (2013). Feature extraction using
multisignal wavelet transform decomposition.
URL httpwww.mathworks.commatlabcentralfileexchange37950-featureextraction-using-multisignal-wavelettransform-decomposition
Kotti, M. and Paterno, F. (2012). Speakerindependent emotion recognition exploiting a
psychologically-inspired binary cascade classification schema, International Journal of
Speech Technology 15(2) 131150.
Ma, J., Jin, H., Yang, L. T. and Tsai, J. J. P. (eds)
(2006). Ubiquitous Intelligence and Computing, Third International Conference, UIC
2006, Wuhan, China, September 3-6, 2006,
Proceedings, Vol. 4159 of Lecture Notes in
Computer Science, Springer.
Mallat, S. (2008). A Wavelet Tour of Signal Processing, Third Edition The Sparse Way, 3rd
edn, Academic Press.
Nicholson, J., Takahashi, K. and Nakatsu, R.
(1999). Emotion recognition in speech using
neural networks, Neural Information Processing, 1999. Proceedings. ICONIP 99. 6th International Conference on, Vol. 2, pp. 495
501 vol.2.
Pan, Y., Shen, P. and Shen, L. (2012). Speech
emotion recognition using support_vector_machine, International Journal of Smart Home
6(2) 101108.
Schuller, B., Rigoll, G. and Lang, M. (2004). Speech emotion recognition combining acoustic
features and linguistic information in a hybrid support_vector_machine-belief network
architecture, Acoustics, Speech, and Signal Processing, 2004. Proceedings. (ICASSP
04). IEEE International Conference on,
Vol. 1, pp. I57780 vol.1.

2859