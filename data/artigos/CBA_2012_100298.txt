Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

CONTROLE DE POSIÇÃO FINAL COM ORIENTAÇÃO PARA CONDUÇÃO DE PESSOAS
M ILTON C ÉSAR PAES S ANTOS F LÁVIO G ARCIA P EREIRA R AQUEL F RIZERA VASSALLO
 Universidade Federal do Espírito Santo
Av. Fernando Ferrari, 514, Goiabeiras, Vitória  ES  Brasil. CEP. 29075-910
 Centro

Universitário Norte do Espírito Santo
Rodovia BR 101 Norte, km 60, Bairro Litorâneo, São Mateus  ES  Brasil. CEP 29932-540
Email milton.santos@ele.ufes.br, flaviogarcia@ceunes.ufes.br, raquel@ele.ufes.br
Abstract This paper presents a nonlinear position controller applied to a mobile robot in order to guide a person to a certain
destination spot with desired heading. The robot is equipped with an omnidirectional vision system, which is used to classify and
determine the location of the legs of a person in the environment. Thus, the robot can find people who wish to be guided and
estimate features such as the their velocity and their distance from the robot used to accomplish the guiding task. The method
presented in this paper uses the technique of background subtraction to detect a person and hisher apparent motion in the image
to perform visual tracking. Then we recover the three dimensional coordinates of the persons legs using polynomials that relate
points in the the image with points in the 3D world. According to the persons coordinates, the robot can make adjustments in the
position controller in order to adapt its linear and angular velocities to the walking ability of the person. In order to validate the
proposed method, some experiments were performed and are shown in this paper.
Keywords Human-Robot Interaction, Nonlinear Guidance Controller.
Resumo Este trabalho apresenta um controlador de posição não-linear aplicado a um robô_móvel a fim de conduzir uma pessoa
até um local desejado com uma orientação específica. O robô é equipado com um sistema de visão omnidirecional, que é usado
para classificar e determinar a localização das pernas de uma pessoa no meio_ambiente. Assim, o robô pode encontrar pessoas que
desejam ser conduzidas e estimar variáveis, tais como a distância entre o robô e a pessoa que está sendo conduzida. O método
apresentado neste trabalho utiliza a técnica de subtração_de_fundo para detectar uma pessoa e seu movimento aparente na imagem
para realizar o acompanhamento visual. Em seguida, recuperam-se as coordenadas tridimensionais das pernas da pessoa usando
polinômios que se relacionam com pontos na imagem com pontos no mundo 3D. De acordo com as coordenadas da pessoa, o robô
pode fazer ajustes no controlador de posição, a fim de adaptar as suas velocidades linear e angular para a capacidade de locomoção
da pessoa. A fim de validar o método proposto, alguns experimentos foram realizados e são mostrados neste trabalho.
Palavras-chave

.

Introdução

Atualmente, a maioria dos robôs são usados em aplicações industriais onde suas principais tarefas são na
execução de tarefas repetitivas, em montagens, em
sistemas de alta precisão. No entanto, com o intuito de desenvolver robôs capazes de ajudar pessoas
e até mesmo executar tarefas em conjunto com elas,
um grande esforço tem sido feito para desenvolver
robôs capazes de auxiliar pessoas em residências, museus, hospitais e outros lugares públicos, os chamados
Robôs de Serviço.
Em buscas da realização desses serviços,
encontram-se muitas pesquisas direcionadas s aplicações relacionadas com a vida cotidiana, onde é
necessário a cooperação de robô(s) com uma ou mais
pessoas na execução de tarefas, tais como manipulação cooperativa (Takubo et al., 2002), transporte de
cargas (Pereira et al., 2010), e, ainda, campeonatos
responsáveis por desenvolver tecnologias e apresentar
resultados em ambientes realistas, ou seja, ambientes
que simulam casas não padronizadas. Neste contexto,
o campeonato RoboCup@Home apresenta resultados
de grande relevância para futuras aplicações domésticas. E uma das principais tarefas apresentadas neste
campeonato é a tarefa de seguimento de pessoas e
navegação em ambientes dinâmicos.
Neste trabalho trabalhou-se a idéia de condução
de pessoas que é uma questão interessante para a ro-

ISBN 978-85-8001-069-5

bótica de serviço, principalmente quando se considera
a capacidade de andar da pessoa, ou seja, o robô não
deve apenas guiá-la, mas deve se mover de acordo
com a mobilidade da mesma. Por exemplo, se o robô
está guiando uma criança, um adulto, um idoso ou alguém com mobilidade reduzida, ele deve movimentarse respeitando a velocidade com que a pessoa guiada
se move.
Para ser capaz de realizar tal tarefa, é importante obter informações tanto do ambiente em que
o robô está inserido quanto da distância da pessoa
para o robô. É possível obter essas informações por
meio de dados de fusão de diferentes tipos de sensores ou usando um único sensor, como um sistema
de visão omnidirecional (Grassi-Junior and OkamotoJunior, 2006). A vantagem de usar um sistema de visão omnidirecional é que ele pode capturar imagens
com um campo de visão de 360o na horizontal, o que
permite a visualização de toda a área em torno do robô.
Assim, neste trabalho, propõe-se um controlador
de posição final com orientação a fim de conduzir pessoas até um determinado ponto de acordo com sua capacidade de andar. Para isso, o robô utiliza um sistema
de visão omnidirecional para detectar a pessoa e estimar sua posição. O controlador de condução proposto
é baseado em um controlador de posição não-linear
que inclui a informação adicional da mobilidade da
pessoa. A Figura 1 (a) apresenta um exemplo do controle sem orientação final (Pereira et al., 2011). A Fi-

214

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

gura 1 (b) mostra a modificação para o controlador de
posição final proposta neste artigo.

(a)

(b)

Figura 1 Robô chegando a um ponto sem controle de
orientação final (a) e com orientação final (b).
O restante deste trabalho está organizado da seguinte forma A Seção 2 apresenta o ajuste para o
controlador de posição com orientação final proposto
neste trabalho enquanto a Seção 3 mostra o sistema de
visão utilizado e a técnica empregada para detectar e
rastrear uma pessoa. Os resultados experimentais são
apresentados na Seção 4. Conclusão e propostas para
trabalhos futuros são discutidos na Seção 5.

2

são dadas por


 x  v.cos()
y  v.sen()


  ,

onde x e y são as coordenadas do robô, v e  são, respectivamente, as velocidades linear e angular do robô.
O ângulo  representa a orientação do robô com relação ao referencial inicial.
No entanto, para ajustar o controlador de posição com orientação final, é necessário representar
a posição do robô através da sua coordenadas polares (Secchi, 1998). Para isso, considerando ,  e ,
respectivamente, o erro de posição, o erro orientação
do robô com respeito um sistema de coordenadas final
<g> e o erro de orientação com relação a orientação
final desejada, a Equação 1 pode ser reescrita como

  v cos ()



sen ()

   + v
,



sen
()

   v


v


 ks tanh() cos()


tanh sen
2
.
.cos
 k .  + k .  + h .ks .


tanh
+ks .
.sen.cos,


com ks > 0, kw > 0, e k , k > 0. Nestas equações,
kv representa o valor máximo da velocidade linear, k
é ajustado para regular o valor máximo da velocidade
angular e k , k são ajustados pele Equação 3.

max   k .  + k . + h .ks ..0, 5
(3)
Com base no controlador descrito pela Equação 3
e considerando agora uma pessoa que segue o robô,
propõe-se uma função (.) para saturar a velocidade
máxima linear do robô. Isto é, a constante ks é substituída por Kv (.) tal que Kv (.)  Kv (.). A função (.)
depende da distância entre o robô e a pessoa guiada.
Assim, a função (d) toma a forma
(d) 

Figura 2 Coordenadas do robô e da pessoa que está
sendo conduzida.
O robô utilizado neste trabalho é do tipo monociclo, assim as equações cinemáticas, que descrevem
o movimento do mesmo, em coordenadas cartesianas,

ISBN 978-85-8001-069-5

(2)

Com base nesse sistema, as ações de controle necessárias para o robô navegar para um ponto específico
são representadas por

O Controlador Proposto

Considerando o caso onde um robô_móvel tem de
guiar uma pessoa para um ponto desejado, o principal
objetivo do controlador proposto é gerar valores adequados para as velocidades linear e angular que devem
ser desempenhadas pelo robô a fim de realizar a tarefa
de condução. Estas velocidades devem ser calculadas
com base na distância do robô até o ponto alvo e de
acordo com o movimento da pessoa guiada. Assim,
é importante mencionar que para calcular tais velocidades, a distância entre o robô e da pessoa, a qual é
obtida a partir das imagens omnidirecionais e a postura do robô com respeito ao ponto desejado têm que
ser estimadas. A Figura 2 ilustra um robô_móvel navegando para atingir a meta e uma pessoa seguindo-o.

(1)

1  k tanh((d  dm))
+ 0 > 0
2

(4)

onde dm é a distância de referência, k é uma constante que limita os valores da tangente hiperbólica,  e
0 são constantes positivas e d é a distância atual entre
a pessoa e o robô.
Assim, substituindo kv  Kv (d), tem-se que as novas ações de controle são definidas como
v

 Kv tanh() cos()
 kv .(d) tanh() cos()

(5)

215

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.



2.1



tanh sen
2
 k .  + k .  + h .Kv .
.
.cos


tanh
+Kv .
.sen.cos



tanh
2
 k .  + k .  + kv .(d).
.sen.cos

tanh sen
+h .kv .(d).
.
.cos.
(6)


Análise da Estabilidade

Para provar a estabilidade do controlador não_linear
proposto, a seguinte candidata função de Lyapunov é
considerada
1
1
1
V(,,)  .h .2 + 2 + .h .2 ,
2
2
2

(7)

com h , h > 0. A qual é definida positiva, radialmente
limitada, V (0, 0, 0)  0,V(,,) > 0para, ,  > 0 e
sua derivada temporal é

isso, adota-se 0 < k < 1 e 0 > 0, assim a função (d)
teria o seguinte comportamento.
(d) 

1  k tanh((d  dm))
+ 0
2
0<.<1

(d) 

.1



z z
1  k tanh((d  dm))
+ 0
2
0<.<1



z
1  k tanh((d  dm))
(d) 
+ 0
2
(d) > 0
Assim, tem-se que V (, , ) é definida negativa,
o que significa   0,   0 e   0 quando t 
 provando a estabilidade assintótica do sistema de
controle proposto.
3

Sistema de Visão e Detecção de Pessoas

O ajuste do controlador de posição apresentado na Seção 2 depende de quatro variáveis que determinam as
V  h .. + . + h ...
(8)
ações de controle. Uma delas é a distância entre o
robô e a pessoa que lhe segue. Esta distância é obtida
Substituindo os valores de ,  e  da Equação 2
por processamento_de_imagens dadas por um sistema
na Equação 8, tem-se
de visão omnidirecional montado sobre o robô. Estas imagens tem um campo de visão de 360o na horiV  h ..(v.cos) +
z


zontal. Nesse contexto, esta seção tem como objetivo
V1
mostrar como essa distância é estimada, enquanto o




sen
robô guia a pessoa.
v.
+ .  + v. sen
+
h
..
.
(9)




z

A detecção pessoa é realizada por um método de
V2
background subtraction. Usando imagens omnidirecionais um modelo de fundo é construído enquanto o
robô está parado. Quando uma pessoa entra no campo
V  V1 + V2
(10)
de visão do robô e permanece na mesma posição durante 3 segundos, o robô entende que a pessoa quer
Para a análise da estabilidade, deve-se analisar as
interagir com ele. Após esta etapa, o robô começa a
funções V1 e V2 . Para V1 < 0, tem-se
navegar para ponto de destino e suas velocidades são
estimados utilizando o controlador de orientação nãoV1  h ..kv .(d).tanh.cos2 ,
(11)
linear apresentado na Seção 2 e, conforme a locomoção do robô o plano de fundo do ambiente é alterado,
Para V2 < 0, tem-se
dessa forma foi necessário descartar a utilização do


background subtraction e utilizar o movimento apatanh
V2  .  + kv .(d).  .sen.cos
rente da imagem, ou fluxo ótico, para aquisição da posição da pessoa.
tanh
+h .kv .(d)..
.sen.cos
É importante mencionar que a pessoa está na parte

de baixo da imagem obtida pelo sistema de visão e,
2
2
 k (  k . ),
assim não é necessário processar a parte superior da
mesma. Portanto, esta parte da imagem pode ser desAssim, a derivada temporal da função candidata
cartada. Para isso, uma máscara é aplicada sobre a
de Lyapunov fica
imagem para mostrar apenas a região de interesse, ou
2
2
2 seja, a parte de baixo da imagem. A Figura 3 mostra a
V (, , )  h ..kv .(d).tanh.cos k ( k . )
imagem original (a) e o resultado após a aplicação da
(12)
máscara (b).
a qual é semi-definida negativa, já que
Depois de detectar a pessoa com o método de

background subtraction, é necessário converter a disV (0, 0, 0)  0
(13)
tância do robô para a pessoa que está em pixels para
V (, , )  0, , ,  > 0 and (d) > 0
metros. Para executar esta conversão, a parte inferior
Para obter uma função definida negativa deve-se enda imagem foi dividido em cinco setores de 36o cada
contrar V (, , ) > 0, , ,  > 0 and (d) > 0. Para
um, como pode ser visto na Figura 3 (b).

ISBN 978-85-8001-069-5

216

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

(a)

(b)

robô, seus pés estão mais perto do centro da imagem. Portanto, as pessoas são representados pelos
seus pés na imagem. Conforme mencionado, após a
identificação e classificação do objeto como uma pessoa pelo método background subtraction, as variáveis
(x pixel , y pixel ) iniciais da pessoa são utilizadas para determinar o fluxo ótico naquela região e assim calcular
a distância desejada da pessoa ao robô durante a navegação.

Figura 3 Imagem original (a) e o resultado da aplicação da máscara (b).
4

Tabela 1 Funções para o setor 3.
Break
(d px )  4 d 3px + 3 d 2px +
2 d px + 1
0.6456
0.000000235165922x3

0.000034718361116x2
+
0.005304564960539x + 0,
75.2113
0.000000235165922x3
+
0.000017887557213x2
+
0.004049564679932 + 0.3
128.2259 0.000000854933652x3 +
0.000055289272502x2
+
0.007929008498114x + 0.6
145.6039 0.000001659579653x3
+
0.000010718341787x2
+
0.009076084179617x
+
0.75
161.1572 0.000000071588881x3 +
0.000088154198505x2
+
0.010613879177047x
+
0.90
173.9454 0.000000899732882x3
+
0.000085407707293x2
+
0.012833433571791x
+
1.05
194.0590 0.000004449742292x3 +
0.000139698302967x2
+
0.017361125303306x
+
1.35
311.8407 0.000004449742292x3 +
0.000029737202765x2
+
0.018756810221612x
+
1.50

Neste trabalho uma importante característica das
imagens omnidirecionais é usada para detectar uma
pessoa. Esta característica é o fato de um objeto
vertical no mundo real aparece radialmente na imagem. Assim, quando uma pessoa está em frente ao

ISBN 978-85-8001-069-5

4.1

Experimento 1

Neste experimento, após detectar a pessoa, o robô deveria navegar e conduzir a pessoa até uma posição 4m
 frente do robô e 1m  sua esquerda e uma orientação
final de 0o . Os caminhos percorridos pelo robô e pela
pessoa podem ser vistos na Figura 4.
Position of the Robot and Person

Position of the Robot and Person
2.5
2

2

1.5
1

1
y (m)

Sector

A fim de testar e validar o controlador de orientação
proposto, alguns experimentos foram realizados utilizando um robô_móvel e pedindo para algumas pessoas
andarem de diferentes formas e velocidades. Dois desses experimentos são apresentados e discutidos neste
documento. O robô_móvel utilizado foi um Pioneer
2-DX equipado com um sistema de visão omnidirecional.

y (m)

Para cada setor, adotaram-se funções polinomiais
que convertem a distância de pixels para metros. Essas
funções foram obtidas interpolando pontos 3D com os
pontos na imagem. A Tabela 1 mostra algumas funções para o setor 3.

Resultados Experimentais

0

Robot
Person

0.5
0
0.5

1

1

1

0

1

2
x (m)

(a)

3

4

1

0.5

0

0.5

1

1.5

2

2.5

3

3.5

x (m)

(b)

Figura 4 Caminhos descritos pelo robô e pela pessoa
durante a tarefa de condução.
Note que o caminho executado pela pessoa é diferente do percorrido pelo robô. Isso acontece pois
o robô guia a pessoa sem repetir os movimentos da
mesma, o robô apenas considera a velocidade desempenhada pela pessoa. Isso é similar ao comportamento
humano quando alguém conduz uma pessoa até um
certo lugar. Nesse caso, os seres humanos geralmente
caminham respeitando a mobilidade da pessoa e não
realizando o mesmo caminho que a outra faz.
As velocidades linear e angular desenvolvidas
pelo robô durante a tarefa de condução podem ser vistas, respectivamente, nas Figuras 5 (a) e (b). Observase, neste experimento, constantes aproximações em
direção ao robô. Isso se deve ao fato de alguns saltos realizados a fim de analisar o comportamento da
velocidade calculada pelo controlador.
Além disso, a distância entre a pessoa e o robô e
a distância do robô até o destino final são mostrados

217

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

Linear Velocity

Distance between the Robot and the Person

Position Error

400

4
1.6

Executed
Calculated

3
2.5

 (m)

d (m)

300
v (mms)

3.5

1.4
1.2

2

1

1.5

0.8

0.5

1

200

0

5

10
t (s)

15

20

0

5

10
t (s)

15

20

100

(a)
5

10
t (s)

15

Orientation angle of the Robot

20

Orientation Error
25

25

20

20
 graus

(a)

Angular Velocity

15

15

 (graus)

0
0

(b)

10

10
5

5
0
0
5

10
 (grauss)

5

0

5

10
t (s)

20

10
0

5

10
t (s)

(c)

0

15

20

(d)

Figura 6 Distância entre o robô e a pessoa (a), erro de
posição do robô (b), Orientação do robô (c) e erro de
orientação do robô.

10
20

0

15

5

10
t (s)

15

20

Position of the Robot and Person

Position of the Robot and Person
2

2

Robot
Person

1.5

(b)

1

1

y (m)

Figura 5 Velocidade linear (a) e velocidade_angular
(b) desenvolvidas pelo robô.

y (m)

0.5

0

0
0.5

1
1
1.5

2

2

0

nas Figuras 6 (a) e (b). Pode-se observar nas Figuras 6 (a) e 5 (a) que quando a pessoa se distancia do
robô, a velocidade linear do mesmo diminui e, consequentemente, há nenhuma alteração significativa no
erro de posição do robô. Esse erro pode ser visto na
Figura 6 (b). Assim, é possível ver que o robô espera
a pessoa se aproximar antes de se mover. Também na
Figura 6 (b) mostra que o erro de posição do robô vai
a zero, o que significa que o robô atinge o ponto de
destino.
4.2

Experimento 2

Neste experimento, após detectar a pessoa, o robô
deve guiá-la até uma posição 5m  frente, porém com
uma orientação de 15o . Os caminhos descritos pelo
robô e pela pessoa são apresentados na Figura 7 (b).
As velocidades linear e angular executadas pelo
robô durante essa tarefa podem ser vistas, respectivamente, nas Figuras 8 (a) e (b).
Assim como no experimento 1, quando a distância entre o robô e a pessoa aumenta, a velocidade linear do robô diminui. Neste experimento, a velocidade_angular do robô, mostrada na Figura 8 (b), é próxima de zero pois o ponto destino está localizado em
frente ao robô.
A distância entre a pessoa e o robô e a distância
do robô até o destino final são mostrados nas Figuras 9
(a) e (b). Pode-se observar nas Figuras 9 (a) e 8 (a) que
quando a pessoa se distancia do robô, a velocidade linear do mesmo diminui e, consequentemente, há ne-

ISBN 978-85-8001-069-5

1

2
3
x (m)

4

5

0.5

0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

x (m)

(a)

(b)

Figura 7 Caminhos descritos pelo robô e pela pessoa
durante a tarefa de condução.
nhuma alteração significativa no erro de posição do
robô. Esse erro pode ser visto na Figura 9 (b). Assim,
é possível ver que o robô espera a pessoa se aproximar
antes de se mover. Também na Figura 9 (b) mostra
que o erro de posição do robô vai a zero, o que significa que o robô atinge o ponto de destino.
5

Conclusão

Este trabalho apresentou uma estratégia de controle
para um robô_móvel realizar a tarefa de conduzir uma
pessoa, respeitando a sua capacidade de se movimentar. Um controlador não-linear foi implementado para
que o robô pudesse ajustar a sua velocidade de acordo
com a mobilidade da pessoa para realizar uma tarefa
de condução até um ponto final desejado. Um sistema
de visão omnidirecional foi utilizada para detectar e
localizar a posição atual da pessoa. Tal informação é
passada para o controlador que define as velocidades
lineares e angular do robô para guiar a pessoa através
do ambiente.
Para validar o controlador de orientação proposto,
alguns experimentos foram realizados em que o robô
conduziu uma pessoa a partir de um ponto inicial até o
local desejado. Pode-se notar que o robô foi capaz de

218

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

Linear Velocity

5.1

Para trabalhos futuros, seria interessante considerar informações adicionais sobre o ambiente durante a realização da tarefa de condução. Assim pode-se melhorar o controlador de orientação, incluindo um mapa do
ambiente. Dessa maneira, o robô poderia levar uma
pessoa a partir de um lugar a outro situados em diferentes salas ou até prédios diferentes. Uma outra
abordagem para trabalho futuro é a inclusão de uma
estratégia para evitar obstáculos usando um sensor_laser (Ferreira et al., 2008) ou apenas ampliar o uso do
sistema de visão omnidirecional para detectar obstáculos através de fluxo óptico (Franca, 2005).
Outra questão interessante a adição de uma interface de comunicação para proporcionar uma interação
entre a pessoa e o robô logo que o robô detecta a pessoa. Neste caso, o robô pode começar um diálogo e a
pessoa pode escolher o lugar para onde deseja ir.

300

v (mms)

250
Executed
Calculated

200
150
100
50
0
0

10

20
t (s)

30

40

(a)

Angular Velocity
3
2
 (grauss)

Trabalhos Futuros

1
0
1

Agradecimentos
2
0

10

20
t (s)

30

40

Os autores gostariam de agradecer  FAPES e CAPESMinCyt (projeto 18110) pelo suporte financeiro.

(b)

Figura 8 Velocidade linear (a) e velocidade_angular
(b) desenvolvidas pelo robô.

Distance between the Robot and the Person

Ferreira, A., Pereira, F. G., Vassallo, R. F., SarcinelliFilho, M. and Bastos-Filho, T. F. (2008). An approach to avoid obstacles in mobile robot navigation The tangential escape., SBA. Sociedade
Brasileira de Automática 19 395405.

Position Error
5

1.8
4

 (m)

d (m)

1.6
1.4

3
2

1.2
1

1

0.8
0

10

20
t (s)

30

40

0

10

(a)

20
t (s)

30

40

(b)

Orientation angle of the Robot

Orientation Error
2
 (graus)

 graus

0
5

0

2
4
6
8

5
0

Franca, A. S. (2005). Detecção de obstáculos através de um fluxo óptico padrão obtido a partir de imagens omnidirecionais, André Stanzani
Franca, Raquel Frizera Vassallo e Hans Jrg Andreas Schneebeli.
Grassi-Junior, V. and Okamoto-Junior, J. (2006). Development of an omnidirectional vision system,
Journal of the Brazilian Society of Mechanical
Sciences and Engineering XXVIII(1) 5868.

4
10

Referências

10

20
t (s)

30

40

(c)

10
0

10

20
t (s)

30

40

(d)

Figura 9 Distância entre o robô e a pessoa (a), erro de
posição do robô (b), Orientação do robô (c) e erro de
orientação do robô.

guiar a pessoa durante todo o caminho, ajustando a sua
velocidade de acordo com a distância da pessoa. Isso
significa que o robô reduziu ou aumentou sua velocidade, se a pessoa andou devagar ou rápido, ou mesmo
parou durante a tarefa de orientação. Estes resultados
preliminares são animadores para manter a motivação
em pesquisar nesta área.

ISBN 978-85-8001-069-5

Pereira, F. G., de Sá, F. B., Ferreira, D. B. and Vassallo, R. F. (2010). Object transportation task by
a human and a mobile robot, International Conference on Industrial Technology - ICIT 2010.
Pereira, F. G., Santos, M. C. P. and VASSALLO,
R. F. (2011). A nonlinear_controller for people
guidance based on omnidirectional vision. 2011,
IROS p. 6.
Secchi, H. A. (1998). Control de vehículos autoguiados con realimentación sensorial, Masters thesis, Facultad de Inginería de la Universidad Nacional de San Juan, San Juan - Argentina.
Takubo, T., Arai, H., Hayashibara, Y. and Tanie, K.
(2002). Human-Robot Cooperative Manipulation Using a Virtual Nonholonomic Constraint,

219

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

The International Journal of Robotics Research
21(5-6) 541553.

ISBN 978-85-8001-069-5

220