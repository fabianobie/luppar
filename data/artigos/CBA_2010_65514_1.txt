PREVISÃO DE AFLUÊNCIAS UTILIZANDO REDES NEURAIS ARTIFICIAIS COM O AUXILIO
DAS TOOLBOXES DO MATLAB
Klayton A. M. Araujo, Bruno C. Vitti, Anna Diva P. Lotufo, Mara L. M. Lopes.
Laboratório de Sistemas Inteligentes , Departamento Engenharia Elétrica , UniversidadeEstadual Paulista
Campus de Ilha Solteira, Av. Brasil 56, Ilha Solteira, SP.
E-mail klayton.feis@gmail.com, brunovitti@hotmail.com,
annadiva@dee.feis.unesp.br, mara@mat.feis.unesp.br

Abstract.This paper deals with artificial neural networks applied to stream flow forecasting. Neural Networks are very important
tools used on approaching, forecasting and other problems. Thus, the objective is to study and use the feedforward neural network with
the Levenberg-Marquardt algorithm and the RBF (radial basis neural network) and compare these two neural networks to solve stream
flow forecasting, using the MATLAB toolboxes. Results are obtained for a Brazilian power hydroelectric stream flow data.
Keywords Artificial Neural Networks, streamflow forecasting, Levenberg- Marquardt, Radial Basis Function, MATLAB.

Resumo Este artigo aborda o desenvolvimento de redes_neurais artificiais aplicadas a previsão_de_afluências. As redes_neurais vêm
se tornando uma ferramenta de estudo bastante utilizada nos problemas de aproximação, previsão, etc. Logo, o objetivo é estudar e
utilizar a rede_neural feedforward com o algoritmo de Levenberg-Marquardt e a rede_neural de base radial e comparar a atuação
dessas arquiteturas na resolução do problema de afluências. As redes_neurais utilizadas foram implementadas com o auxilio das
toolboxes do MATLAB, o qual, viabiliza de forma rápida e eficiente o uso de tais redes. Os dados de afluências utilizados no
desenvolvimento do programa foram obtidos de uma usina hidroelétrica do sistema elétrico brasileiro.
Palavras-chave .

evaporação, evapotranspiração, percolação do solo,
vazão vertida a montante entre outros (Lotufo,
1982). Neste trabalho estes fatores não serão considerados, pelo fato de que, nem sempre estão disponíveis devido a diversos motivos (falha nas medições, etc.) e também por não ser o objetivo principal
deste trabalho.
Redes Neurais Artificiais (Bender, 1996 Jain et al.,
1996 King, 1998) de uma forma geral são redes de
comunicação adaptativas que ligam uma função custo a uma saída desejada. Matematicamente, representam um sistema dinâmico que pode ser modelado
como um conjunto de equações diferenciais eou
algébricas, não-lineares acopladas. As redes_neurais
são compostas de neurônios interligados formando
camadas, distinguindo-se em camadas de entrada,
intermediárias e de saída. No entanto, estas redes
precisam aprender a tarefa para poder atuar. Isto
está associado aos pesos de ligação entre os neurônios. Os valores finais dos pesos constituem o programa da rede_neural artificial (Bender, 1996 Haykin, 1996).
As Redes Neurais podem ser aplicadas em muitas
áreas do conhecimento, sejam elas tecnológicas ou
não, para executar as mais diversas tarefas que tentam reproduzir o comportamento do cérebro humano. A partir do advento das redes_neurais e da aplicação para problemas de previsão (Biondi Neto et.al.
2004 Cameron et.al. 1999 Chen and Chang, 2009
Luna et al., 2007 Turan et al.,2009), estas se tornaram bastante interessantes suplantando os métodos
estatísticos tradicionais, por exemplo, o ARIMA de
Box  Jenkins (Costa et al., 2007).

1 Introdução
A geração_de_energia_elétrica no Brasil depende basicamente das vazões que naturalmente afluem aos
aproveitamentos hidroelétricos brasileiros distribuídos por doze bacias hidrográficas do país. Esses aproveitamentos totalizam mais de 85 da capacidade instalada de geração do país. A existência de reservatórios com capacidade de regularização significativa torna o problema do planejamento_da_operação um problema não-separável no tempo, uma vez
que qualquer decisão de deplecionamento destes
reservatórios influência a capacidade de geração do
sistema no futuro. A capacidade de geração futura
do sistema também é influenciada pelas afluências
hidrológicas futuras, cujas previsões e incertezas
devem ser consideradas no planejamento_da_operação do sistema (Costa et al., 2007).
A operação e o planejamento de sistemas_elétricos
exigem o conhecimento antecipado de uma série de
variáveis necessárias ao bom funcionamento do sistema. Dentre estas variáveis, destacam-se as cargas
elétricas e, num processo anterior, as vazões (Costa
et al., 2007 Lotufo 1982) que chegam a um determinado reservatório. O sistema elétrico brasileiro é
predominantemente hidráulico, logo as vazões representam a quantidade de energia que deverá ser
gerada para suprir as cargas.
As afluências que chegam a um reservatório de uma
usina hidroelétrica dependem de inúmeros fatores e
dentre eles destacam-se a precipitação da chuva,
2585

A atualização desses pesos pode acontecer de duas
formas incremental ou em lote. No primeiro caso a
atualização dos pesos se dá  medida que cada padrão  conjunto de entradas e saídas associadas  de
treinamento é apresentado. No segundo, a atualização se dá apenas depois de finalizada uma leitura
completa do conjunto de treinamento. Os pesos são
adequados atendendo a um critério ou índice de desempenho que visa minimizar a diferença entre os
valores de saída previstos pela rede e os contidos nos
padrões de treinamento. O algoritmo de treinamento
utilizado neste trabalho é o método de LevenbergMarquardt (Saini and Soni, 2002) que utiliza treinamento em lote e consiste em um aperfeiçoamento
do método Gauss-Newton, que é uma variante do
método de Newton. O método de Newton usa a informação da derivada parcial de segunda ordem do
índice de desempenho utilizado para corrigir os pesos w. Isso permite que além da informação do gradiente seja usada informação sobre a curvatura da
superfície do erro (Bazaraa et al., 1993).
Como esse algoritmo de Levenberg Marquardt é
baseado no método de Newton, utiliza-se a aproximação para a matriz Hessiana, mostrada pela Equação (1), determinada em função da matriz Jacobiana,
que contém as primeiras derivadas dos pesos em
função dos pesos sinápticos, expressa na Equação (2)
(Catalão et al., 2007 Suratgar, 2005)

No horizonte de previsão de curto prazo, a partir de
um histórico de vazões naturais médias diárias, em
sua grande maioria baseado em dados de balanço
hídrico, utilizando tecnologia determinística com
modelos chuva-vazão, ou até mesmo, utilizando modelos estocásticos, são realizadas estimativas de vazões naturais médias diárias para um horizonte de
até 14 dias  frente. Acredita-se que também possa
haver um ganho bastante elevado nos resultados das
previsões de vazões diárias, sempre que houver uma
evolução nas tecnologias de previsão de precipitação
que permita ampliar o horizonte atual de somente
alguns poucos dias para duas a três semanas  frente.
As previsões de vazões de curto prazo, em nível diário destinam-se  programação diária da operação do
Sistema Interligado Nacional - SIN, ao monitoramento e controle de eventos extremos (cheias e secas) e no auxílio  tomada de decisão para promover
o uso múltiplo da água (Guilhon, 2001).
Os dados utilizados para simulação serão obtidos
diretamente do banco_de_dados do ONS (ONS,
2009), que devem contemplar a maioria destas informações pelo menos de forma implícita.
2 Redes neurais artificiais
2.1 Rede neural artificial multicamadas feedforward
com algoritmo de treinamento Levenberg- Marquardt

2

H 

 ER ( W )
W

Uma rede_neural artificial (RNA) multicamadas é
uma rede de neurônios artificiais interligados, estruturada com uma camada de entrada (sem pesos sinápticos, com a função de distribuição dos valores de
entrada), uma ou mais camada intermediárias e uma
camada de saída.

J 

(1)

2

 e (W )

(2)

W

sendo
H

J

ER (W) 
e(W) 

matriz hessiana
matriz_jacobiana
erro relativo dos pesos sinápticos
erro referente aos pesos sinápticos
e( W )  yi  yei

(3)

onde

yi  peso sináptico atual
yei  peso sináptico da próxima iteração.

Figura 1. Rede Neural Artificial Multicamadas

A determinação da matriz Jacobiana é muito mais
simples que a determinação da matriz Hessiana.
Como, para uma rede_neural, o desempenho de treinamento é expresso em função da soma dos erros
quadráticos, a matriz Hessiana pode ser expressa
pela Equação (4)
T
(4)
H  J (W ) J (W )

O treinamento supervisionado dessa rede consiste
em determinar valores adequados para os pesos sinápticos (incluindo os bias) de todos os neurônios
que compõem as camadas intermediárias e de saída.

O problema com esse método é que a matriz Hessiana pode não ter inversa. Para contornar essa situação, Levenberg propôs somar a parcela I a essa
matriz.

2586

Desta forma, o método de Newton atualiza os pesos
através da Equação (5)
-1
(5)
W (k  1 )  W (k )  H g

dade de dados utilizados na rede_neural não seja
muito grande (Saini and Soni, 2002).

sendo gk descrito conforme a Equação (6)

2.1.1 Rede Neural de Base Radial

k

(6)

g k  2 J T (W ) e (W )

A rede de função_de_base_radial possui na sua camada de entrada (camada de base radial), neurônios de
base radial, e na sua camada de saída (camada linear
simples), neurônios com função de ativação linear
(Dibike and Solomatine, 2001 Garg et al., 2007). A
Figura 2 apresenta o modelo de um neurônio de função_de_base_radial.

Utilizando as Equações (4) e (6) na Equação (5)
obtêm-se a atualização dos pesos dada pela Equação
(7)
T

W ( k  1 )  W ( k )   J ( W ) J ( W )   I
k

no qual
I  matriz identidade
K  constante do método
Marquardt.

1

T

J (W ) e(W ) (7)

w1,1

de

Levenberg-

p1
p2
p3




w1, R

pR 

Após uma atualização, se o valor do índice de desempenho diminui  deve ser diminuído para reduzir a influência do gradiente_descendente. Se ao contrário, o valor do índice de desempenho aumenta
então seguir a direção do gradiente_descendente é a
melhor escolha e o valor de  deve ser aumentado.
Se  tornar-se muito grande, a informação dada pela
aproximação H para o hessiano não será útil no cálculo da atualização de w. Para contornar esse problema, Marquardt propôs substituir a matriz identidade pela matriz diagH (matriz diagonal de H),
resultando na seguinte regra de atualização que pode
ser resumido através dos seguintes passos (Catalão et
al., 2007 Suratgar, 2005)

Figura 2. Modelo de um neurônio de base radial com R entradas.

É possível notar que a expressão para a entrada da
rede de um neurônio de base radial difere de outros
neurônios. Neste caso a entrada da rede para a função_de_transferência do neurônio de base radial é o
vetor distância entre seu respectivo vetor peso w e o
vetor de entrada p, multiplicado pelo bias b.
As funções de ativação de neurônios de base radial
são funções não_lineares, cujos valores diminuem ou
aumentam em relação a um ponto central chamado
de centro da função_de_base_radial (Kartalopoulos,
1996 Haykin, 1999).
Uma das funções não_lineares mais comuns é a do
tipo Gaussiana. A saída da primeira camada é representada pela Equação (8) (Kartalopoulos, 1996)

Passo 1 - obter uma atribuição inicial de pesos
Passo 2 - calcular a atualização dos pesos de acordo
com a Equação (7) e avaliar o erro, propagando os padrões na rede
Passo 3 - se o erro aumentar é necessário desfazer a
atualização de w e diminuir  caso contrário, validar a atualização de w e incrementar 
Passo 4 - verificar a convergência, ou seja, se a rede
neural convergiu encerre o processo senão
voltar para passo 2.

 ( p  w1, j )( p  w1, j ) 

2
2 j



n1, j  exp 

j  1, ..., R

(8)

em que
p  entrada padrão
n1, j  saída do j-ésimo nó da primeira camada
w1, j  vetor peso do j-ésimo nó na primeira camada

Os critérios de convergência mais usuais são a)
norma do gradiente ser menor do que um valor prédeterminado b) soma do erro quadrático menor do
que um valor pré-determinado c) atingir um número pré-determinado de iterações.
A rede_neural treinada através do algoritmo de Levenberg- Marquardt converge em um número menor
de iterações comparado aos demais algoritmos de
treinamento utilizados nas redes MLP. Uma desvantagem apresentada pelo algoritmo de LevenbergMarquardt é o fato de este exigir um maior número
de cálculos realizados em cada iteração. Isto ocorre
em conseqência do calculo das matrizes inversas
que são necessários na execução do algoritmo. Apesar dos esforços realizados durante o processo o algoritmo se mantém rápido, uma vez que, a quanti-

2
 j  parâmetro de normalização para o j-ésimo nó.

A saída da segunda camada é dada por
t

a j  w2 , j n1

(9)

em que
a j ,  saída do j-ésimo nó da segunda camada
n1,  vetor de saída da primeira camada
w 2 , j  vetor peso da saída

Quando se usa as funções Gaussianas cada nó produz uma saída idêntica para entradas que estão dentro de uma distância radial fixada a partir do centro
de uma base, isto é, são radialmente simétricas e daí
o nome RBF (Radial Basis Function).
2587

A função_de_transferência de um neurônio de base
radial é dada pela expressão
radbas (n)  e

-n

A função newrb cria iterativamente uma rede de
base radial de um neurônio por vez. Neurônios são
adicionados  rede até que a soma do erro quadrático
esteja abaixo de um erro desejado (parâmetro goal)
ou um máximo número de neurônios tenha sido atingido (Demuth and Beale, 1998).
Para as duas arquiteturas de RNAs projetadas, os
vetores de entrada possuem o mesmo padrão.
O padrão de entrada é descrito por um vetor contendo informações dos valores das vazões diárias n, n1, n-2 e n-3. As redes foram submetidas a seis treinamentos distintos, diferenciados pela quantidade de
dias utilizados para cada treinamento e a previsões
para 7 e 14 dias conforme Tabela 1.

(10)

O gráfico desta função_de_transferência é dado pela
Figura 3

Figura 3. Função de Base Radial.

O treinamento de uma rede_neural de função de base
radial pode ser separado em duas etapas

Tabela 1. Especificações de cada treinamento quanto ao período, o
numero de vetores de entrada e previsão.

1. Definição dos centros, forma e dispersão das funções de base radial, normalmente baseada em
treinamento não supervisionado (quantização_vetorial ou algoritmo de treinamento competitivo)
ou computação_evolutiva
2. Aprendizado dos pesos da camada de saída, responsáveis pela combinação_linear das ativações da
camada intermediária, empregando técnicas como
pseudo-inversão e OLS (Orthogonal Least Squares) (Chen et al., 1991).
De um modo geral, a rede RBF apresenta tempos de
treinamento bem baixos quando comparada a rede
feedforward com algoritmo backpropagation, pois
possui cálculos bem mais simples (em geral, trabalha-se com funções exponenciais) (Kartalopoulos,
1996). A rede RBF é computacionalmente, em termos de rapidez, mais vantajosa quando comparada
s redes feedforward com algoritmo de treinamento
por Levenberg-Marquardt, uma vez que esta trabalha com inversão de matrizes e derivadas de segunda
ordem (Catalão et al., 2007 Suratgar, 2005).

Treinamento

Período

1

251206 
251207
181206 
181207
251204 
251207
181204 
181207
251202 
251207
181202 
181207

2
3
4
5
6

Número de
vetores de
entrada
366

Previsão
(dias)

366

14

1096

7

1096

14

1827

7

1827

14

7

Os resultados serão apresentados em forma de gráfico e Tabelas. Para comparar os resultados obtidos
por cada rede, verificamos o MAPE (erro percentual
absoluto máximo) e o erro máximo obtido durante a
previsão das afluências dados pela Tabela 2. As expressões do MAPE e do erro máximo são mostradas
abaixo
MAPE 

1
ND

3 Resultados e Discussões
Para o caso da rede feedforward com treinamento
por Levenberg-Marquardt (Catalão et al., 2007 Suratgar, 2005), a RNA criada para prever as afluências de 7 dias referente a três aplicações com períodos diferentes, possui 4 neurônios em sua camada de
entrada, 50 neurônios em sua camada intermediaria
e 1 neurônio em sua camada de saída. As funções de
ativação utilizadas para cada camada, foram as funções sigmóide 2, sigmóide 1 e linear (Haykin, 1999
Kartalopoulos, 1996), respectivamente.
Referente s mesmas aplicações citadas anteriormente, criou-se uma rede de função_de_base_radial
baseada na função newrb, presente na toolbox de
redes_neurais do MATLAB com duas camadas, contendo tantos neurônios na camada de entrada quanto
forem o número de dados presentes no vetor de entrada e 1 neurônio na camada de saída.

E

max

(

(

ty
t

ty
t

(11)

)  100

(12)

)100

sendo
ND  número de dados de entrada
t
 vetor de dados reais
y
 vetor de dados estimados.
Pela análise da Tabela 2, observa-se que a RNA feedforward com algoritmo Levenberg-Marquardt
obteve valores de MAPE consideravelmente pequenos atingindo seu maior valor para o treinamento 2,
onde havia o menor número de vetores de entradas
quando comparados aos outros e o maior erro máximo.

2588

Figura 4. Curvas de comparação das RNA para treinamento 1.
4

Tabela 2. MAPE e máximo erro obtido durante a previsão_de_afluências.

1.4

x 10

Levenberg-Marquardt
Curva de Afluência Real
RBF

1.32

Treinamento

MAPE
()

1
2
3
4
5
6
1
2
3
4
5
6

1,5235
2,6773
1,3232
1,9537
1,1490
1,6242
1,8844
1,5686
1,7134
0,9701
0,9074
0,8591

RNA feedforward
backpropagation
com algoritmo
LevenbergMarquardt

RBF

Erro
máximo
()
2,8554
5,2375
2,6541
3,9536
2,9633
3,6693
4,7553
6,2047
5,1054
3,3141
2,3695
2,1684

V a z ã o ( m 3 s )

RNA

1.24

1.16

1.08

1

0.9

1

2

3

4

5

6

7

8

9

10

11

12

13

14

Tempo (Dias)
Figura 5. Curvas de comparação das RNA para treinamento 2.
x 10

4

1.35

Levenberg-Marquardt
Curva de Afluência Real
RBF

1.3

V a z ã o (m 3 s )

A RBF obteve êxito na diminuição do MAPE a cada
treinamento, mesmo como o maior erro máximo
neste.
Também foi verificado o tempo utilizado para o treinamento de cada RNA, submetido aos diferentes
períodos de tempo, Tabela 3.

1.25

1.2

1.15

1.1

Tabela 3. Tempo gasto para o treinamento de cada rede devido a
diferentes períodos de tempo período de tempo.

RNA feedforward backpropagation com algoritmo
Levenberg-Marquardt

RBF

Treinamento
1
2
3
4
5
6
1
2
3
4
5
6

1

x 10

Tempo (s)
0,819652
1,381217
2,206715
2,869283
18,088542
19,836463
0,049949
0,087482
0,099846
0,160451
0,181922
0,219736

1.4

5

6

V a z ã o ( m 3 s )

4

Levenbrg-Marquardt
Curva de Afluência Real
RBF

1

0.9

1

2

3

4

5

6

7

8

9

10

11

12

13

14

Tempo (Dias)
Figura 7. Curvas de comparação das RNA para treinamento 4.

1.06

4

7

1.08

1.12

3

6

1.16

1.18

2

5

1.24

Levenberg-Marquardt
Curva de Afluência Real
RBF

1

x 10

1.32

1.24

1

4

Figura 6. Curvas de comparação das RNA para treinamento 3.

4

1.3

3

Tempo (Dias)

As Figuras 4-9 apresentam as curvas obtidas através
da RNAs que foram submetidas ao melhor período
de treinamento, no qual se baseou ao menor MAPE
gerado.
1.36

2

V a z ã o (m 3 s )

RNA

1.05

7

Tempo (Dias)

2589

4

x 10

Sobre os resultados obtidos com o MAPE observa-se
que somente para os treinamentos 1 e 2 a rede por
Levenberg-Marquardt apresenta resultados melhores
quando comparado com a RBF.  medida que são
fornecidos mais vetores de entrada á rede RBF, aos
poucos ela atinge melhores resultados que Levenberg-Marquardt. Por exemplo, no caso do treinamento 6, a rede RBF apresenta um MAPE de aproximadamente 0,86, enquanto que a de LevenbergMarquardt 1,62.
Já o erro máximo para o algoritmo de LevenbergMarquardt foi de 5,24, enquanto para a RBF foi de
6,20, aproximadamente.
Em geral, observa-se que para cada uma das arquiteturas têm-se diferentes análises para seus MAPEs.
No caso do método de Levenberg-Marquardt, se
houver a necessidade de prever mais dias, o erro se
propaga e conseqentemente há um aumento do
MAPE, por ser uma rede_neural com retropropagação. Já a RBF não permite que haja esta relação e o
erro diminui.
Diante dos resultados podemos observar a superioridade da RBF quanto ao tempo de processamento, em
que no caso do treinamento 6 os tempos da RBF e de
Levenberg-Marquardt são de aproximadamente 0,22
e 19,84 segundos, respectivamente, sendo que essa
superioridade se mantém por todos os treinamentos
efetuados.
Tal superioridade é justificada pelo fato da rede RBF
possuir em sua fase de treinamento cálculos menos
complexos (em, geral, funções exponenciais) do que
os cálculos realizados pela rede feedforward com
treinamento Levenberg-Marquardt (inversão de matrizes e derivadas de segunda ordem) nesta mesma
fase de treinamento.

Levenberg-Marquardt
Curva de Afluência Real
RBF

1.36

V a z ã o ( m 3 s )

1.3

1.24

1.18

1.12

1.06

1

1

2

3

4

5

Tempo (Dias)

6

7

Figura 8. Curvas de comparação das RNA para treinamento 5.
1.4

x 10

4

Levenberg-Marquardt
Curva de Afluência Real
RBF

V a z ã o (m 3 s )

1.32

1.24

1.16

1.08

1

0.9

1

2

3

4

5

6

7

8

9

10

11

12

13

14

Tempo (Dias)
Figura 9. Curvas de comparação das RNA para treinamento 6.

A Tabela 3 traz os respectivos tempos de processamento de cada rede_neural em cada treinamento. A
RNA feedforward com algoritmo LevenbergMarquardt possui um tempo maior a cada treinamento e também superior quando comparada a RBF.
Isto ocorre devido  necessidade do algoritmo de
Levenberg-Marquardt ter de treinar e efetuar mais
cálculos quando se comparado a RBF que apenas
realiza a aproximação por uma função.

Agradecimentos
A FAPESP (processos números 200801229-3 e
200913941-2) como entidade financiadora por acreditar e apoiar este trabalho. A professora e orientadora Dra Anna Diva Plasencia Lotufo pela sua confiança e suas contribuições em nossa pesquisa. A
professora Mara Lúcia Martins Lopes que auxiliou
no desenvolvimento do artigo.

4 Conclusão
Realizar a previsão_de_afluências utilizando redes
neurais artificiais vem, nos últimos tempos, mostrando evolução e bons resultados devido ao desenvolvimento de novos softwares e o aumento do interesse de alguns grupos de pesquisa pelo assunto.
Assim, as comparações dos resultados obtidos utilizando tipos diferentes de treinamentos de redes_neurais é algo bastante interessante, afinal cada rede se
comporta de maneira diferente dependendo do problema proposto.
Alguns padrões foram analisados para facilitar as
comparações e peculiaridades de cada rede_neural,
como MAPE, erro máximo e tempo de processamento. Os gráficos evidenciam que os dados previstos pelas redes_neurais, independentes do tipo de
treinamento, possuem uma proximidade com os dados reais.

Referências Bibliográficas
Bazaraa, M. S. Sherali, H. D. and Shetty, C. M.
(1993). Nonlinear Programming, Theory and
Algorithms. John Wiley  Sons, USA.
Bender, E.A. (1996). Mathematical Methods in
Artificial Intelligence. IEEE Computer Society
Press. Los Alamitos, Califórnia, USA.
Biondi Neto, L. Coelho, P. H. G. Velloso, M. L. F.
and Meza, L. A., Setembro 2004, Monthly
Flow Estimation Using Neural Networks In

2590

Lotufo, A. D. P. (1982). Previsão de Afluências 
Curtíssimo
Prazo
para
Operação
de
Hidroelétricas. Dissertação de Mestrado, UFSC,
Florianópolis, SC, Brasil.
Luna, I. Soares, S. Ballini, R., outubro 2007,
Modelo Adaptativo Baseado em Regras
Nebulosas Aplicado  Previsão de Séries de
Vazões Semanais Simpósio Brasileiro de
Automação Inteligente, Florianópolis, SC,
Brasil.
ONS-Operador Nacional do Sistema Elétrico.
(2009). httpwww.ons.org.br. Acessado em11
jan. 2010.
Saini, L. M. and Soni, M. K. (2002). Artificial
Neural Network based Peak Load Forecasting
Using Levenberg-Marquardt and Quasi-Newton
Methods. IEE Proceedings on Generation
Transmission, Distribution, Vol. 149, No. 5, pp.
578-584.
Suratgar, A. A. Tavakoli, M. B. and Hoseinabadi,
A. (2005). Modified Levenberg-Marquardt
Method for Neural Networks Training.
Engineering and Technology, Vol. 6, pp. 46-48.
Turan, M. E. and Yurdusev, M. A. (2009). River
Flow Estimation from Upstream Flow Records
by Artificial Intelligence Methods. Journal of
Hydrology, Vol. 369, No. 1-2, pp. 71-77.

Simpósio Brasileiro de Redes Neurais, São Luiz,
MA, Brasil.
Cameron, M. Z Donald, H. B. and Slobodan, P. S.
(1999). Short Term Streamflow Forecasting
Using Artificial Neural Networks. Journal of
Hydrology, Vol. 214, No. 1-4, pp. 32-48.
Catalão, J. P. S. Mariano, S. J. P. S. Mendes, V.
M. F. and Ferreira, L. A. F. M. (2007). Shortterm Electricity Prices Forecasting in a
Competitive Market A Neural Network
Approach. Electric Power Systems Research,
Vol. 77, pp. 1297-1304.
Chen, S. Cowan, C. F. N. and Grant, P. M. (1991).
Orthogonal Least Squares Learning Algorithm
for Radial Basis Functions Networks. IEEE
Transactions on Neural Networks, Vol. 2, No.
2, pp. 302-309.
Chen, Y. and Chang, F. (2009). Evolutionary
Artificial Neural Networks for Hydrological
Systems Forecasting. Journal of Hydrology, Vol.
367, No. 1-2, pp. 125-137.
Costa, F. S Maceira, M. E. P and Damázio, J. M.
(2007). Modelos de Previsão Hidrológica
Aplicados ao Planejamento da Operação do
Sistema Elétrico Brasileiro. Revista Brasileira
de Recursos Hídricos - RBRH, Vol. 12, No. 3,
pp. 21-30.
Demuth, H. and Beale, M. (1998). Neural Network
Toolbox For Use with MATLAB - Users Guide,
The Math Works Inc., Massachusetts, USA.
Dibike, Y. B. and Solomatine D. P. (2001). River
Flow Forecasting Using Artificial Neural
Networks. Phys. Chem. Earth (B), Vol. 26,
No.1, pp. 1-7.
Garg, S. Pal, S. K. and Chakraborty, D. (2007).
Evaluation
of
the
Performance
of
Backpropagation and Radial Basis Function
Neural Networks in Predicting the Drill Flank
Wear. Neural Comput  Applic, Vol. 16, pp.
407-417.
Guilhon, L. G. F. (2002). Modelo Heurístico de
Previsão de Vazões Naturais Médias Semanais
Aplicado  Usina de Foz do Areia. Dissertação
de Mestrado, Programa de Pós-Graduação em
Planejamento Energético - COPPE UFRJ, Rio
de Janeiro, RJ, Brasil, 88 p.
Haykin, S. (1999). Neural Networks A
Comprehensive Foundation. Prentice-Hall,
Upper Saddle River, New Jersey, USA.
Jain, A. K. Mao, J. and Mohiuddin, K. M. (1996).
Artificial Neural Networks A Tutorial. IEEE
Computer, Vol. 29, No.. 3, pp. 31-44.
Kartalopoulos, S.V. (1996). Understanding Neural
Networks and Fuzzy Logic Basic Concepts and
Applications. IEEE Press, Piscataway, New
Jersey, USA.
King, R. L. (1998). Artificial Neural Networks and
Computational Intelligence. IEEE Computer
Application in Power, Vol. 11, No. 4, pp. 14-25.

2591