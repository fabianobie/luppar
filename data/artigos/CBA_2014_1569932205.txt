Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

NEURAL NETWORK FITTING FOR INPUT-OUTPUT MANIFOLDS OF ONLINE
OBSERVERS WITH ERROR LIMITATION
Marconi O. de Almeida Samaronne N. do Carmo Flavio A. de Castro Rafael F.R.
Campos Jose M. Araujo Carlos E.T. Dorea




Instituto Federal da Bahia, Departamento de Automacao e Sistemas
Rua Emdio dos Santos, SN, Barbalho
Salvador, BA, 40301015, Brazil

Universidade Federal do Rio Grande do Norte, Centro de Tecnologia
Departamento de Engenharia de Computacao e Automacao
Lagoa Nova, Natal, RN, 59078900, Brazil
Email araujo@ieee.org

Abstract This paper aims to present the use of Neural Networks (NN) to approximate the input-output
map manifold for online output injection laws in the context of observers with error limitation. The set invariance
approach is applied for computation of as small as possible conditioned invariant sets that confine the estimation
error of a full-order observer. Online output injection laws are attractive due to its ability to cope with the peak
phenomenon, but the runtime of its computation may turn its use unfeasible in systems with fast dynamics.
The input-output map of such injection law is then approximated via NN training. Structures with NNs present
processing times as fast as the adequate technology is employed for their implementation, for instance, FPGAs.
Two examples, one of which the classical well-known magnetic levitation ball system, are presented to illustrate
the merit of the approach.
Keywords

Set invariance, Observers, Neural Networks, Function Approximation.

Resumo Neste artigo, o uso de Redes Neurais Artificiais para a aproximacao do mapa da variedade de
entrada-sada de leis de injecao de sada para observadores com limitacao de erro e apresentado. O metodo de
invariancia_de_conjuntos e aplicado para a obtencao de conjuntos invariantes condicionados os menores possveis
que confinem o erro de estimacao de um observador de ordem completa. Leis de injecao de sada calculadas
online (a cada passo) sao atrativas devido a sua habilidade em lidar com o fenomeno de pico, mas o tempo
de calculo da mesma pode tornar sua aplicacao inviavel em sistemas de dinamica rapida. O mapa de entradasada de tais leis de injecao sao entao aproximados atraves de treinamento de redes_neurais. Estruturas com
redes_neurais apresentam tempos de processamento tao rapidos quao adequada e a tecnologia empregada, por
exemplo, FPGAs. Dois exemplos, um dos quais e o classico e bem conhecido sistema de levitacao magnetica de
um esfera, sao apresentados como forma de ilustrar o merito da abordagem apresentada.
Palavras-chave

.

Introduction

this problem as in Haimovich et al. (2004).
The set invariance approach, on the other
hand, is interesting because a substantial part of
the computation, if not all of it, can be performed
offline. In some cases, namely with a single measurement output, analytical expressions for the
output injection law can be constructed by means
of piecewise affine functions. Important contributions on this subject can be found in Araujo
et al. (2011)Dorea and Pimenta (2005a)Dorea
and Pimenta (2005b). The peak phenomenon is
still present as seen in Araujo et al. (2011), as a
consequence of high gain structures. Nevertheless,
yet in Araujo et al. (2011), an online output injection law shows a good response, overcoming the
peak phenomenon.
Artificial Neural Networks or simple Neural Networks (NNs) form a class in Artificial Intelligence techniques with several successful applications, among them control and
modeling and estimation of dynamical systems
(Narendra and Parthasarathy (1990),Yamada
(2008),Mini and Padma Suresh (2014)Alessandri et al. (2011),Alessandri et al. (2008)) func-

The design of observers with error limitation is a
relevant issue in control systems theory and practice. In linear observer design, the trade-off between fast convergence and inrush in initial performance arises from the peak phenomenon verified in high gain observers (Gauthier and Kupka.
(2001)). In the last two decades, some important
contributions on the design of observers with error
limitation, including systems subject to measurement noise and disturbances, have been reported.
Two of them are the so-called set-valued and setinvariant state estimators. The first (Shamma
and Tu (1999)Lin et al. (2003)Blanchini and Miani (2007)) consists in computing online (at each
step) the set of admissible states with respect to
the measurement, taking into account noise and
disturbance. An optimal state estimate is then
picked from such a set according to a given criterium. The main disadvantage in this case is the
time needed for online computation that may increase quickly with the dimension of the problem.
Some contributions have succeeded in mitigating

2916

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

tion approximation (Andras (2014),Yang et al.
(2013)) pattern recognition and time series prediction (Azad et al. (2014),Bishop (1995),Haykin
(1999),Ouyang and Yin (2014),Wu et al. (2014)).
The present state of NN firmware implementations is such that the execution times for relatively large NNs are of microseconds order, and
it suggests applications even in the so-called realtime systems (Krips et al. (2002)Omondi and Rajapakse (2006)).
This note focuses in the application of NNs
in the approximation of the map manifold of online output injection laws computed from conditioned invariant sets for error limitation of observers in discrete time linear systems. Since the
simulation phase of any implementation is an offline task, the set of training points can be obtained this way based on the computed online output injection laws. The advantage is that the NN
execution time will be several times smaller than
the online computed injection law in the case of
more complex invariant polyhedra and preserves
the feature of overcoming the peak phenomenon.
Moreover, there is not to date any systematic procedure for computing offline output injection laws
for multiple-output systems, making therefore online implementations the best alternative.
The other sections of the paper are structured as preliminary concepts used in the proposed methodology description of the contribution numerical illustrative examples, and concluding remarks.
2
2.1

Figure 1 Signal-flow graph for a single
perceptron.

e(k + 1)  Ae(k) + B1 d(k) + (z(k), k) (3)
z(k)  Ce(k) + (k)
Let the disturbance d belong to a compact 0symmetrical polyhedron D  Rr , and noise measurements to the set N      .  is a
compact 0-symmetrical polyhedron defined by linear inequality constraints,   e  Ge   with
G  Rgn ,   Rm , and it induces the following
set of admissible outputs
Z ()  z  z  Ce + , e  ,   N .
The estimation errors which are consistent
with each z  Z () compose the set
E (z)  e  Ce  z  ,   N .
A polyhedron   Rn , is said to be
conditioned-invariant -contractive with respect
to system (3) if

Preliminaries

Design of Observers With Conditioned Invariant Sets

z  Z () ,   Ae + B1 d +   ,
d  D, e  E(z)  .

Given a linear time-invariant discrete-time system, subject to unknown but bounded disturbances and measurement noise in state-space
form

x(k + 1)  Ax(k) + B1 d(k)
y(k)  Cx(k) + (k),

Actually, a small ultimate boundedness set
confines e(k) for some k in the presence of disturbance and measurement noise
In a few cases for single output systems, a
linear or piecewise linear output injection law 
can be constructed, as seen in Dorea and Pimenta
(2005b). The main advantage is that such laws are
off-line in nature. But the peak phenomenon may
still be present in this case, as shown in Araujo
et al. (2011). For multi-output systems, an offline
injection law may even exist, but a systematic way
to determine its structure is unknown to date for
general systems (Dorea (2006)).

(1)

with x  Rn , d  Rq , y,   Rl , being respectively the system state, the exogenous disturbance, the measurement and the measurement
noise. State estimation can be performed using a
full order observer given by

2.2
x(k + 1)  Ax(k)  (z(k), k)
y(k)  C x(k),

(4)

(2)

Neural Networks

Neural Networks are sets of basic units called neurons, whose diagram representation is shown in
fig. 1. The development of these systems have
experimented a fast growth since they were introduced in (Farley and Clark, 1954) , and belongs to the class of Artificial Intelligence (AI)

where  is a (not necessarily linear time-invariant)
output injection law, a function of z  y  y. The
error (e  x  x) dynamics is henceforth given by

2917

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

The main disadvantage of this online scheme
is noted in systems with fast dynamics. A number
of g linear programms (LPs) with n variables and
g constraints for , plus the linear program (6)
must be solved at each step. It is clear that such
computation can become quite expensive. However, the peak phenomenon can be mitigated if
one employs this approach Araujo et al. (2011).
Since the input-output manifold of online
computed injection laws can be obtained by simulation from the solutions of LPs (6), (7) and
(8), the proposed approach consists in training
multilayer NNs perceptrons to emulate the manifold (z(k)) with high accuracy. The natural
choice for NNs is the feedforward type with backpropagation learning algorithm, and LevenbergMarquardt strategy is suggested to give good convergence for moderate size networks with random
initial weights (Hagan and Menhaj (1994)). The
training data is obtained from the system simulation error trajectories with initial error being random points of the initial confidence polyhedron.
The minimal conditioned invariant polyhedron is
computed by means of the algorithms presented
in Araujo et al. (2011).

Figure 2 Signal-flow graph for MLP with linear
activation function in the output neurons.
techniques. Their main feature is the capability
of learning input-output pattern from given data
and has been successfully used in pattern recognition, time-series prediction and function approximation. In the control systems field, some important applications include modeling of dynamical systems and neural estimators and controllers
(Narendra and Parthasarathy (1990)). In fig. 1,
a flow-graph for a single neuron or perceptron is
depicted, and fig. 2 shows the classical architecture of multilayer perceptrons (MLP). The transfer function of a single perceptron is given by
m
X
y  (
wi xi + b),

4
(5)

4.1

i1

where wi is the i -th input weight, b is the constant
bias and () is the so-called activation function generally a sigmoid hyperbolic tangent or logistic
function.

Numerical Examples

A Second Order System

This example is borrowed from (Le et al., 2011).
The system model is given by



3
 25
0  21
x(k) +
d(k)(9)
1
1 1
50


y(k)  2 1 + (k),


x(k + 1) 
3

The Proposed Approach

In the general case, for a given -contractive
polyedron   e  Ge  , the online computation at each step can be performed as (Dorea
(2006))
min



in which d  1 and   0.2. The confidence
polyhedron of initial error is the box

T
  e0  e0   3 3
.
A minimal conditioned invariant polyhedron
with contraction rate o  0.8 was then computed. This set is seen in fig. 3 together with
the box . A MLP with 9 neurons at hidden
layer is then trained from error trajectories generated by the simulated online output injection law
starting from random initial conditions. A number of five training starting from random initial
weights were tested, with almost the same performance index being obtained for the trained NN.
In fig. 4, a simulation of the neural and the online
observer is shown, starting from an initial condition that does not belong to the training set. A
good fitting was obtained for the two error trajectories. The input-output map of the neural ob
T
server (z)  1 (z) 2 (z)
 z is sketched in
fig. 5. A piecewise affine-like behavior is evident
in this non-linear manifold. This fact had already

(6)

(z(k),k),

s.t. (, z(k)) + G(z(k), k)    ,
where  is a vector representing the worst case of
disturbance action, given by
i  max Gi B1 d
d

(7)

s.t.Dd  w.
The vector  represents the worst case of all
admissible errors associated to a given output z.
It must be computed, row by row, at each step by
i (, z)  max Gi Ae
e,

(8)

s.t. Ge  , N (Ce  z)  .

2918

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Figure 3 Invariant set and initial error set for
the example 1.

Figure 6 Magnetic ball levitation system.
4.2

Magnetic Ball Levitation System

In this classical example, taken from Golnaraghi
and Kuo (2009) and sketched in fig. 6, a discretization with sampling time Ts  2ms was applied, and the linearized, discrete-time model is
given by eq. (10).

1.0001
x(k + 1)   0.1288
0



0.0020
0
1.0001 0.0290  x(k) +
0
0.8178

0
 0.0030  u(k)
(10)
0.1813


0 1 0 x(k) + (k).
y(k) 

The set of the confident constraints on the
initial error is composed by e1   0.005m, e2  
0.1ms and e3   0.1A, and the noise in velocity
measurement is bounded as   0.01ms. By
using the algorithms presented in Araujo et al.
(2011), an as small as possible, 230 faces conditioned invariant polyhedron was computed this
big number of faces indicates that the computation time of the online injection law must be appreciable. This set is showed at fig. 7. Using
a generated training set composed by points of
the trajectories for the error starting from some
edge points in the confidence initial set, the online injection results were used to train a NN
for function approximation with one hidden layer
with 9 neurons and inverse hyperbolic tangent activation function. The good fitting between the
neural and the online manifold is seen in fig. 8.
In figs. 9 and 10, two noise free state trajectories are depicted, respectively, in the error space
and in time domain, one using the online injection law computed for the system and other using the trained NN, and the absence of peak is
notable in the later. Also, the average time for
computation of a 100 steps simulation using a
Intel(R) Core (T M ) i3  2310M CP U @2.10GHz
is showed at tab. 1. It must be noted that the
sim function from Neural Network Toolbox was
used, and still a better runtime was observed for

Figure 4 Error trajectories for online (circle)
and neural (cross) observers.

Figure 5 Input-Output manifold components of
the NN emulating the online injection law.

been observed in previous works, as in (Araujo
et al., 2012).

2919

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Table 1 Mean runtime performance for a 100
steps simulation of the online and neural observers.
Online
Neural
135msstep 7.5msstep

Figure 9 Noise free performance of the observers
in magnetic ball system within invariant
polyhedron.
5

Concluding Remarks

A novel approach which combines the best of both
worlds - the online and the offline injection law was proposed in this paper, by training NNs with
the goal of approximating the input-output manifold of an online output injection law, in the context of observers with error limitation. The piecewise affine like behavior of this laws could be observed in the input-output map captured by NNs.
Two simulation examples were carried out to show
the merit of the proposed approach with respect to
runtime and peak phenomenon mitigation, one of
which a classical control system benchmark found
in the literature.
Future works include the use of NNs to emulate the input-output map for the problem of
static or dynamic output feedback control of constrained systems.

Figure 7 Conditioned invariant polyhedron for
the observer in magnetic ball system.

Acknowledgment
The authors would like to thank their Institutions
and FAPESB for financial support.
References

Figure 8 Fitting of the online observer. The
initial condition does not belong to the initial
conditions n the training set.

Alessandri, A., Baglietto, M. and Battistelli, G.
(2008). Moving-horizon state estimation for
nonlinear discrete-time systems New stability results and approximation schemes, Automatica 44(7) 17531765.

the NN observer. Moreover, in the Simulink simulation on the complete nonlinear model for the
magnetic ball system, the online injection law was
not able to perform the injection law computation
until the end of simulation, and NN was as effective as the online injection law. The better performance in terms of error convergence and peak
absence, with noise at the output for state estimation can be seen in fig. 11.

Alessandri, A., Baglietto, M., Battistelli, G. and
Gaggero, M. (2011). Moving-horizon state
estimation for nonlinear_systems using neural networks, Neural Networks, IEEE Transactions on 22(5) 768780.
Andras, P. (2014). Function approximation using
combined unsupervised and supervised learn-

2920

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Bishop, C. (1995). Neural Networks for Pattern Recognition, Neural Networks for Pattern Recognition, Oxford University Press,
USA.
Blanchini, F. and Miani, S. (2007). Set-Theoretic
Methods in Control, Systems  Control
Foundations  Applications, Springer London, Limited.
Dorea, C. E. T. (2006). Set-invariant estimators for multiple-output discrete-time systems, Decision and Control, 2006 45th IEEE
Conference on, pp. 45384543.
Dorea, C. and Pimenta, A. (2005a). Design of setinvariant estimators for linear discrete-time
systems, Proceedings of the 44th IEEE Conference on Decision and Control, pp. 7235
7240.

Figure 10 Noise free performance of the
observers in magnetic ball system in time
domain.

Dorea, C. and Pimenta, A. (2005b). Set-invariant
estimators for linear systems subject to disturbances and measurement noise, Proceedings of 16th IFAC World Congress.
Farley, B. G. and Clark, W. (1954). Simulation of
self-organizing systems by digital computer,
Information Theory, Transactions of the IRE
Professional Group on 4(4) 7684.
Gauthier, J.-P. and Kupka., I. (2001). Deterministic Observation Theory and Applications,
Cambridge University Press.
Golnaraghi, F. and Kuo, B. (2009). Automatic
Control Systems, Wiley.
Figure 11 Performance of the observers under
severe noise in velocity measurement.

Hagan, M. and Menhaj, M.-B. (1994). Training feedforward networks with the marquardt
algorithm, Neural Networks, IEEE Transactions on 5(6) 989993.

ing, IEEE Transactions on Neural Networks
and Learning Systems 25(3) 495505.

Haimovich, H., Goodwin, G. and Welsh, J.
(2004). Set-valued observers for constrained
state estimation of discrete-time systems
with quantized measurements, Control Conference, 2004. 5th Asian, Vol. 3, pp. 1937
1945 Vol.3.

Araujo, J., Barros, P. and Dorea, C. (2011).
Design of observers with error limitation
in discrete-time descriptor systems A case
study of a hydraulic tank system, IEEE
Transactions on Control Systems Technology
PP(99) 17.

Haykin, S. (1999). Neural Networks A Comprehensive Foundation, International edition,
Prentice Hall International.

Araujo, J. M., Barroso, H. C., Barros, P. R. and
Dorea, C. E. T. (2012). Output feedback control of constrained descriptor systems a case
study of a hydraulic tank system, Proceedings
of the Institution of Mechanical Engineers,
Part I Journal of Systems and Control Engineering 226(3) 429436.

Krips, M., Lammert, T. and Kummert, A. (2002).
Fpga implementation of a neural network
for a real-time hand tracking system, Electronic Design, Test and Applications, 2002.
Proceedings. The First IEEE International
Workshop on, pp. 313317.

Azad, H., Mekhilef, S. and Ganapathy, V. (2014).
Long-term wind speed forecasting and general pattern recognition using neural networks, IEEE Transactions on Sustainable
Energy 5(2) 546553.

Le, V. T. H., Alamo, T., Camacho, E. F., Stoica,
C. and Dumur, D. (2011). A new approach
for guaranteed state estimation by zonotopes, IFAC Word COngress, 2011, Vol. 18,
pp. 92429247 Vol.3.

2921

Anais do XX Congresso Brasileiro de Automática
Belo Horizonte, MG, 20 a 24 de Setembro de 2014

Lin, H., Zhai, G. and Antsaklis, P. J. (2003).
Set-valued observer design for a class of uncertain linear systems with persistent disturbance and measurement noise, International
Journal of Control 76(16) 16441653.
Mini, M. and Padma Suresh, L. (2014). Comparative evaluation of intelligent controller for a
buck-boost converter, International Journal
of Soft Computing 9(3) 143150.
Narendra, K. and Parthasarathy, K. (1990). Identification and control of dynamical systems
using neural networks, Neural Networks,
IEEE Transactions on 1(1) 427.
Omondi, A. and Rajapakse, J. (2006). FPGA Implementations of Neural Networks, Springer.
Ouyang, Y. and Yin, H. (2014). A neural gas
mixture autoregressive network for modelling
and forecasting fx time series, Neurocomputing 135 171179.
Shamma, J. and Tu, K.-Y. (1999). Set-valued
observers and optimal disturbance rejection,
Automatic Control, IEEE Transactions on
44(2) 253264.
Wu, X., Wang, Y., Mao, J., Du, Z. and Li, C.
(2014). Multi-step prediction of time series
with random missing data, Applied Mathematical Modelling 38(14) 35123522.
Yamada, T. (2008). Remarks on tracking method
of neural network weight change for adaptive type neural network feedforward feedback controller, Artificial Life and Robotics
13(1) 286289.
Yang, S., Ting, T., Man, K. and Guan, S.-U.
(2013). Investigation of neural networks for
function approximation, Procedia Computer
Science 17 586594. cited By (since 1996)2.

2922