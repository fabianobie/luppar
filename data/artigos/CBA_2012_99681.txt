Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

ARQUITETURA DE CONTROLE OTIMIZADA PARA RASTREAMENTO VISUAL DE ALVOS
MAURÍCIO GRUZMAN, DOUGLAS B. TAGAWA
Seção de Engenharia Mecânica e de Materiais, Instituto Militar de Engenharia
Praça General Tibúrcio 80, Praia Vermelha, Rio de Janeiro, RJ. CEP 22290-270
E-mails gruzman@ime.eb.br, douglasbt89@hotmail.com

HANS I. WEBER, RUBENS SAMPAIO
Departamento de Engenharia Mecânica, Pontifícia Universidade Católica do Rio de Janeiro
Rua Marquês de São Vicente 225, Gávea, Rio de Janeiro, RJ. CEP 22453-900
E-mails hans@puc-rio.br, rsampaio@puc-rio.br
Abstract This work presents a target tracking system composed with a digital camera and a pan-tilt mechanism. Due to the
relatively long time for image acquisition, target recognition and calculation of the desired pan and tilt angles, a control architecture with two separated loops was used, with the second loop exclusively for actuators control. This allows higher frequency
controllers for the actuators, improving the system performance. To obtain the desired angles, fuzzy logic controllers designed to
behave like a human operator (but in a faster way) were used. The entrances for those controllers are the targets centroid position
at the image captured by the camera and its variation between two consecutive images. Experimental results that support the effectiveness of the proposed control architecture are presented.
Keywords Target tracking systems, fuzzy logic, control, systems with time-delay, pan-tilt systems
Resumo Neste trabalho é apresentado um sistema de rastreamento_de_alvos constituído por uma câmera digital e um mecanismo pan-tilt. Devido ao tempo relativamente longo para a aquisição das imagens pela câmera, reconhecimento do alvo e cálculo dos ângulos desejados de pan e tilt optou-se em utilizar uma arquitetura_de_controle separada em duas malhas, sendo a
segunda utilizada exclusivamente para o controle dos atuadores. Isto permite que o controle dos atuadores seja feito em freqências mais altas, contribuindo, assim, para um melhor desempenho do sistema. Para a geração dos ângulos desejados utilizou-se
um controlador de lógica_fuzzy cujas entradas são a posição do centróide do alvo na imagem adquirida e sua variação entre duas
imagens consecutivas. Este controlador é elaborado para atuar de forma similar a um operador humano, porém mais velozmente.
Por fim são apresentados resultados experimentais onde se constata a eficiência da arquitetura_de_controle escolhida.
Palavras-chave 

1

Introdução

Sistemas de rastreamento_visual de alvos têm
vasta aplicação tanto no meio militar como no civil.
Tais sistemas possuem geralmente câmeras digitais e
são comumente empregados em sistemas de segurança, monitoramento de veículos no trânsito, robótica,
vigilância área, etc. No meio militar são empregados,
ainda, em bombas inteligentes, sistemas de mira de
armamentos e em mísseis. No entanto, como as câmeras possuem ângulos de visão limitados, é necessário movê-las de modo que o alvo seja mantido dentro
de seu campo de visão. Nas aplicações mais sofisticadas é comum utilizarem-se câmeras com ângulos
de visão pequenos, conforme se observa em Waldmann (2001), pois há necessidade de se ter muito
zoom. Então é imprescindível o uso de mecanismos
eficientes para movimentá-la.
A configuração mecânica mais comum destes mecanismos é do tipo pan-tilt, que fornece dois graus de
liberdade angular a uma câmera, conforme se observa
na Figura 1. O eixo vertical é chamado de eixo de
pan e o horizontal de eixo de tilt. Acoplados a
cada eixo encontram-se atuadores.

ISBN 978-85-8001-069-5

Figura 1. Sistema pan-tilt

A configuração acima permite apontar o eixo ótico da
câmera para o objeto de interesse, no entanto, não
permite um controle de rotação em torno deste eixo.
Se o vetor velocidade_angular da base possuir alguma
componente na direção do eixo ótico e for importante
que a imagem capturada não gire, deve-se prever
mais um grau de liberdade de rotação spin para a
câmera.

2 Arquitetura de Controle
A arquitetura_de_controle deste tipo de sistema
pode ser separada em duas fases. Na primeira identi-

890

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

fica-se qual vem a ser o alvo na imagem capturada e
decide-se de quanto se devem girar os eixos de pan
e tilt de modo a manter o alvo dentro dos limites de
visão da câmera, preferencialmente próximo ao seu
centro. Na segunda fase busca-se levar os eixos para
as posições desejadas. Esta fase trata, portanto, de
um problema clássico de controle de posicionamento
angular de eixos. Uma otimização desta arquitetura
ocorre ao separar cada fase em diferentes malhas,
pois o tempo de atualização da saída da primeira fase
(sinal de referência para o controle dos atuadores)
costuma ser da ordem de dezenas de milisegundos,
enquanto que o controle dos atuadores deve ser feito
com atrasos de tempo bem menores, pois atrasos
grandes prejudicam o seu desempenho. Caso seja
utilizada uma única malha, o intervalo de tempo para
a atualização do sinal de controle dos atuadores será
a soma dos atrasos de cada fase. Na Figura 2 é apresentado o esquema da arquitetura_de_controle.

ser calculados baseando-se na posição de algum ponto de interesse do alvo na imagem adquirida, como o
seu centróide (pode-se considerar o ângulo de referência para o eixo de pan proporcional  coordenada do centróide em relação ao centro da imagem adquirida, medida em um eixo horizontal e, o de tilt,
proporcional  coordenada medida em um eixo vertical).
No entanto, técnicas que utilizam também a variação
da posição do alvo podem contribuir para um melhor
desempenho do sistema devido  sua ação antecipatória. Conhecendo-se a dinâmica do sistema mecânico
pan-tilt, do corpo no qual o sistema é montado ou
do alvo é possível utilizar métodos ainda mais eficazes para tentar antecipar o posicionamento do alvo
na imagem num instante posterior (Bapna, 1998 Li
et al., 2003). Entretanto, é raro se ter a disposição
modelos adequados de cada um, especialmente do
alvo.
Quando se utiliza um operador humano nesta fase,
todas as etapas, com exceção da aquisição das
imagens, são executadas por ele. O operador, a partir
da imagem obtida identifica o alvo e, baseado em sua
posição e em seu movimento no plano da imagem,
gera comandos (por meio de dispositivos como
joysticks, teclados, etc) para a próxima fase. Neste
caso o período para a atualização do sinal de saída da
primeira fase torna-se ainda maior devido ao tempo
necessário para a conclusão do processo percepçãodecisão-ação por parte do operador humano.

Figura 2. Arquitetura de controle

Figura 3. Operador Humano na fase 1

2.1 Fase 1
Esta fase é mais lenta em decorrência dos processos nela contidos. Ela pode ser feita automaticamente ou através de um operador humano. Quando
ela é automatizada possui três etapas aquisição da
imagem, processamento da imagem adquirida para
identificação de qual é o alvo e cálculo dos ângulos
de referência para os eixos de pan e tilt.
A aquisição de imagem por câmeras digitais é geralmente feita a taxas da ordem de 30 quadros por segundo. Câmeras mais sofisticadas podem funcionar a
taxas bem mais altas, mas, em contrapartida, são mais
caras. No modo de funcionamento automático a imagem adquirida precisa, ainda, ser processada para se
identificar o alvo. Dependendo da sofisticação do
método empregado para o reconhecimento do alvo, o
tempo que se adiciona ao processo pode ser relevante. A última etapa, que usualmente é a mais rápida,
consiste no cálculo dos ângulos de referência que são
enviados para a próxima fase. Estes ângulos podem

ISBN 978-85-8001-069-5

2.2 Fase 2
Nesta fase utilizam-se controladores com a finalidade de levar cada eixo do sistema aos ângulos desejados. Se os atuadores forem motores de corrente
contínua, a saída dos controladores_podem ser valores de tensão. As entradas são os ângulos de referência obtidos na fase 1 menos os ângulos atuais dos
eixos. Diversos tipos de controladores_podem ser
utilizados nesta fase. Quando não se dispõe de um
modelo_dinâmico da planta podem-se utilizar controladores independentes para cada eixo como, por exemplo, o PID (Astrm, 2008), ou suas variações P,
PD ou PI. Este é o tipo mais comum de controle empregado nos sistemas_de_automação atualmente e tem
como principal atrativo sua simplicidade. Na Figura 4
encontra-se o esquema da fase 2, para um atuador.

891

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

saída. O sinal de referência para o servo-motor é fornecido na forma de um sinal de tensão PWM com 5V
de amplitude e freqência de 50 Hz (período de
20ms). A largura do pulso (P) varia de 0,5 ms (valor
correspondente a um ângulo de referência de -90)
até 2,5 ms (valor correspondente a um ângulo de referência de 90), conforme se observa na Figura 7.
Outra vantagem do servo-motor é que ele pode ser
alimentado por uma fonte c.c. comum, dispensando o
uso de amplificadores de potência.
Figura 4. Esquema do controle na fase 2

Como esta fase encontra-se toda em uma malha independente da primeira, é possível que ela trabalhe em
freqências bem mais altas, contribuindo assim para
um melhor desempenho do sistema como um todo.
Pode-se, inclusive, empregar controladores analógicos nesta fase. Uma solução de baixo_custo e eficaz
consiste na utilização de servo-motores (Kikuchi,
2007 Liu, 2004 Antolovic, 2001). Nestes atuadores
os efeitos do atrito seco e folgas são pequenos, o que
vem a ser uma característica importante, pois ambos
prejudicam significativamente o desempenho do controlador (Gruzman, 2011 Gruzman, 2010). Nas figuras 5 e 6 apresenta-se o tipo de servo-motor empregado no sistema.

Figura 7. Sinal PWM em função do tempo

3 Bancada de Testes
O sistema foi montado utilizando-se dois servomotores, conforme se observa na Figura 8. Para o
movimento de pan empregou-se um servo-motor da
marca Hobbico , modelo CS-80, alimentado por
uma fonte de corrente contínua de 6V e para o movimento de tilt um servomotor da marca Hitech,
modelo HS 322 HD, alimentado por uma fonte de
corrente contínua de 5V. Para a aquisição das imagens foi utilizada uma câmera digital da marca Phillips, modelo SPC 1030NC, com saída USB, funcionando a uma taxa de 30 quadros por segundo e com
uma resolução de 320 pixels por 240 pixels.

Figura 5. Servo-motor (fotografia)

Figura 8. Sistema pan-tilt utilizado na bancada de testes

Figura 6. Servo-motor (desenho esquemático)

Os servo-motores realizam todas as operações constantes da fase 2, representadas na Figura 4, pois possuem um motor_de_corrente_contínua (c.c.), um controlador próprio - geralmente proporcional (Sono,
2008) - e um potenciômetro conectado ao eixo de

ISBN 978-85-8001-069-5

Conforme discutido anteriormente, toda a fase 2 é
realizada pelos servo-motores. Para a fase 1 foi utilizado um computador e um programa elaborado com
o software LabView onde foram implementadas
todas as operações da fase 1. Entretanto, para produzir os sinais PWM para os servo-motores foi utilizada
uma placa multifuncional da marca National Instruments, modelo USB-6229 de 16 bits. Esta placa

892

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

conecta-se ao computador por meio de um cabo
USB.
Na fase 1 há a opção de se ter funcionamento automático ou manual (através de um operador humano).
Para permitir o funcionamento manual foi empregado
um joystick para PC com saída USB. O esquema
da bancada de testes encontra-se na Figura 9.

incrementos) podem-se gerar movimentos mais suaves e precisos para a câmera.
Quando se está operando no modo automático utiliza-se o método de reconhecimento computacional de
imagens descrito a seguir.
Inicialmente delimita-se uma região da imagem que o
contenha o alvo, configurando assim uma descrição
do objeto de interesse. Esta região é, então, armazenada na memória como padrão de comparação. Nos
instantes seguintes, conforme a imagem é atualizada,
realiza-se uma busca pelo padrão armazenado, de
modo a indicar a nova posição do alvo. A busca pelo
padrão, ao longo do domínio da imagem, é feita através da operação de correlação-cruzada, dada por

( f  g )( x, y ) 
Figura 9. Esquema experimental

(1)

m 1 n 1

  f (i, j ) g ( x  i, y  j )
i 0 j  0

No painel frontal do programa implementado em
LabView há uma tela onde é apresentada a imagem
adquirida pela câmera. A posição de cada pixel da
imagem é definida com auxílio de um sistema de
coordenadas cuja origem é o centro da imagem, conforme se observa na Figura 10.

Figura 10. Eixos coordenados na imagem obtida pela câmera

No modo manual o operador movimenta o joystick
de modo a manter o alvo no centro da imagem. Ou
seja, quando o operador desejar que o alvo seja levado mais para a direita na imagem irá mover o joystick para direita, com isso a câmera irá girar para
esquerda. Quando desejar que o alvo seja levado
mais para esquerda irá mover o joystick para esquerda, com isso a câmera irá girar para direita.
Quando o operador desejar que o alvo seja levado
mais para cima irá mover o joystick para frente,
com isso a câmera irá girar para baixo. Quando desejar que o alvo seja levado mais para baixo irá mover
o joystick para trás, com isso a câmera irá girar
para cima. Pode-se notar que são comandos que irão
gerar incrementos nos ângulos de referência enviados
para a fase 2, ao invés de se ter cada posição no sentido esquerda-direita do joystick correspondendo a
um determinado ângulo pan de referência e cada
posição no sentido frente-trás do joystick correspondendo a um determinado ângulo tilt de referência. Com essa estratégia de comando (geração de

ISBN 978-85-8001-069-5

onde f representa o padrão de comparação, com resolução m x n, e g representa a imagem. A operação
resulta em valores máximos nas regiões em que há
alta correspondência da imagem com o padrão, indicando a possível nova posição do alvo.
O método foi implementado no LabView através
das funções IMAQ Learn Pattern 2, que armazena a
região da imagem que contém o alvo, e IMAQ Find
CoordSys (Pattern) 2, que realiza a correlaçãocruzada entre o padrão e a imagem, tendo como saída
a posição do alvo localizado. As funções, parte do
pacote IMAQ Vision, permitem reconhecer alvos
rotacionados de 0 a 360 no plano da imagem, assim
como variações de escala na ordem de até 5,
através de sucessivas rotações do padrão e operações
de correlação.
A operação de correlação-cruzada pode consumir
tempo apreciável, em comparação com a taxa de
quadros por segundo obtida pelo dispositivo de captura de imagem. Considerando que entre os instantes
de captura de cada quadro, o alvo apresenta pequenos
deslocamentos, pode-se restringir a área de busca no
cálculo da correlação-cruzada, e reposicioná-la a
partir de posições anteriores do alvo.
O método proposto é esquematizado na Figura 11.
Numa primeira etapa, é feito o posicionamento manual da câmera, de modo a centralizar o alvo na imagem. Quando o alvo estiver devidamente emoldurado
por uma região de interesse na imagem o padrão é
armazenado na memória, sendo utilizado para as operações de correlação. É atribuída uma pontuação mínima para o maior valor encontrado nas correlações,
como critério de tolerância para a similaridade encontrada. Caso a pontuação seja satisfatória, são extraídas as coordenadas do alvo, a área de busca é
reposicionada a partir da nova posição do alvo e é
adquirida a próxima imagem, reiniciando-se o ciclo.
No caso da pontuação ser insuficiente, a correlação é
calculada para toda a imagem, considerando a possibilidade do alvo ter escapado da área de busca estipu-

893

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

lada. Verifica-se novamente a pontuação obtida, e se
esta for insuficiente, considera-se o alvo perdido.

Figura 11. Fluxograma do algoritmo de rastreamento

No modo automático é necessário, ainda, utilizar
controladores que gerem os incrementos para os
ângulos de pan e tilt sem a interferência de um
operador. É importante salientar que se trata de um
caso pouco convencional de controle, pois são
gerados incrementos para ângulos de referência
baseando-se no posicionamento do alvo e de sua
velocidade em uma imagem. Estes controladores não
dispõem dos ângulos de pan e tilt nem de
modelos dinâmicos do alvo, do mecanismo pan-tilt
e do corpo no qual o mecanismo é montado. Além
disso, devido ao tempo relativamente grande para a
aquisição e processamento da imagem, tem-se um
processo bastante lento para a atualização da saída
dos controladores presentes na fase 1. Assim,
estratégias convencionais podem ser difíceis de
serem empregadas.
Uma alternativa atraente parece ser o uso de algum
controlador baseado em heurística, como o controlador de lógica_fuzzy (FLC) do tipo Mamdani (Pasino e
Yurkovich, 1998). Este controlador é bastante flexível, pois permite implementar um mapeamento não
linear entre as entradas e saídas e, devido  sua natureza heurística, aproxima-se mais da forma de pensar
humana do que os sistemas de lógica tradicional.
Nos FLC, uma estratégia de controle lingística, baseada nos conhecimentos de algum especialista, é
convertida em uma estratégia de controle_automático.
Serão empregados dois FLC independentes, um para
gerar os incrementos para o ângulo de referência de
pan e o outro para o de tilt. As entradas do FLC

ISBN 978-85-8001-069-5

que gera incrementos para o ângulo de referência de
pan são
- Entrada 1 a coordenada horizontal do centróide do
alvo no plano da imagem (x), medida em pixels, dividida pelo valor máximo em pixels que esta coordenada pode ter (para a configuração utilizada na câmera
são 160 pixels). É, portanto, um valor adimensional
que varia entre -1 e 1 e será chamado de X.
- Entrada 2 a variação de X entre duas leituras consecutivas que será chamada de X. Esta variável relaciona-se com a velocidade do alvo no plano da imagem. Se X for positivo o alvo estará se movendo
para a esquerda na imagem, se for negativo para a
direita. O valor de X é obtido subtraindo-se o penúltimo valor medido de X do último valor medido
de X.
As entradas do FLC que gera incrementos para o
ângulo de referência de tilt são
- Entrada 1 a coordenada vertical do centróide do
alvo no plano da imagem (y), medida em pixels, dividida pelo valor máximo em pixels que esta coordenada pode ter (para a configuração utilizada na câmera
são 120 pixels). É, portanto, um valor adimensional
que varia entre -1 e 1 e será chamado de Y.
- Entrada 2 a variação de Y entre duas leituras consecutivas que será chamada de Y. Esta variável relaciona-se com a velocidade do alvo no plano da imagem. Se Y for positivo o alvo estará se movendo
para baixo na imagem, se for negativo para cima. O
valor de Y é obtido subtraindo-se o penúltimo valor
medido de Y do último valor medido de Y.
Os ângulos de referência são enviados para fase 2 na
forma de sinais PWM, cujas larguras dos pulsos (PX
e PY) são proporcionais a estes ângulos. Por isso as
saídas dos FLC devem ser incrementos (PX e PY),
em milisegundos, para os valores das larguras de
pulsos PX e PY obtidas na última execução da fase 1.
Os conjuntos_fuzzy correspondentes s variáveis de
entrada e de saída estão representados por suas funções de pertinência, Figura 12. Os eixos verticais das
funções de entrada correspondem ao grau de pertinência (). Utilizam-se cinco funções de pertinência
relativas aos conjuntos_fuzzy, chamadas de NG (negativo grande), NP (negativo pequeno), Z (zero), PP
(positivo pequeno) e PG (positivo grande). A base de
regras encontra-se na tabela 1.
Tabela 1. Base de Regras.

Entrada
1

NG

NG
NG

Entrada 2
NP Z PP
NG NP NP

PG
Z

NP

NG

NP

NP

Z

PP

Z

NP

NP

Z

PP

PP

PP

NP

Z

PP

PP

PG

PG

Z

PP

PP

PG

PG

894

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

podem-se utilizar ganhos, conforme o desenho da
Figura 13, que multiplicam as entradas (KX, KY, KX
e KY) e saídas (KPX ou KPY), permitindo ajustes
sem que se tenha que refazer todas as funções de
pertinência.

Figura 12. Funções de pertinência (2 entradas e 1 saída para cada
FLC)

A função de pertinência relativa ao conjunto fuzzy
zero da entrada 1 constitui-se de um trapézio. Isso
faz com que as coordenadas do centróide sejam consideradas zero quando estiverem compreendidas entre -0.1 e 0.1. Geralmente não se consegue levar o
centróide do alvo exatamente para o centro da imagem quando se utiliza esta função de pertinência para
Z, no entanto, caso sejam utilizadas funções de pertinência triangulares para Z o sistema permanecerá
oscilando em torno da posição desejada, pois
a) quando o centróide do alvo estiver parado nas proximidades do centro da imagem, porém não exatamente no centro, o sistema irá acusar um pequeno
erro. Como a saída do FLC é incremental este erro
fará com que a saída permaneça aumentando até que
o motor irá mover a câmera. No entanto, se na nova
posição o alvo não ficar exatamente no centro da
imagem a ação anterior irá se repetir, e assim por
diante
b) pequenos erros no processo de obtenção do centróide da imagem e eventuais ruídos podem levar a
pequenas variações no valor das coordenadas do centróide, levando s mesmas conseqências do problema discutido no parágrafo anterior.
Com relação  entrada 2, o trapézio da função pertinência relativa ao conjunto fuzzy zero pode ter a
aresta superior menor, pois agora o que se quer evitar
é que a variação na posição do centróide da imagem
devido aos erros discutidos no item b), entre duas
leituras consecutivas, gere variações no sinal de saída
do FLC. Utilizam-se, então, os limites -0.01 e 0.01
para esta aresta, pois se considera que os erros mencionados provavelmente estarão limitados entre +
0.01, que corresponde a + 1.6 pixels no eixo horizontal e + 1.2 pixels no vertical quando se utiliza uma
câmera com resolução de 320pixels x 240pixels.
Pode-se observar na Figura 12 que os conjuntos
fuzzy das variáveis de entrada variam entre -1 e 1. O
mesmo ocorre para as variáveis de saída. No entanto,

ISBN 978-85-8001-069-5

Figura 13. Utilização de ganhos para se evitar alterações nas funções de pertinência

Por fim, cabe ressaltar que usualmente há limites para
os ângulos com que os servo-motores podem trabalhar. Estes limites vêm tanto de restrições físicas do
mecanismo como dos próprios servo-motores em si,
que geralmente não giram em valores inferiores a 90 nem superiores a 90. Assim, estabeleceu-se neste
trabalho que antes de se enviar o sinal PWM para os
servo-motores o sinal irá passar por um bloco de saturação, de modo a se assegurar que 0,5ms<P<2,5ms,
conforme indicado na Figura 14. O símbolo P- indica
o sinal antes da passagem pelo saturador e P+ após a
passagem. Para simplificar a figura omitiu-se o subscrito X (ou Y).

Figura 14. Limites de saturação para o sinal PWM

Se a coordenada do centróide demorar a se aproximar
de zero, o valor de P- pode se tornar excessivamente
grande (ou pequeno) e continuar a crescer (ou diminiuir), mesmo que P+ fique saturado (isto é, atingir
seu limite superior de 2,5ms ou inferior de 0,5 ms). O
sinal P+ permanecerá saturado quando P mudar de
sinal e pode levar bastante tempo antes que P+ adentre nos limites de saturação, prejudicando o desempenho do sistema. Para evitar isso basta inserir a seguinte linha de comando imediatamente antes de se
adicionar PX  PX
SE (PX+2,5ms E PX>0) OU (PX+0,5ms E
PX<0) ENTÃO PX0.
E a seguinte linha de comando imediatamente antes
de se adicionar PY  PY

895

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

SE (PY+2,5ms E PY>0) OU (PY+0,5ms E
PY<0) ENTÃO PY0.
As linhas de comando acima, colocadas no final da
fase 1, atuam tanto durante o controle_automático
como durante o controle manual.
4 Resultados Experimentais
Para a escolha dos ganhos KX, KX e KPX foram
feitos experimentos que consistiram em se posicionar, inicialmente, um alvo na frente da câmera com
um determinado erro angular de azimute. Em seguida, ligou-se o servo-motor de pan, utilizando-se
diferentes valores para KX, KX e KPX e registraramse os valores obtidos experimentalmente de
a) M percentual de overshoot (M) da curva
x(t)
b) T0.1 tempo para esta curva adentrar num limite de
0,1x e
c)  ess percentual do módulo do erro em regime
permanente.

Figura 16. Esquema do dispositivo para movimentação do alvo 
frente da câmera

Para uma velocidade_angular do disco de aproximadamente 1,2 rads, foram obtidos os resultados apresentados na Figura 17. Os servo-motores só foram
acionados após cerca de 7 segundos (ver setas na
Figura 17) e o teste durou 30 segundos.
Observa-se que a amplitude de x foi reduzida de cerca de 110 pixels para cerca de 50 pixels e a amplitude de y foi reduzida de cerca de 110 pixels para cerca
de 30 pixels. No entanto, como a atualização do sinal
de saída da primeira fase e os servo-motores utilizados na bancada são relativamente lentos, pode-se
considerar que tal redução é significativa, indicando
que o controle funciona adequadamente. A atualização do sinal de saída da primeira fase é relativamente
lenta devido ao processamento da imagem adquirida
pela câmera e, no caso dos servo-motores, o motivo é
a significativa taxa de redução de velocidades no
trem de engrenagens.

Figura 15. Parâmetros obtidos do experimento

Os mesmos procedimentos foram repetidos posicionando-se o alvo  frente da câmera com um erro angular de elevação e ligando-se o servo-motor de
tilt, de modo a subsidiar a escolha dos ganhos KY,
KY e KPY. Dos resultados obtidos observou-se que,
utilizando os ganhos KXKXKY KY1 e
KPXKPY0,05, conseguiu-se manter M abaixo de
20, ess abaixo de 5 e T0.1 abaixo de 0,5s para
ambos os eixos.
Para verificar se o sistema consegue acompanhar um
alvo em movimento de forma adequada, montou-se
um experimento no qual um alvo foi fixado num disco,  frente da câmera, que por sua vez é posto para
girar por um motor, conforme se observa na Figura
16.

ISBN 978-85-8001-069-5

Figura 17. Resultados do experimento no modo automático com
alvo em movimento

Na Figura 18 encontram-se os resultados do experimento realizado no modo manual onde, através de
um joystick, um operador buscou manter o alvo no
centro da imagem. Os servo-motores só foram acionados após cerca de 4 segundos (ver setas na Figura
18) e o teste durou 30 segundos.

896

Anais do XIX Congresso Brasileiro de Automática, CBA 2012.

Comparando-se os resultados do experimento realizado no modo automático com o realizado no modo
manual, observa-se a superioridade do primeiro modo, pois se conseguiu com ele manter o alvo mais
próximo do centro da imagem adquirida pela câmera.

lhidos para overshoot máximo, erro máximo em
regime_permanente e tempo de acomodação.Utilizando-se um mecanismo com diferentes
massas e inércias, mas os mesmos atuadores, novos
ajustes precisariam ser feitos no FLC (sem quaisquer
alterações nos controladores internos dos servomotores).
Referências Bibliográficas

Figura 18. Resultados do experimento no modo manual com alvo
em movimento

5 Conclusões
Este trabalho apresentou uma estratégia de controle para um sistema pan-tilt de rastreamento de
alvos onde não se dispõe do modelo_dinâmico da
planta, do alvo nem dos atuadores. Além disso, o
processo de aquisição de imagens e reconhecimento
do alvo é relativamente demorado para fins de controle, durando cerca de 0,035s. Separou-se a arquitetura_de_controle em duas fases de modo a permitir
que a malha_de_controle dos atuadores pudesse funcionar em freqências mais altas, contribuindo assim
para um melhor desempenho do sistema. A geração
dos ângulos de referência para os atuadores ficou
contida na primeira fase, onde se fez uso de controladores de lógica_fuzzy (FLC). Optou-se por este tipo
de controlador devido  natureza pouco convencional
do problema, que dificulta o emprego de controladores tradicionais. Nos FLC empregou-se uma estratégia semelhante  utilizada por operadores humanos
que, baseando-se apenas no posicionamento do alvo
e de sua velocidade na imagem adquirida pela câmera, movem um joystick gerando incrementos para
os ângulos de referência enviados s malhas_de_controle dos atuadores. Para se verificar o funcionamento da arquitetura_de_controle foi realizado um teste no
qual se constatou que o sistema consegue perseguir o
alvo adequadamente e de forma superior a um operador humano.
Apesar de não se conhecer os ganhos dos controladores internos dos servo-motores foi possível ajustar os
ganhos dos FLC da fase 1 de modo a levar o sistema
para a posição desejada atendendo a critérios esco-

ISBN 978-85-8001-069-5

Antolovic, D. (2001). Development of a Real Time
Vision System for an Autonomous Model
Airplane. MSc Dissertation. Department of
Computer Science, Indiana University, Indiana.
Astrm. K.J. (2008). Feedback Systems an Introduction for Scientists and Engineers. Princeton
University Press, New Jersey.
Bapna, D. (1998). Payload Pointing from Mobile
Robots. PhD Thesis. The Robotics Institute,
Carnegie Mellon University, Pittsburg.
Gruzman, M. (2011). Sistema de Acompanhamento
de Alvos Montado em um Corpo em Movimento. Tese de Doutorado, Departamento de Engenharia Mecânica, PUC-Rio.
Gruzman, M. Weber, H.I. Menegaldo, L.L. (2010).
Modelagem de um Sistema de Posicionamento
com Folga e Atrito Seco. VI Congresso Nacional de Engenharia Mecânica, Campina
Grande.
Kikuchi, D.Y. (2007). Sistema de Controle Servo
Visual de uma Câmera Pan-Tilt com Rastreamento de uma Região de Referência. Dissertação de Mestrado. Departamento de Engenharia Mecatrônica e de Sistemas Mecânicos, Escola Politécnica da Universidade de São Paulo, São Paulo.
Li, X.R.A Jilkov, V.P. (2003). Survey of Maneuvering Target Tracking. Part I Dynamic Models.
IEEE Transactions on Aerospace and
Eletronic Systems, Vol. 39, No. 4, pp.
13331364.
Liu, T.L. (2004). The Development of a TargetLockup Optical Remote Sensing System for
Unmanned Aerial Vehicle. Masther Thesis.
Institute of Aeronautics and Astronautics, National Cheng Kung University, Taywan.
Pasino, K.M. Yurkovich, S. (1998). Fuzzy Control.
Addison-Wesley Longman, California.
Sono, T.S.P. (2008). Projeto de um Sistema de Controle Sub-atuado para uma Prótese de Mão.
Dissertação de Mestrado. Seção de Engenharia Mecânica e de Materiais, IME.
Waldmann, J. (2001). Modeling and Control of an
Imaging Seeker for a Visually Guided Missile.
III SBEIN  Simpósio Brasileiro de Engenharia Inercial, Rio de Janeiro.

897