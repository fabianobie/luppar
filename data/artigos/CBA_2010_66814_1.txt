XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

TEORIA DO CAOS APLICADA  DEFINIÇÃO DO CONJUNTO DE ENTRADAS DE MODELOS NEURAIS AUTÔNOMOS PARA PREVISÃO DE CARGA EM CURTO PRAZO
VITOR HUGO FERREIRA, ALEXANDRE P. ALVES DA SILVA
Departamento de Engenharia Elétrica, Universidade Federal Fluminense (UFF), Rua Passo da Pátria,156,
Sala 509, Bloco D, CEP 24210-240, Niterói, RJ, Brasil
Programa de Engenharia Elétrica, PEE-COPPE, Universidade Federal do Rio de Janeiro (UFRJ), C.P. 68504,
CEP 21945-972, Rio de Janeiro, RJ, Brasil.
E-mails vitor@vm.uff.br, alex@coep.ufrj.br
Abstract After 1991, the literature on load forecasting has been dominated by neural network based proposals. However, one
major risk in using neural models is the possibility of excessive training data approximation, i.e., overfitting. The extent of nonlinearity provided by neural network based load forecasters, which depends on the input space representation, has been adjusted
using heuristic procedures. The empirical nature of these procedures makes their application cumbersome and time consuming.
Autonomous modeling including automatic input selection and model complexity control has been proposed in recently for
short-term load forecasting. However, these techniques requires the specification of the initial input set that will be processed by
the model in order to select the most relevant variables. This paper explores chaos theory as a tool from non-linear time series
analysis to automatic select the lags of the load series data that will be used by the autonomous neural models. In this paper,
Bayesian inference applied to multi-layered perceptrons and relevance vector machines are used in the development of autonomous neural models.
Keywords Load forecasting, artificial neural networks, input selection, Bayesian inference, multi-layered perceptron, relevance vector machines.
Resumo Após 1991, a literatura sobre previsão_de_carga passou a ser dominada por propostas baseadas em modelos neurais.
Entretanto, um empecilho na aplicação destes modelos reside na possibilidade do ajuste excessivo dos dados, i.e, overfitting. O
excesso de não-linearidade disponibilizado pelos modelos neurais de previsão_de_carga, que depende da representação do espaço
de entrada, vem sendo ajustado de maneira heurística. Modelos autônomos incluindo técnicas automáticas e acopladas para seleção_de_entradas e controle de complexidade dos modelos foram propostos recentemente para previsão_de_carga em curto prazo.
Entretanto, estas técnicas necessitam da especificação do conjunto inicial de entradas que será processado pelo modelo visando
determinar aquelas mais relevantes. Este trabalho explora a teoria do caos como ferramenta de análise não-linear de séries_temporais na definição automática do conjunto de atrasos de uma dada série de carga a serem utilizados como entradas de modelos neurais autônomos. Neste trabalho, inferência Bayesiana aplicada a perceptrons_de_múltiplas_camadas e máquinas de vetores relevantes são utilizadas no desenvolvimento de modelos neurais autônomos.
Palavras-chave .

1

modelagem indesejada do ruído e a conseqente
redução da capacidade de generalização do modelo.
Modelos neurais autônomos de previsão, incluindo métodos analíticos e automáticos para seleção
de entradas, controle de complexidade e escolha do
modelo, são necessários visando reduzir a intervenção de especialistas na modelagem, possibilitando a
extensão destes modelos ao nível de barramento.
RNAs com estas características vem sendo propostas
na literatura de previsão_de_carga (Ferreira e Alves da
Silva, 2007), porém ainda requerendo a definição de
um conjunto inicial de entradas para utilização das
técnicas propostas. Visando ampliar o nível de automatismo destas metodologias, técnicas de seleção de
entradas baseadas somente nas séries em análise são
necessárias. Conhecidas como técnicas de filtragem
(Guyon e Elisseeff, 2003), estes métodos independem do modelo de previsão utilizado.
Este trabalho investiga a aplicação da teoria do
caos como ferramenta para seleção do conjunto inicial de atrasos a serem utilizados como entradas de
modelos neurais autônomos para previsão_de_carga
em curto prazo. Incluindo técnicas para seleção automática das entradas mais relevantes de forma aco-

Introdução

A tomada de decisão na operação de sistemas de
potência, abrangendo desde o despacho_econômico
até a comercialização de energia, depende do conhecimento do comportamento futuro da carga. Vários
métodos para previsão_de_carga vêm sendo propostos
nos últimos anos, com destaque para as redes_neurais
artificiais (RNAs) (Hippert, et.al., 2001). As RNAs
vêm apresentando desempenho superior quando
aplicadas a problemas multivariados envolvendo
bases de dados de elevada cardinalidade, como é o
caso de previsão_de_carga. Mesmo sendo mais robustas, questões críticas como a representação do espaço
de entrada e o controle de complexidade das RNAs
ainda não mereceram a devida atenção.
A seleção_de_entradas constitui uma das tarefas
mais importantes na previsão_de_carga. Técnicas nãolineares de extração_de_características utilizam somente informação da série em estudo, sendo necessária uma abordagem mais orientada a modelos neurais. O controle de complexidade de RNAs visa adequar o nível de não-linearidade disponibilizado 
regularidade apresentada pelos dados, evitando a
4439

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

x

plada com o controle de complexidade das estruturas
e seleção do modelo de previsão, neste trabalho são
estudadas duas metodologias inferência Bayesiana
aplicada a perceptrons_de_múltiplas_camadas, do
inglês multi-layered perceptron (MLP) (Ferreira e
Alves da Silva, 2007) máquinas de vetores relevantes, do inglês relevant vector machines (RVMs)
(Ferreira e Alves da Silva, 2009). As metodologias
são testadas utilizando três bases de dados de domínio público, as quais são apresentadas na seção 4.

dado por (3) seja equivalente quele no espa-

ço original X  D . Na existência ilimitada de dados, ausência de ruído e supondo a existência de um
mapeamento   x   d  D e seu inverso

1  X  

D



d

, ambos suaves, contínuos, biuní-

vocos e continuamente diferenciáveis, x 

d

será

uma imersão de X 
se d  2D para  escolhido arbitrariamente. Apesar de dedicar atenção somente  dimensão d , em aplicações práticas a escolha de  também é vital na obtenção do espaço reconstruído (Abarbanel et.al., 1993).
Existem diversos critérios propostos na literatura
para definição de  , baseados em argumentos geométricos e estatísticos, com os últimos sendo mais
utilizados (Kantz e Schreiber, 1997). Dentre os métodos estatísticos, o estudo da função_de_autocorrelação amostral de x  k  , rxx  k  , é a técnica mais
D

2 Teoria do Caos
O desenvolvimento da teoria do caos encontra
motivação no estudo de sistemas_dinâmicos sensíveis
s condições iniciais. Um sistema dinâmico
F  X   D  D em um espaço_de_estados

X

d

D

pode ser definido pela seguinte expressão
(1)
X  k  1  F  X  k 
Em sistemas determinísticos como o da equação
(1), a partir do estado atual X  k  1 , todos os esta-

simples. Buscando um compromisso entre compressão do atrator e reconstruções baseadas em direções
não-correlacionadas, o primeiro mínimo do módulo
de rxx  k  pode ser usado como estimativa para  .

dos subjacentes do sistema podem ser obtidos. Assim, além de depender de F  X  , a trajetória do

Apesar de simples, de uma maneira geral a definição
de  baseada na análise de rxx  k  não evita o confi-

sistema depende do estado inicial do mesmo. O conjunto de condições iniciais que conduzem assintoticamente o sistema para uma dada região do espaço
são chamadas bases de atração para esta região, denominada atrator (Kantz e Schreiber, 1997).
As definições acima são válidas no espaço multidimensional ao qual o sistema F  X  está confina-

namento do atrator, visto que interdependências nãolineares podem comprimir o mesmo em trajetórias
desta natureza.
A teoria da informação fornece índices para
mensuração de relacionamentos gerais entre variáveis aleatórias. A informação mútua I x  r  mede o

do. Contudo, na prática somente registros escalares
x  k  , k  1, 2,..., N , são disponíveis através de uma

ou seja, redução na incerteza sobre x  k  devido ao

função de medição s  X  

D



grau de informação que x  k  r  traz sobre x  k  ,
conhecimento de x  k  r  . Utilizando no cálculo

, ou seja,

x  k   s  X  k     k 

das probabilidades envolvidas, I x  r  é dada por

(2)

I x  r   H x  0  H x  r   H xx  r 

onde   k  representa o ruído de medição.
A função s  X  comprime a informação multi-

p

H x  r    P  x  k  r   i  

variada contida em X  k  em uma medida escalar

(4)
(5)

i 1

log P  x  k  r   i 

x  k  , projetando variáveis não-observáveis do sis-

p

p

tema em uma escala real. Visto que s  X  é desco-

H xx  r    P  x  k   i , x  k  r   j  

nhecida, em conjunto com a presença do ruído
  k  , a reconstrução fidedigna de X  k  a partir de

log P  x  k   i , x  k  r   j 

x  k  é impossível. Entretanto, a estimação perfeita
do espaço original é desnecessária, sendo suficiente a
definição de um novo espaço de representação cujo
atrator seja equivalente (Takens, 1981). Denominado
espaço reconstruído, este espaço pode ser obtido por
t
(3)
x  k    x  k  , x  k    , , x  k   d  1 
onde  e d são parâmetros conhecidos como atraso
e dimensão da imersão, respectivamente.
O teorema de Takens (Takens, 1981) define as
condições para que o atrator no espaço reconstruído

onde p representa o número de intervalos utilizados

i 1 j 1

no cálculo dos histogramas P  x  k  r   i  a
probabilidade de x  k  r  pertencer ao intervalo  i 

P  x  k   i , x  k  r   j  a probabilidade conjunta

de x  k  pertencer ao intervalo  i e x  k  r  pertencer ao intervalo  j . Analogamente  análise de

rxx  k  , o primeiro mínimo de I x  r  pode ser utilizado como estimativa de  (Fraser e Swinney,
1986), sendo este o critério adotado neste trabalho.

4440

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Para estimação da dimensão da imersão d existem diversas técnicas propostas na literatura, baseadas no cálculo de características invariantes do atrator (Kantz e Schreiber, 1997) e (Abarbanel et.al.,
1993). Além de computacionalmente intensivas,
estas técnicas são subjetivas, requerendo a intervenção de especialistas na análise. Uma das técnicas
mais populares para estimação de d tem por base a
identificação de trajetórias espúrias, sendo conhecido
como método dos falsos vizinhos mais próximos
(Kennel et. al., 1992). Esta denominação encontra
fundamento na forma na qual as intersecções espúrias são identificadas observando a mudança na vizinhança de um dado ponto em função do aumento da
dimensão. Pontos vizinhos devido  dinâmica do
sistema permanecem nesta condição quando d sofre
acréscimo. Aqueles que deixam a vizinhança em
virtude do aumento da dimensão são denominados
falsos vizinhos, visto que estão situados na vizinhança devido  reconstrução incompleta do atrator.
Visando incrementar o nível de automação do
método dos vizinhos mais próximos, (Cao, 1997)
propôs um método prático para estimação de d . Seja
  i, j, d  a distância entre pontos x  i  e x  j 

valor d 0 . Em outras palavras, para dimensões superiores a d 0 o número de falsos vizinhos mais próximos não é alterado, fazendo com que J  d  não
sofra variações entre dimensões. Assim, a dimensão
de imersão é dada por d  d0  1 .

Para detecção automática de d 0 , seja d max a

dimensão máxima para a qual a estatística   d  é

calculada, supondo que a estabilização de   d  já
tenha ocorrido para algum d0  dmax . De posse dos
pares  d ,   d  , d  1, 2,..., dmax , um modelo de
regressão_linear da evolução de   d  em função de

d é estimado, sendo realizado um teste ao nível de
significância  para a hipótese nula considerando o
coeficiente angular igual a zero (Griffiths et. al.,
1993). Se a hipótese nula puder ser rejeitada, o primeiro par  d ,   d  é retirado, sendo estimado um
novo modelo considerando os pontos para
d  2,3,..., dmax . Este procedimento é repetido até a
hipótese nula não ser rejeitada, com a dimensão de
imersão sendo dada pelo primeiro ponto utilizado na
estimação do modelo_linear.
A heurística definida acima depende da definição de dois parâmetros, d max e  . A escolha do
nível de significância  , apesar de heurística, é mais
intuitiva e conhecida na literatura (Griffiths et. al.,
1993). Já a definição de d max está diretamente relacionada com o esforço computacional, visto que
devem ser realizados cálculos para dimensões maiores que d 0 . Neste trabalho, dmax  30 e   0,01 .

reconstruídos na dimensão d dada por

  i, j, d   max xl  i   xl  j 

(6)

l 1,..., d

Em (6), xl  i  representa o l-ésimo elemento do
vetor no instante i . O vizinho mais próximo de x  i 
é o ponto para o qual   i, j, d  é mínimo, ou seja,

n  i, d   arg  min   i, j, d 
 j  d 1 1,..., N


(7)

onde n  i, d  é o índice do vetor x  n  i, d  mais
próximo de x  i  no espaço de dimensão d .

2 Inferência Bayesiana Aplicada a MLPs (BMLPs)

Seja a  i, d  a relação entre vizinhos mais próximos em dimensões consecutivas dada por

a  i, d  

 i, n  i, d  , d  1

Seja x 

(8)

Na equação (8), se  i, n  i, d  , d  for nulo, n  i, d 
é substituído pelo índice do vizinho mais próximo
adjacente. O valor médio de a  i, d  dá origem 
estatística J  d  
N

 a i, d 

o vetor contendo os sinais de entrada

o vetor com todos os pesos e bias da
e w
RNA, sendo M  mn  2m  1 , com m respondendo
pelo número de neurônios na camada oculta. Os bias
dos neurônios sigmoidais da camada oculta são representados por bk , com b sendo o bias do neurônio
linear da saída, dada por

 i, n  i, d  , d 

1
J d  
N   d  1

n

M

m

 n

f ( x, w)    wk   ak  ( wik xi )  bk    b
k 1 
 i 1


(9)



i   d 1 1

(11)



Dado um conjunto U  X , Y contendo N pares

A variação relativa   d  desta estatística em função

entradasaída,

do aumento da dimensão da imersão é dada por
(10)
J  d  1
 d  
J d 

X

N



n

,

t
t
t
X   x1 , x 2 ,..., x N  ,

, Y   d1 , d 2 ,..., d N  , d j  sendo a saída
desejada, o objetivo do treinamento de RNAs sob a
ótica bayesiana reside na estimação do vetor w que
maximize a probabilidade a posteriori dada por

Y

Segundo (Cao, 1997), para séries_temporais oriundas de um atrator, a variação   d  estabiliza
quando a dimensão de imersão d é maior que um

4441

N

t

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

p Y w  p  w 

pw Y  

1
1 n3
ln p Y H h    S  w   ln A  w    M i i
2
2 i 1

(12)

p Y 

N

Na equação (12), p Y w é a verossimilhança de Y ,

p  w

a

probabilidade

a

priori

de

w

 ln(  2 m2 m !) 

e

p Y    p Y w  p w  d w .

As máquinas de vetores relevantes (RVMs) (Tipping, 2001) são modelos probabilísticos esparsos
baseados em kernel, esparsos no sentido que somente
alguns pontos do conjunto de treinamento contribuem para a estimação da superfície de regressão. Estes
pontos são denominados vetores relevantes.

tidade de dimensão M  M , e que as saídas desejadas estão corrompidas com ruído branco gaussiano
com variância  1 , ou seja, d j  f ( x j , w)   j , a



aplicação da equação (12) resulta em
  S  w 

 S  w

formulação probabilística tradicional considerando
ruído aditivo
na saída desejada,
k 

dw

dk  F  x k    k . Para modelar

onde

S ( w) 


2

N

 d
j 1

 f  x j , w 
2

j



Dado um conjunto de dados U  X , Y , seja a

(13)

e

e

1 n 3  2  1  2 
 ln    ln 

2 i 1   i  2  N   

3 Máquina de Vetores Relevantes (RVMs)

Assumindo que w possui uma distribuição
gaussiana com vetor média nulo e matriz de covariância diagonal igual a  1 I , I igual  matriz iden-

pw Y  

(16)


2

M

w
l 1

2
l

(14)

seja a função f  x, w 

n



F  x 

,

formada pela com-

binação linear de funções   x, z  

Portanto, maximizar a probabilidade a posteriori
p  w Y  é equivalente a minimizar S ( w) .



n

n



n



centradas em cada ponto do conjunto D 
N

(17)

f  x,W    wi   x, xi   b    x  W

Para problemas multivariados, a utilização de um
único  para todos os pesos não é recomendável.
Neste trabalho, os pesos que ligam cada entrada aos
neurônios da camada oculta são agrupados, com cada
grupo possuindo o seu respectivo  i . A mesma idéia
é aplicada aos demais pesos, sendo agrupados os bias
dos neurônios da camada oculta, os pesos que ligam
a camada oculta  saída e o bias do neurônio de saída, totalizando n  3 grupos. Neste caso, S ( w) passa
a ser dado por
2
(15)
 N
1 n 3 M
S ( w)    d j  f  x j , w   i  wil2
2 j 1
2 i 1 l 1

t

i 1

Em

w

(17),

N

,

b

W

,

N 1

,

t
W  b w  , com   x   n  N 1 representando as funções de base   x, xi   i  x  incluindo
uma parcela constante responsável pelo bias.
Pela regra de Bayes, a probabilidade a posteriori
p W Y , X é dada por
t











A magnitude dos  i s relacionados s entradas
pode ser utilizada para mensuração da relevância de
cada sinal. A inserção de variáveis de prova proposta
em (Ferreira e Alves da Silva, 2007) é utilizada neste
trabalho para definição empírica de limiares de relevância. Ao utilizar o próprio modelo na seleção das
entradas, a metodologia utilizada neste trabalho pode
ser inserida no grupo de técnicas encapsuladas (Guyon e Elisseeff, 2003). Maiores detalhes sobre o
processo de estimação dos  i s e  podem ser
encontrados em (Mackay, 1992) e (Bishop, 1995).
A inferência_bayesiana também pode ser utilizada
para seleção da melhor estrutura dentre uma série de
hipóteses   H1 , H 2 ,..., H K  , com o conjunto de

 
p Y X 

p Y W, X p W X

p W Y, X 



Em (18), p Y X





(18)

é um fator de normalização,

  representa a probabilidade a priori de W e
p Y W , X  a função de verossimilhança relacionada

p W X

com a distribuição de probabilidade do ruído aditivo
 k existente na saída desejada. Como os modelos
neurais não modelam a distribuição de X , condicionamentos em relação a esta variável serão omitidos a
partir deste ponto.
Supondo que as amostras do ruído  k sejam geradas de forma independente a partir de uma distribuição gaussiana com média nula e variância  2  , a

variáveis relevantes para cada hipótese previamente
selecionado. Supondo que todas as hipóteses sejam
equiprováveis e utilizando uma aproximação gaussiana em torno dos hiperparâmetros estimados, o logaritmo da evidência para os modelos ln p Y H h 

função de verossimilhança p Y W  é dada por
p Y W , 

2



1

 2 
2

pode ser obtido pela expressão (Bishop, 1995)

onde  

4442

N



N 1

N
2

 Y  W
exp  

2 2


2






é a matriz de modelagem.

(19)

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

Para a probabilidade a priori p W  seja o produto

Entradas com  k de pequena magnitude contribuem
menos para o cálculo da saída. Analogamente ao
apresentado na seção 2, variáveis de prova artificiais
são utilizadas para definição de limiares de relevância empíricos, sendo incluídas no modelo final somente as variáveis com relevância superior em relação  respectiva variável de prova. Os hiperparâmetros  k são estimados via subida em gradiente visando  maximização da evidência (Tipping, 2001).

de distribuições gaussianas dado por
N 1

p W    



1
exp  
Wi 2 
1
 2 i


1
2 i 1

i 1

(20)

Em (20), são consideradas distribuições gaussianas
distintas, todas com média nula e variância dada pelo
inverso dos respectivos i   , responsáveis pelo
controle da magnitude de cada parâmetro Wi .
Diante do surgimento dos hiperparâmetros  2 e
 , é necessária a definição de probabilidades a
priori para estas variáveis também desconhecidas.
Distribuições gamma não-informativas são utilizadas, refletindo o desconhecimento prévio sobre a
distribuição destes hiperparâmetros (Tipping, 2001).

4 Resultados
Para avaliação dos modelos, são utilizadas três bases de dados. O primeiro conjunto apresenta dados
horários de carga L(k), temperatura T(k) e temperatura ao quadrado T2(k) para o período de 1 de janeiro
de 1985 a 31 de março de 1991, utilizada em uma
competição (Ramanathan et. al., 1997). Deve ser
prevista a carga horária de 16 até 40 passos  frente,
para dias úteis, e de 16 até 80 passos  frente, para
fins de semana, para o período de 1 de novembro de
1990 a 31 de março de 1991. Para treinamento dos
modelos, são utilizados dados do mês corrente e dos
dois meses anteriores ao dia a ser previsto, sendo
também utilizados dados para o mesmo período do
ano anterior.
O segundo conjunto possui dados diários de carga
L(k) e temperatura máxima T(k) para o período de 1
de janeiro de 1997 a 31 janeiro de 1999, sendo utilizados todos os dados para treinamento. Neste caso,
são realizadas previsões para o período de 1 a 31 de
janeiro de 1999 (Chen et. al., 2004).
A última base de dados apresenta dados horários
de carga L(k) e temperatura T(k) para o período de 4
de dezembro de 2001 a 31 de dezembro de 2003. O
conjunto de treinamento é definido de forma análoga
ao utilizado no caso 1. A tarefa consiste na previsão
de carga horária, de 1 até 6 passos a frente, para
diferentes semanas de 2003 (Mandal et. al., 2005).
A Tabela 1 apresenta os parâmetros  e d estimados utilizando o critério do primeiro mínimo de
I x  r  e o método dos falsos vizinhos mais próximos

Visto que p Y W ,  2  e p W   são gaussianas,

p Y  ,  2  pode ser estimada diretamente por meio

da convolução entre as distribuições, sendo dada por
1
 1 t 1 
p Y  ,  2  
exp   Y C Y 
1
N
(21)
2

 2  2 C 2 
1

C   2 I  A 

t

Em (21), I é matriz identidade, com A diagonal
com aii  i . Assim, p W Y ,  ,  2  é dada por
t
 1

1
exp   W    W   
2


2
p W Y ,  ,   
1
N 1
2
 2  2 



N 1

onde  



   2   A
t

e 

N 1









N 1



(22)

dados por

1

(23)

   2  t Y
2

O valor esperado d N 1 e a variância  da estimativa da saída desejada d N 1 associada a um novo
ponto de teste x N 1 são obtidos através de



d N 1  f x N 1 , 

MP

    x

 
t

N 1

MP

descritos na seção 2 utilizando todos os dados disponíveis para treinamento. Estes parâmetros_são utilizados para definição do conjunto inicial de entradas
utilizadas em cada caso por meio da obtenção dos
respectivos espaços reconstruídos utilizando a equação (3). Visando modelar a sazonalidade presente nas
séries analisadas, ao conjunto inicial definido pelo
teorema de Takens são adicionadas variáveis binárias
para representação das sazonalidades. Assim, para os
casos 1 e 3 que tratam de séries horárias, são utilizadas mais 31 variáveis binárias para representação da
hora do dia (24 variáveis) e dia da semana (7 variáveis).
A Tabela 2 apresenta o desempenho dos modelos
em termos do erro absoluto percentual médio (EAPM) para os respectivos períodos de teste. A última
linha desta Tabela apresenta os melhores resultados
encontrados na literatura para cada base de dados,

(24)

   MP     x N 1    MP   x N 1 
2

Em (24), 

2

t

e 

MP

MP

são obtidos a partir da avalia-

ção das expressões (23) para 
e  MP estimados.
Um método iterativo para cálculo destes hiperparâmetros baseado no princípio da maximização da
evidência pode ser encontrado em (Tipping, 2001).
A função de base gaussiana utilizada neste trabalho permite mensurar a relevância de cada entrada
por meio da expressão
MP

  x, z   e



n

k  xk  zk 
k 1

2

(25)

4443

XVIII Congresso Brasileiro de Automática  12 a 16 Setembro 2010, Bonito-MS.

mostrando que os modelos autônomos apresentaram
resultados consistentes com a literatura.

Cao, L. (1997). Practical Method for Determining the
Minimum Embedding Dimension of a Scalar
Time Series, Physica D, v.110, n.1-2, pp. 43-50.
Chen, B.-J., Chang, M.-W., Lin, C.-J. (2004). Load
Forecasting Using Support Vector Machines A
Study on EUNITE Competition 2001, IEEE
Trans. on Power Systems, 19(4), pp. 1821-1830.
Ferreira, V.H., Alves da Silva, A.P. (2007), Toward
Estimating Autonomous Neural Network-based
Electric Load Forecasters, IEEE Transactions on
Power Systems, 22 (4), n.4, pp. 1554-1562.
Ferreira, V.H., Alves da Silva, A.P. (2009), Automatic Kernel Based Models for Short Term Load
Forecasting, Proceedings of the 15th International Conference on Intelligent System Application
to Power Systems, Curitiba, Paraná, Brazil.
Fraser, A.M., Swinney, H.L. (1986). Independent
Coordinates for Strange Attractors from Mutual
Information, Physical Review A, v.33, n.2, pp.
1134-1140.
Guyon, I., Elisseeff, A. (2003). An Introduction to
Variable and Feature Selection, Journal of Machine Learning Research, n.3, pp. 1157-1182.
Griffiths, W.E., Hill, R.C., Judge, G.G. (1993).
Learning and Practicing Econometrics, John Wiley  Sons.
Hippert, H.S., Souza, R.C., and Pedreira, C.E.
(2001). Neural Networks for Load Forecasting
A Review and Evaluation, IEEE Transactions
on Power Systems, v.16, n.1, pp. 44-55.
Kantz, H., Schreiber, T. (1997). Nonlinear Time
Series Analysis, Cambridge Nonlinear Science
Series, n.7, Cambridge University Press.
Kennel, M.B., Brown, R., Abarbanel, H.D.I. (1992).
Determining Embedding Dimension for Phasespace Reconstruction Using a Geometrical Construction, Physical Review A, v.45, n.6, pp.
3403-3411.
Mandal, P., Senjyu, T., Uezato, K., Funabashi, T.
(2005). Several-Hours-Ahead Electricity Price
and Load Forecasting Using Neural Networks,
IEEE PES General Meeting, San Francisco,
USA.
Mackay, D.J.C. (1992). Bayesian Methods for Adaptive Models, Ph.D. dissertation, California Institute of Technology, Pasadena, California, USA.
Ramanathan, R., Engle, R., Granger, C.W.J., VahidAraghi, F., Brace, C. (1997). Short-Run Forecasts of Electricity Loads and Peaks, International Journal of Forecasting, v.13, n.2, pp. 161174.
Takens, F. (1981). Detecting Strange Attractors in
Turbulence, In. D.A. Rand, L.-S. Young (eds.),
Dynamical Systems and Turbulence, Lecture
Notes in Mathematics, v.898, pp. 366-381,
Springer-Verlag.
Tipping, (2001). Sparse Bayesian Learning and the
Relevance Vector Machine, Journal of Machine
Learning Research, v.1, pp. 211-244.

Tabela 1. Parâmetros da imersão ( e d)

L (k )
T (k )
T 2 (k )

Caso 1
d

10
6
18
13
17
13

Caso 2
d

12
4
14
15
-

Caso 3
d

12
13
19
13
-

Vale destacar que os resultados encontrados na
literatura foram obtidos por modelos especificados
por especialistas em previsão_de_carga, ao passo que
os modelos autônomos propostos neste trabalho
requerem a intervenção pontual de especialistas na
definição de poucos hiperparâmetros não relacionados diretamente com as séries em análise. Em outras
palavras, ao contrário de parâmetros como número
de neurônios na camada oculta, os hiperparâmetros
dos modelos autônomos propostos podem ser definidos de forma mais geral.
Tabela 2. Comparação entre os modelos (EAPM)
Caso 1 Caso 2
BMLP
RVM
Benchmark

4.83
8.64
4.73

3.25
3.00
1.98

Caso 3
1 passo 2 passos 3 passos 4 passos 5 passos 6 passos
0.64
1.02
1.55
1.69
1.87
1.88
1.09
1.80
2.10
2.29
2.72
2.94
0.56
0.83
1.00
1.15
1.20
1.30

5 Conclusão
Este trabalho investigou a aplicação da teoria do
caos na definição do conjunto inicial de entradas de
modelos neurais autônomos. Autonomia deve ser
entendida como um conjunto de procedimentos automáticos e acoplados para escolha do espaço de
entrada e controle de complexidade da estrutura,
incluindo seleção do modelo. Neste trabalho, dois
modelos baseados em redes_neurais foram utilizados
inferência_bayesiana aplicada a MLPs e máquinas de
vetores relevantes. Os resultados obtidos, comparáveis com os melhores encontrados na literatura para
as bases de dados analisadas, mostram a potencialidade dos modelos autônomos propostos neste trabalho, incrementando o nível de automatismo das metodologias propostas em (Ferreira e Alves da Silva,
2007) e possibilitando a utilização de tais métodos
em problemas incluindo múltiplas séries_temporais,
por exemplo, previsão por barramento. O desenvolvimento de BMLPs considerando ruídos nãogaussianos em conjunto com melhorias no método
iterativo para estimação dos parâmetros e hiperparâmetros das RVMs podem contribuir para melhoria
dos resultados promissores obtidos neste trabalho.

Referências Bibliográficas
Abarbanel, H.D.I., Brown, R., Sidorowich, J.J.,
Tsimring, L.S. (1993) The Analysis of Observed
Chaotic Data in Physical Systems, Reviews of
Modern Physics, v.65, n.4, pp. 1331-1392.
Bishop, C.M. (1995). Neural Networks for Pattern
Recognition, Oxford University Press.

4444